{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the ACL Ethics Website","text":"<p>Why are you here? What are you looking for? Ethics is a broad and interdisciplinary concern of our field. </p> <p>Ethics can be defined as \"a branch of philosophy that systematizes, defends, and recommends concepts of right and wrong conduct\" (Wikipedia). As members of the ACL community, ethics can guide us towards a fairer, more respectful and honest research, which aims at honoring everyone, within and outside of our community, as well as our environment. You will find a more detailed definition in the ACL Code of Ethics, with a special focus on ethics as a NLP researcher.</p> <p>The people visiting this website have one or several of the questions below in mind that brought them here. Which one is/are yours? </p> <p>Starting your Research? One aspect of ethical research is not only to adhere to the Ethics Charter linked above, but also to think about our research methodology as outlined in the responsible research checklist. This checklist should be part of every scientific project in the domain of CL/NLP and should be the first point of reference if you come up with an interesting research question \u2013 even before you start working on it. Throughout the project, the checklist guides you to keep in mind questions of responsible research. Added benefit: On submission of your paper it is already filled in and you don\u2019t have to think about what you decided several weeks or months ago. See here how this can be put into practice. </p> <p>How do I review for Ethics?  Much of our research can have real-world implications and touch on sensitive ethical issues. As a concerned scholar and reviewer of our community, perhaps you are unsure what constitutes an appropriate use for flagging a paper for further ethics review.  Perhaps you also want to learn how to contribute to the process of assessing papers for ethical issues. We\u2019ll show you how to best use the author-provided responsible research checklist as a basis for starting your assessment, and also how to test your own knowledge of ethics through case studies and simulated reviewing.</p> <p>Ethics reviewing is arguably one of the most important contributions we as a community can do for the long-term health of our field. Right now, we are sorely lacking in enough manpower to do all the reviewing we would ideally want to do. By completing these self-guided exercises, we hope that you will volunteer to the pool of qualified ethical reviewers to help make scalable ethics reviewing a reality. You can find case studies in the Tutorial resources, and a detailed recommendations document in the Resource section.</p> <p>How do I learn about Ethical Concerns? While checklists are a good means to start thinking about ethics from common perspectives, it is important to view such checklists as an incomplete means to holistically think about the impact of our work. There will be new areas of concern that become necessary to consider as our scholarship continues to advance. We\u2019ll walk you through some case studies to help you think about works from multiple stakeholders\u2019 perspectives and timeframes. You can find such case studies in the Tutorial resources.</p> <p>Are there good resources to teach Ethics? You are a researcher, lecturer, reader or professor in CL/NLP and want to raise awareness on ethical issues amongst your students \u2013 either BSc, MSc or PhD level. Our Instructors page organizes the resources relevant to teaching ethics to students.</p> <p>I am interested in Ethics Research, where should I start? We compiled a list of relevant NLP papers that address a variety of topics: biases,  crowdsourcing issues, dual use, environmental impact,... You can find this Reading list, and contribute to it, in the Resource section.</p>"},{"location":"committee/","title":"Committee","text":""},{"location":"committee/#members-of-the-acl-ethics-committee","title":"Members of the ACL Ethics Committee","text":"David Ifeoluwa Adelani (david.adelani@mcgill.ca, he/him) is an Assistant Professor at McGill School of Computer Science, Canada and a Core Academic Member at MILA, and a Canada CIFAR AI Chair (in 2024). Previously, he was a DeepMind Academic Fellow at UCL, and a obtained his PhD in Computer Science at Saarland University. He specializes in machine learning, multilingual NLP, and NLP for low-resource languages, focusing on machine translation, multilingual representation learning, and cross-lingual transfer learning. His expertise extends to speech processing, including text-to-speech, speech recognition, speech representation learning, and speech translation.          Alvin Grissom II (agrissom@haverford.edu, he/him) is an Associate Professor of Computer Science at Haverford College.          Zhijing Jin (zjin@cs.toronto.edu, she/her) is an incoming Assistant Professor at the University of Toronto, as well as a CIFAR AI Chair, ELLIS advisor, faculty member at the Vector Institute, and faculty affiliate at the Schwartz Reisman Institute. She is currently a postdoc at Max Planck Institute for Intelligent Systems in Germany. Her research focuses on causal inference for NLP, with a focus on Responsible AI applications. Together with Rada Mihalcea and many others, she co-organizes many NLP for Positive Impact Workshops at *CL conferences, as well as the  ACL Year-Round Mentorship.          Min-Yen Kan (kanmy@comp.nus.edu.sg, he/him): Associate Professor at the National University of Singapore and a co-chair of the ACL Ethics Committee. He has taught over 5,000 graduate and undergraduate students on his research interests in digital libraries, information retrieval and natural language processing.          Seunghun J. Lee (seunghun@icu.ac.jp, he/him) is a Senior Associate Professor of Linguistics at the International Christian University, a liberal arts college in Tokyo, Japan. I am also an Adjunct Professor of African Languages at the University of Venda in South Africa, and an Honorary Associate Professor in the Centre for Linguistic Science &amp; Technology at the Indian Institute of Technology Guwahati in India.           Margot Mieskes (margot.mieskes@h-da.de, she/her) is a Professor for Information Science at the University of Applied Sciences, Darmstadt, Germany. She works in Computational Linguistics (CL) and Natural Language Processing (NLP), focusing on automatic summarization, evaluation methods, data quality, emotion detection, ethics, experiment reproducibility, and biases in large language models.          Aur\u00e9lie N\u00e9v\u00e9ol (aurelie.neveol@lisn.fr, she/her) is a CNRS Researcher at LISN (formerly, LIMSI) working on clinical and biomedical Natural Language Processing. Her research interests include information extraction and knowledge representation in specialized domains. Her research addresses both methods and applications of biomedical text analysis, ranging from explorations of representation models and their cross-language or cross-domain adaptability, to the integration of representation frameworks to extract new medical knowledge from clinical text. She also has a strong interest in ethics issues related to the development, evaluation and deployment of Natural Language Processing systems.          Adriana Silvina Pagano (apagano@ufmg.br, she/her) is a Full Professor in Applied Linguistics at the Federal University of Minas Gerais, Brazil, teaching and supervising students. As a CNPq and FAPEMIG research fellow, she investigates multilingual text production and models multilingual texts. She collaborates internationally and co-leads an interdisciplinary group focusing on NLP and healthcare studies."},{"location":"committee/#student-members-of-the-acl-ethics-committee","title":"Student Members of the ACL Ethics Committee","text":"Fanny Ducel (fanny.ducel@universite-paris-saclay.fr, she/her) is a PhD candidate at the Universit\u00e9 Paris-Saclay, in France. She works on stereotypical biases in LLMs. She also teaches ethics to international NLP graduates at the Universit\u00e9 de Lorraine (France).          Guido Ivetta (guidoivetta@mi.unc.edu.ar, he/him) is a PhD candidate at the Universidad Nacional de C\u00f3rdoba, in Argentina. His work focuses on language model calibration and biases.          Punya Syon Pandey (punya.pandey@mail.utoronto.ca, he/him) is a research assistant at the University of Toronto, in Canada. His work focuses on adversarial robustness in LLMs and evaluating multi-agent interactions.         Esther Gan (esther.gan@u.nus.edu, she/her) is a PhD candidate at National University of Singapore. Her work focuses on LLM trustworthiness and adversarial robustness."},{"location":"committee/#past-members-of-the-acl-ethics-committee","title":"Past Members of the ACL Ethics Committee","text":"<ul> <li>Luciana Benotti - Served as Co-Chair (2024-2025)</li> <li>Mark Drezde</li> <li>Kar\u00ebn Fort - Served as Co-Chair (2021-2025) </li> <li>Pascale Fung</li> <li>Dirk Hovy</li> <li>Jin-Dong Kim</li> <li>Malvina Nissim</li> <li>Yulia Tsvetkov</li> </ul>"},{"location":"committee/#past-stuent-members-of-the-acl-ethics-committee","title":"Past Stuent Members of the ACL Ethics Committee","text":"<ul> <li>Minzhi Li - Served in 2024</li> </ul>"},{"location":"schedule/","title":"Schedule","text":"<p>In this page, we will post all past and upcoming events related to the ACL Ethics Committee. This will serve as a comprehensive schedule where members and interested parties can stay informed about important dates and activities. Whether it's meetings, workshops, or conferences, you will find all relevant information here. Our goal is to ensure transparency and keep everyone updated on the committee's efforts and initiatives. By regularly checking this page, you can stay engaged with the ongoing work and contribute to the ethical discourse within the ACL community.</p>"},{"location":"resources/","title":"Resources","text":"<p>In this page, we will compile all relevant materials necessary for crafting ethical consideration sections for ACL papers. This includes guidelines for ethical research, best practices, and case studies to help researchers navigate diverse situations. By providing comprehensive resources, we aim to support authors in addressing ethical issues effectively and ensuring their work adheres to the highest standards of integrity. Whether you are new to ethical research or looking to refine your approach, this page will serve as a valuable reference to guide you through the process of ethical decision-making in your research endeavors.</p>"},{"location":"resources/#what-you-will-find-here","title":"What You Will Find Here","text":"<ul> <li> <p>Reading list: A curated list of essential readings that cover various aspects of ethical research. This includes foundational texts, recent papers, and influential articles that provide insights and guidance on ethical considerations in research.</p> </li> <li> <p>Responsible Research Checklist: A checklist to help you think about your research and whether or not it complies with the ACL Code of Ethics. </p> </li> <li> <p>Ethical Review Recommendations: The ACL Ethics committee is currently working on a detailed document compiling all the information on ethical reviewing for reviewers, ethical reviewers, ethical chairs, and conference chairs.</p> </li> <li> <p>Teaching Material: The tutorials resources include material that can be re-used to teach ethics in an academic context.</p> </li> </ul>"},{"location":"resources/ethical-review-recommendations/","title":"Ethical Reviewing Recommendations","text":"<p>This document aims at regrouping information and recommendations about ethical reviewing. It is split into different sections, each directed at different actors: conference chairs, ethical chairs, ethical reviewers, and authors/general reviewers.</p> <p>This was made by combining information from different sources, either pasting them or rephrasing them. The structure and patchwork was done by Ella Li, Minzhi and Fanny Ducel. The conversion to Markdown was done by Guido Ivetta: </p> <ul> <li> <p> \u2013 Kar\u00ebn Fort and Min-Yen Kan</p> </li> <li> <p> \u2013 Jin-Dong Kim and Min-Yen Kan</p> </li> <li> <p> \u2013 Vinodkumar Prabhakaran and Malihe Alikhani (ACL Rolling Review Ethics Chairs), with help from NAACL 2024 Ethics Chairs, EACL 2024 Ethics Chairs, and EMNLP 2024 ethics chair</p> </li> <li> <p> \u2013 Karen Fort and Min-Yen Kan (No need to formally cite)</p> </li> <li> <p> \u2013 developed by Marine Carpuat, Marie-Catherine de Marneffe and Ivan Vladimir Meza Ruiz, the NAACL 2022 program chairs, working with Jesse Dodge, and with the ARR editors in chief. Additional input was provided by the other NAACL 2022 reproducibility chairs, Margot Mieskes, Anna Rogers, and the ACL Ethics Committee. Updated for ARR October 2024 cycle by Anna Rogers, based on discussions with ARR board.</p> </li> <li> <p> \u2013 drafted for ARR by Amanda Stent and reviewed and edited by the ARR Editors in Chief, Tim Baldwin, Anna Rogers, the NAACL 2022 ethics chairs Kai-Wei Chang and Diyi Yang, and members of the ACL Ethics Committee.</p> </li> <li> <p> \u2013 Malihe Alikhani and Vinodkumar Prabhakaran</p> </li> <li> <p> \u2013 Luciana Benotti, Kar\u00ebn Fort, Min-Yen Kan, Yulia Tsvetkov</p> </li> </ul>"},{"location":"resources/ethical-review-recommendations/#1-general-introduction-to-ethics-reviewing","title":"1. General introduction to ethics reviewing","text":"<p>The following section is a compilation of other documents: one written by Kar\u00ebn Fort and Min-Yen Kan and another written by Malihe Alikhani and Vinodkumar Prabhakaran.</p> <p>Ethics reviews are a cornerstone of maintaining integrity and responsibility in academic research. They are not just a formality; they are critical to the integrity of academic discourse. In particular, the ethics reviews are meant to assess whether the submitted research exhibits any substantial ethical issues and could lead to harm. It is especially critical to uphold these standards as we engage in research that deals with sensitive data and/or controversial topics. Ethics reviewing plays a pivotal role in safeguarding these standards. We want to emphasize that an ethics review is not just about ticking boxes, nor is it a technical review; it\u2019s about engaging critically with the material and its implications.</p> <p>The existence of ethics committees should not inhibit, prevent, or discourage reviewers, ACs, or SACs from making decisions to reject a paper on the basis of ethical concerns. While our committee will presumably provide reviews and discussion for those papers, we believe it should be the ultimate goal of the ACL community that these considerations be considered as a relevant part of the standard review process.</p>"},{"location":"resources/ethical-review-recommendations/#standardized-terminology","title":"Standardized Terminology","text":"<p>ACL Ethics Committee - In charge of \u201cprovid[ing] a continuous and consistent platform for dealing with potential ethical concerns raised within ACL events and the ACL community\u201d, focusing on \u201cprovid[ing] guidance and address considerations of what constitutes ethical research\u201d. Their role includes the coordination with Ethics chairs at *ACL conferences, the provision of guidelines on how to report ethical concerns and more generally, \u201cthe compilation and publication of resources to educate the broad community about the limitations and societal implications of the technologies we develop and deal with ethical concerns within the ACL\u201d. The present document was created by members of the ACL ethics committee, in line with the last aforementioned goal. Composed of \u201cthree co-chairs serving a five-year term, and six members at large serving a three-year term, ensuring uniform coverage of the three geographic regions represented by AACL, EACL, and NAACL\u201d. The members of the current committee are listed at LINK. Source.</p> <p>ARR Ethics Chairs - In charge of considering submissions flagged for ethics review during ARR review. If they consider it necessary, they will assign the paper to ethics reviewers for an in-depth ethics review. They remain in charge of supervising all the ethics review(er)s.  As of Dec 2024, the ARR Ethics Chairs are, according to source, Malihe Alikhani and Vinodkumar Prabhakaran. (Rephrased from source and source)</p> <p>Ethics Review Chairs of a Convenor - Each conference has its own ethics chairs. Their role is similar to the one of ARR Ethics Chairs but for the papers submitted to the conference they are in charge of.</p> <p>ACL Publications ethics committee - In charge of \u201cdeveloping policies and procedures related to publication ethics, including such issues as plagiarism, the use of LLMs in producing reviews, disclosures of e.g. authorial control of papers, and how to handle issues raised about papers post-publication\u201d. A first policy was made available in June 2024 at source. As of Dec 2024, the current chairs are Leon Derczynski, Dr. Kokil Jaidka and Dr. Aoife Cahill. Source.</p>"},{"location":"resources/ethical-review-recommendations/#2-recommendations-for-conference-chairs","title":"2. Recommendations for conference chairs","text":""},{"location":"resources/ethical-review-recommendations/#make-sure-ethics-chairs-have-enough-time","title":"Make sure ethics chairs have enough time","text":"<p>The ethics chairs should be recruited early in the conference planning process, with sufficient time to participate in setting the review schedule to ensure there is time for ethics review and clarity about how papers will be referred and evaluated.</p> <p>There should be at least 2-3 weeks in the review timelines allocated to the ethics review, and there should be a strict cut-off for when the ACs/SACs flag a paper for ethics review.  Ethics chairs should not be getting requests after the Ethics review timeframe.</p>"},{"location":"resources/ethical-review-recommendations/#process-flow-arr-ethics-chairs-including-conference-ethics-chairs","title":"Process Flow (ARR Ethics Chairs, including conference ethics chairs)","text":"<p>During ARR review, some submissions are flagged for ethics review. These submissions are considered by the ethics chairs and if necessary, sent to ethics reviewers, who are supervised by the ethics chairs.</p> <p>Timeline:</p> <p></p>"},{"location":"resources/ethical-review-recommendations/#phase-0-preparation","title":"Phase 0: Preparation","text":"<ol> <li>Familiarize with the Open Review consoles:<ul> <li>You can find them by logging into the Open Review platform. If your profile is correctly set up in the system as Ethics Chairs for a particular ARR cycle, you should have two of the below consoles (in addition to others) under Your Active Consoles:<ul> <li>ACL ARR &lt;Year&gt; &lt;Month&gt; Ethics Chairs Console: This is the main console where you perform most of the actions related to this task, such as reviewing papers, ethics review flag and justification, assign ethics reviewers etc. </li> <li>ACL ARR &lt;Year&gt; &lt;Month&gt; Ethics Reviewer Console: This console will be used in two contexts:<ol> <li>When you want to see how a reviewer sees the assignment (for example, to check the review form).</li> <li>To Add a review to a paper acting as ethics reviewer (for which you\u2019ll first have to assign yourself as an ethics reviewer to the paper from the Ethics Chairs console).</li> </ol> </li> </ul> </li> </ul> </li> <li>Familiarize with the ARR Ethics Review Cycle-specific Master Tracking Sheet, which contains the following sheets:<ul> <li>Timeline: A spreadsheet version of the above timeline, where you could add Cycle-specific dates for easy tracking etc.</li> <li>Instructions: A set of common false flags and misconceptions about ethics reviewing, and suggested actions and how to deal with them (including comment templates, if applicable)</li> <li>Reviewers: A sheet that keeps track of the reviewers available for the current cycle. This will help keep track of how many papers are assigned to each reviewer, what load they requested etc.</li> <li>Chairs Coordination: To coordinate among the ethics chairs; to track the load handled by each chair, to track availability/OOO time etc.</li> <li>Papers Tracking: A sheet that keeps track of each paper flagged for ethics review.</li> <li>Papers in the OR queue: </li> </ul> </li> <li>Ensure that we have an adequately sized ethics reviewer pool. <ul> <li>Having an adequate # of reviewers depends on the submission volume. In the past, about 4% of all submissions get a full ethics review and we recommend a rate of 5%. Each paper needs just one ethics review. So assuming 2.5 papers per reviewer on average, for X total submissions, if you have between 0.02X/2.5 and 0.03X/2.5 reviewers, you should be good. </li> <li>But keep track of trends in your cycle, and you may need to request new reviewers if you feel the existing pool doesn\u2019t have the expertise to review a particular paper.</li> <li>Add any new reviewers to the \u201cReviewers\u201d sheet in the master tracking sheet</li> <li>To check the reviewers in the system, click on the \u201cEdit Group\u201d button on the top of the Ethics Reviewer Console. </li> <li>To add new reviewers to the system, follow the instructions here.</li> </ul> </li> <li>Ensure reviewer availability for the time period. <ul> <li>Please note that every ethics reviewer from past cycles will have been carried over to the new cycles on Open Review, but they may not be available to review for your cycle. So you will need to first check with them about their availability \u2014 either using the message functionality or directly emailing them (latter is more likely to succeed).</li> <li>You may also use this form and sample recruitment email to recruit additional reviewers as well as collect their availability information.</li> </ul> </li> </ol>"},{"location":"resources/ethical-review-recommendations/#phase-1-2-assigning-tracking-ethics-reviews","title":"Phase 1 &amp; 2: Assigning &amp; Tracking Ethics Reviews","text":"<p>Because this will need to be coordinated among all ARR ethics chairs, we usually do this using a spreadsheet for coordination and tracking.</p> <ol> <li>[Monitoring]: Monitor the incoming papers and add them to the \"Papers Tracking\" sheet in the master spreadsheet. This is an ongoing task and has a few kinks that are outlined below. [Owner Assignment] Assign an Owner ethics chair who will be in charge of the paper</li> <li>[Initial assessment] Decide which papers really need an ethics review. The usual process is to perform a quick check and flagging papers that don't have any justifications etc. You can check the \"Instructions\" sheet in the spreadsheet for some common patterns and suggested actions. You may also choose to read the abstract or quickly review the paper, in case of any doubt.</li> <li>[Optional Note] If a paper does not need a full ethics review,<ul> <li>You may want to leave a note depending on what the case is. Some such scenarios in the Instructions sheet. Rule of thumb is whether the flagger or authors benefit from knowing that someone looked at it from an ethics perspective. If a paper was flagged with a justification \"None\", it is a false flag and doesn't require a response. But if, for instance, it was flagged for not having an ethical consideration section, it would be helpful for the flagger and the authors to hear that we looked at it and it (by itself) was deemed to be not enough justification for a full review.</li> <li>If you need to add a note, you have to first assign yourself as a reviewer to the paper (instructions here). It may take a while for the assignment to trickle through. So you may have to check after a few minutes to an hour.</li> </ul> </li> <li>[Reviewer Assignment] If a paper is deemed to need a full ethics review:<ul> <li>Assign the reviewer in OpenReview. You can do it by going to the Ethics Chairs console and clicking on the paper and it should show an \"edit assignments\" button. Detailed instructions here.</li> <li>Update the Papers Tracking sheet to keep track, and also making sure not to assign more than 2-4 papers (depending on the cycle) to each ethics reviewer, and respecting any reduced load they requested. </li> </ul> </li> <li>[Follow up] Owner follows up with the reviewer closer to the review deadline to make sure they submit their ethics review by then. Emailing directly is often more effective than reminders via OpenReview. This deadline varies between Phase 1 &amp; Phase 2.</li> </ol>"},{"location":"resources/ethical-review-recommendations/#ongoing-tasks","title":"Ongoing Tasks","text":"<ul> <li>[Monitoring Flagged Papers] Whenever a reviewer/AE flags a paper for ethics review, it automatically sends an email to all ethics chairs. You can also see the currently flagged papers in the \u201cPaper Status\u201d tab in the Ethics Chairs console. Periodically, make sure to update the \u201cPapers Tracking\u201d sheet in the Master Spreadsheet with these flagged papers so that you can coordinate on the initial assessment and review assignment. You may use a helpful script written by Ameeta Agarwal given below, or simply use a spreadsheet formula to do such batch transfer, periodically., There are a few issues associated with this:<ul> <li>[Inflow] They come in almost daily, and aligned with certain deadlines in the technical review timeline, there may be huge influxes of papers getting tagged. This is a manual step. So you may want to wait for a few days to get a big batch in one go, or update the sheet with papers as they come, based on what your work style is and bandwidth at that time. I have reached out to OpenReview to make this easier, and will report back if viable.</li> <li>[Duplicates] Every time a reviewer/AE flags a paper we get an email. So if you are adding papers to the sheet from the email notifications, note that some of them may already have been flagged. Currently Column C in the Papers Tracking sheet has a formula to flag duplicates, to make it easier to detect them.</li> <li>[Removals] Some reviewers/AEs may realize a paper was accidentally flagged, and update their ethics review flag to \u201cNo\u201d. This will remove the paper from the Paper Status console on Open Review. Correspondingly I have added a column D in the Papers Tracking sheet to note if the paper is active on the console. In the beginning you can manually update it if you find the paper is no longer in the console. But we can also semi-automatically refresh this column periodically. </li> </ul> </li> </ul>"},{"location":"resources/ethical-review-recommendations/#suggestions-for-call-for-paper","title":"Suggestions for Call-for-paper","text":"<ul> <li>The Call for Papers (CFPs) should incorporate ethics guidelines, making it clear that submissions may be subject to rejection due to ethical concerns.</li> <li>This proactive measure may contribute to deterring submissions presenting straightforward ethical issues, such as manual annotations lacking proper compensation disclosure.</li> <li>For conferences featuring multiple tracks (e.g., main, student, industrial), uniform ethical guidelines should be applied across all tracks. It's essential that these guidelines are clearly articulated in the CFPs for each track, ensuring consistency and awareness among prospective authors.</li> <li>Furthermore, extending these ethical standards to the Call for Tutorials and Workshop Proposals is prudent. Given that workshop papers are also archived in the ACL Anthology, adherence to the same ethical guidelines is imperative to maintain integrity across all conference proceedings.</li> </ul>"},{"location":"resources/ethical-review-recommendations/#3-recommendations-for-ethics-committee-chairs","title":"3. Recommendations for ethics committee chairs","text":""},{"location":"resources/ethical-review-recommendations/#form-a-diverse-committee","title":"Form a diverse committee","text":"<p>Form a large and diverse ethics committee, including participants working in different countries from all continents and declaring a variety of genders. For an example, see the NAACL 2021 committee. We also recommend that ethics reviewers have term limits (where possible) to motivate and ensure that ethics reviewers come from a wide and diverse swath of the memberships and not by a fixed coterie of incumbent reviewers. Less experienced ethics reviewers can be paired with more experienced ones.</p> <p>As members of such a committee may experience pressure to implement decisions from their institutions and/or governments, we suggest to give papers to ethics-review to reviewers from another country. This will not eliminate such risks, but will allow to limit them. </p>"},{"location":"resources/ethical-review-recommendations/#plan-enough-time-anticipate-the-uncertainty","title":"Plan enough time, anticipate the uncertainty","text":"<p>The ethics committee and the recommendations to authors should be publicized in advance (at least one month) on the conference website and on the usual lists. The overall process, including conditional-accept papers shepherding, takes quite a long time and this should be planned accordingly.</p> <p>Take into account the fact that some papers might be flagged for ethics and be false positive, i.e. will not in fact need an ethics review.</p>"},{"location":"resources/ethical-review-recommendations/#document-the-process","title":"Document the process","text":"<p>The ACL ethics committee\u2019s website provides a dedicated form for documentation at LINK.</p> <p>The documentation of the process will, among other things, help future ethics chairs to estimate their workload.</p> <p>Documentation should especially include the number of papers: - flagged for ethics review - indeed reviewed for ethics - accepted conditionally - rejected on ethical grounds: both scientific and ethical OR ethical only</p>"},{"location":"resources/ethical-review-recommendations/#scope-of-ethical-reviewing","title":"Scope of ethical reviewing","text":"<ul> <li>The purview of Ethics Chairs should be limited to reviewing the ethical issues in the execution of the research presented in the paper. </li> <li>Perhaps the ethics section in the papers (or the checklist in the submission process) explicitly requires that authors state explicitly that they had legal access to this data.  </li> </ul>"},{"location":"resources/ethical-review-recommendations/#4-recommendations-for-ethics-reviewers","title":"4. Recommendations for ethics reviewers","text":"<p>These guidelines are aimed at ethics reviewers, i.e. people assigned to review papers that have already been flagged by other reviewers, focusing on ethics issues. These guidelines are not meant to be exhaustive (especially as ethics is a discussion and can not be diminished to a checklist), but to help reviewers to better understand their role and provide them practical examples.</p>"},{"location":"resources/ethical-review-recommendations/#scope-what-to-focus-onhow-to-write-an-ethics-review","title":"Scope (what to focus on/how to write an ethics review)","text":"<p>Reminder: an ethics review is not a scientific, nor a complete technical review. Your focus is only on the ethical issues and their presentation. You do not need to check any equations, thoroughness of citations (except as they pertain to ethical issues), or provide any feedback on experimental design or grammar/typos/writing style.</p> <ul> <li>The goal of the ethics review is to decide whether or not there are any substantial ethical issues (i.e. increased risk of harm outside the current norms of NLP/CL research) with the research presented in the submission.</li> <li>Take into account the paper, supplementary materials, the ethics and reproducibility checklist completed by the authors. However, the paper should stand on its own.</li> <li>If there are ethical issues:<ul> <li>Describe each in terms of the (ACL code of ethics). If you cannot describe the issue in terms of the ACL code of ethics, please consider whether this is something the community agrees is an issue. Please refrain from relying on regional or national laws, regulations or practices in your ethics review, since the submission may be from another country or region. What governs acceptable practice in *ACL venues is the ACL code of ethics. Bear in mind that notions of ethical behavior and practice vary over time and across cultures. If you have questions, please contact the ACL ethics committee.</li> <li>For each ethical issue you identify, describe how you would suggest the authors address it.</li> </ul> </li> </ul>"},{"location":"resources/ethical-review-recommendations/#examples-of-issues","title":"Examples of issues","text":"<ul> <li>Issues with the method or approach, for example:<ul> <li>failure to consider and ameliorate the negative impacts of the approach on the political, social, or natural environment. </li> <li>failure to consider and ameliorate biases that the approach may perpetuate</li> <li>failure to consider possible risks and impacts of the approach.</li> <li>failure to consider robustness and security, especially in papers about the development of systems close to or in production deployment.</li> </ul> </li> <li>Issues with the use of code, data and use of people, for example:<ul> <li>failure to obtain informed consent where required, or to protect personally identifiable information as required by relevant institutional ethics boards.</li> <li>failure to respect intellectual property and data/code ownership; failure to cite the creators of artifacts used, or to use these artifacts in the ways intended (for example, violations of licenses).</li> <li>failure to consider and ameliorate biases in the data, or biased code/model outputs.</li> <li>failure to consider how the data, the code or other outcomes of the research may cause harm.</li> <li>failure to consider how the participation of people (e.g. annotators) in the research may cause benefits or harms to those individuals.</li> </ul> </li> <li>Issues with the intended or potential applications of the research (i.e., dual use), for example:<ul> <li>failure to consider how applications of the research may harm individuals, groups or society at large</li> <li>failure to discuss ways to mitigate such harms.</li> <li>failure to consider other possible risks of applications of the research; failure to discuss ways to mitigate such risks.</li> </ul> </li> <li>Other issues, including academic dishonesty:<ul> <li>dishonesty in the execution or presentation of the research, including **plagiarism**, deliberate **violation of anonymity, citation, review**, or **duplicate submission policies, falsifying results**, or **misrepresentation** (for example, claiming someone is a co-author when they are not).</li> </ul> </li> </ul>"},{"location":"resources/ethical-review-recommendations/#examples-of-ethics-review","title":"Examples of ethics review","text":""},{"location":"resources/ethical-review-recommendations/#examples-of-ethics-reviews-that-adhere-to-the-above-guidelines","title":"Examples of ethics reviews that adhere to the above guidelines","text":"<p>The paper considers the analysis of data from a website that hosts user contributed posts. The authors obtain access to private data by using an account that falsified information to deceive site moderators. The authors scrape the content of the site and release the resulting data, without removing personally identifiable information (including usernames). They do not obtain approval from the site owners or obtain informed consent from the site users. These practices violate the ACL code of ethics\u2019 guidance to \u201cAccess computing and communication resources only when authorized or when compelled by the public good\u201d and to \u201cRespect privacy\u201d. The authors are encouraged to (a) document whether and how they obtained permission to scrape and reshare the data; and (b) document how they will remove personally identifiable information from their dataset before releasing it.</p> <p>The authors fail to discuss ways in which their solution may cause harm to individuals or groups; specifically, in this case, ways in which their solution, if applied, would \u201cout\u201d people who are LGBTQIA, including potentially people who are not out, and potentially falsely \u201cout\u201d people who are not LGBTQIA. This has significant potential to cause harm, rather than contributing to society and to human well-being, as outlined in the ACL code of ethics. I don\u2019t see any way for the authors to avoid these potential harms as their solution currently stands; the best they can do is to promise not to release their model, data and code. (There are cultures and societies where being a member of one of these groups is against the law or considered to be immoral; however, an ethics reviewer in this case might refer the authors to the Universal Declaration of Human Rights).</p> <p>The authors of this paper claim that their solution beats the performance of previous methods on a common benchmark dataset. To demonstrate the improvement, the authors reproduce a figure showing accuracy numbers of several methods from a previous paper. However, the authors include the figure without attribution and modify it to remove another method that obtains better results than their proposed method. Knowingly misrepresenting the work of others is a violation of the code of ethics (\u201cStrive to achieve high quality in both the processes and products of professional work\u201d). The authors should include all the relevant results with attribution.</p>"},{"location":"resources/ethical-review-recommendations/#examples-of-ethics-reviews-that-do-not-adhere-to-the-above-guidelines-with-comments-on-what-is-wrong","title":"Examples of ethics reviews that do **not** adhere to the above guidelines (with comments on what is wrong)","text":"<p>The authors didn\u2019t pay their annotators at least \u00a38.91 / hour, which is the minimum wage in the UK. This means they didn\u2019t \u201cManage personnel and resources to enhance the quality of working life\u201d.</p> <pre><code>-&gt; The minimum wage in the UK is not a global minimum wage. An ethics reviewer could inquire if the authors paid the annotators at least \u201ca local living minimum wage\u201d.\n</code></pre> <p>There is no documentation of IRB approval for this research.         </p> <pre><code>-&gt; The specific term \u201cIRB\u201d applies to research conducted by USA-based researchers or in the USA that has federal funding and involves human participants only. It is not a universal regulation. An ethics reviewer could ask, if the research involves human participants - particularly in a high stakes setting such as medical care - whether the authors had worked with an ethics review board.\n</code></pre> <p>This work will lead to biases in how medical diagnoses are made.</p> <pre><code>-&gt; Good problem statement, but incomplete: what part of the ACL code of ethics is violated, and how might the authors address or correct this?\n</code></pre> <p>This model achieves only 60% accuracy on this data set, even though the authors have deployed it in the educational system in their country. That means that they haven\u2019t followed the ethical rule to \u201ctake special care of systems that become integrated into the infrastructure of society\u201d. They should withdraw the model from use, or insist on a human in the loop at all times.</p> <pre><code>-&gt; Depending on the nature of the model, 60% accuracy may very well be state of the art, and the model may have documented utility even at that level of accuracy. If there is an issue of ethical practice here - and contemporary NLP researchers may disagree - the authors should perhaps discuss how they are going to mitigate the weaknesses of the model; a human in the loop is one possibility, but not the only one.\n</code></pre>"},{"location":"resources/ethical-review-recommendations/#5-recommendations-for-authors-and-reviewers","title":"5. Recommendations for authors and reviewers","text":""},{"location":"resources/ethical-review-recommendations/#guidelines-for-flagging-papers-for-ethics-review","title":"Guidelines for Flagging Papers for Ethics Review","text":"<p>Based on: LINK. (the introductory paragraph was adapted by FD, but the \u201cwhat to avoid?\u201d and \u201ccommon misconceptions\u201d were simply pasted as I find them very clear as they are)</p> <p>Ethics reviews are essential to ensure that academic research maintains integrity and responsibility. The number of submissions keeps increasing every year, and we must ensure that all papers adhere to ethical standards, rules, and regulations. Reviewers and action editors have the responsibility to flag papers that may need an in-depth ethics review (which will be performed by an ethics reviewer). The rest of this section provides guidelines for flagging papers for ethics review. More precisely, we list bad practices in ethics flagging, that result in false flags. Over-flagging should be avoided as it burdens the review process by overloading ethics reviewers.</p>"},{"location":"resources/ethical-review-recommendations/#what-to-avoid","title":"What to avoid?","text":"<ol> <li>No justification: If you are flagging a paper for full ethics review, please try to give a clear and succinct justification so that ethics chairs can appropriately assign ethics reviewers for the paper. A huge majority of papers still get flagged without the justification field being filled in, or left as \u201cN/A\u201d, \u201cNone\u201d, \u201cNo ethical concerns\u201d etc. This unnecessarily adds to the workload of the ethics chairs and reviewers.</li> <li>Flagging for Missing Section(s): Another substantial number of papers get incorrectly flagged because of missing ethical considerations section, or missing limitations section, or incompletely/incorrectly filled Responsible AI checklist. While these issues may need to be flagged to the AE\u2019s attention, and in some cases may justify desk rejection (in case of Limitations section for certain conferences), they do not justify a full ethics review. For ACL conferences, these issues can be flagged in the \"reviewer checklist\". Similarly, adding an ethical considerations section is not mandatory; however if you believe there are specific ethical issues that warrant a full review, please flag the paper and provide a clear justification.</li> <li>Flagging for Copyright, Consent, Transparency: While it is important to ensure that ARR process correctly flags submissions that may be in violation of copyright policies of datasets used, inadequate informed consent process, or transparency of presented artifacts, these issues in and of themselves do not justify a fuller ethics review. Instead, since you have already identified the issue, you can call out the authors in your review or meta review itself to address these issues. However, if there are aspects that require a deeper look, you can of course flag it for a full ethics review, outlining the concern.</li> </ol>"},{"location":"resources/ethical-review-recommendations/#common-misconceptions","title":"Common Misconceptions","text":"<ol> <li>All Data-centric Papers require Ethics Review: A common misstep is assuming that any paper discussing data usage needs a full ethics review. This is **not** the case. Instead, focus should be on potential misuse or unethical handling of data. A mere description of data usage does not automatically warrant an in-depth review.</li> <li>Use of Human Annotators require Ethics Review: The involvement of human annotators in a study does **not** on its own justify an ethics review. However, if there are specific concerns about the human annotation step, such as potential exploitation or ethical lapses, these may warrant an in-depth ethics review.</li> <li>All Datasets on Sensitive Topics require Ethics Review: Datasets that feature critical content, such as misinformation detection, might raise eyebrows due to their potential dual use. But again, the mere presence of such content does not automatically demand a full ethics review. If it involves engaging with specific marginalized communities (e.g., linguistic minorities) or if the content of the annotation involves potentially traumatizing data (e.g., involving hate speech or other gory concepts), then it may justify an in-depth ethics review to assess whether adequate safeguards were taken. In such cases, explain your reasons as justification while flagging for ethics review.</li> <li>All Papers on High-stakes Domains require Ethics Review: While all of NLP research can arguably have downstream human impact, data/methodological innovations on high-stakes domains may have an immediate impact on users or communities. These include educational use cases such as automated grading scenarios, or medical use cases such as in psychotherapy, or legal use cases such as criminality prediction. These may also include challenges in de-identification in high-stakes domains such as healthcare. However, just because a paper focuses on such a high-stakes domain doesn\u2019t by default necessitate a full ethics review. What matters is the context and application of the research. If regulations have been followed and necessary precautions taken, and these are detailed in the paper, then sensitive research areas can be explored without automatically qualifying for a full ethics review.</li> <li>All Papers on NLP ethics require Ethics Review: A paper engaging with questions on NLP ethics and fairness in and of itself does not justify an in-depth ethics review. However, many of these papers do tend to engage with topics that are potentially sensitive and may sometimes need an in-depth review. But this determination should be based on such additional contexts, rather than merely for the topic being NLP ethics.</li> </ol>"},{"location":"resources/ethical-review-recommendations/#checklist-for-responsible-nlp-research","title":"Checklist for Responsible NLP Research","text":"<p>Most questions in this (checklist) address the kinds of information that is often asked by reviewers (e.g. experimental details, annotation protocols, IRB approval, etc.). For every submission, it checks whether the authors describe the limitations and potential risks of the work. If there\u2019re scientific artifacts, it checks if the authors cite the creators of artifacts, and if the authors discuss the license or terms for use or distribution of any artifacts, if the use of existing artifact(s) was consistent with their intended use, the steps taken to check whether the data that was collected or used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect or anonymize it. Moreover, it checks for documentation and statistics description of the artifacts. When computational experiments are conducted, it checks if the authors report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used, discuss the experimental setup, including hyperparameter search and best-found hyperparameter values, report descriptive statistics about the results, and use any existing packages. For work involving human participants, it checks whether the authors report the full text of instructions given to participants, report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, discuss if such payment is adequate, discuss whether and how consent was obtained, get approval or exempt for the data collection protocol from an ethics review board, as well as report the basic demographic and geographic characteristics of the annotator population that is the source of the data. On top of that, it checks for the use of AI assistants for the work submitted. This allows the checklist to serve as a kind of FAQ for the reviewers, pre-empting questions that would otherwise be asked in the author response period. Reviewers are asked to use the checklist information as one of the factors in their evaluation.</p>"},{"location":"resources/ethical-review-recommendations/#ethical-concerns-examples","title":"Ethical concerns examples","text":"<p>Ethics cannot be \u201cone size fits all\u201d as it is often about dealing with dilemmas, details that change the nature of the problem, evaluation biases, etc. We therefore do not want to provide an ethics checklist, which would give the false impression that everything is in it and that your research is ethical provided you checked all the boxes. Instead we believe ethics is about thinking differently about one\u2019s research and the ethical considerations section is here for authors to detail this part of their work.</p> <p>We provide here some examples of ethical concerns that should be addressed, which are not exhaustive in any way.</p>"},{"location":"resources/ethical-review-recommendations/#data-collectioncreation","title":"Data collection/creation","text":""},{"location":"resources/ethical-review-recommendations/#microworkers-remuneration","title":"Microworkers remuneration","text":"<p>In case microworking crowdsourcing was used, the paper should state how a fair rate of pay was determined and how the researchers ensured that crowd workers were compensated fairly.</p>"},{"location":"resources/ethical-review-recommendations/#scraping-datasets","title":"Scraping Datasets","text":"<p>A distinction should be made between reusing existing scraped datasets (without redistributing them) and scraping new ones (with the intent to distribute them). </p>"},{"location":"resources/ethical-review-recommendations/#identity-characteristics","title":"Identity characteristics","text":"<p>Well-known pitfalls in this area that should be avoided: treating identity characteristics as something which can be reliably ascribed (e.g. based on names) and also essential properties of humans and drawn from fixed sets.</p>"},{"location":"resources/ethical-review-recommendations/#environmental-impact","title":"Environmental impact","text":"<p>Emerging best practices include calculating how much energy a given experiment or methodology requires and publishing that information.</p>"},{"location":"resources/ethical-review-recommendations/#appendix","title":"Appendix","text":""},{"location":"resources/ethical-review-recommendations/#temporary-temporally-sensitive-bugs","title":"Temporary, temporally sensitive bugs","text":"<p>The setup for platforms such as SoftConf or OpenReview should be meticulously prepared and thoroughly tested before implementation. Unfortunately, this was not the case for LREC-COLING, leading to several challenges:</p> <ul> <li>Submissions flagged for ethical issues had to be manually copied (or shared) to the \"Ethics Review Track\" by program committee chairs multiple times.</li> <li>Ethical issues reported by technical reviewers were not accessible to ethical reviewers. Instead, they had to be downloaded into a spreadsheet by track chairs, necessitating the maintenance of an external document.</li> <li>Due to the restriction of only one meta-review per submission, ethics chairs were unable to enter meta-reviews of ethics assessments.</li> <li>Submissions within the \"Ethics Review Track\" were also associated with another technical track. This created confusion for area chairs of technical tracks, as they were unable to distinguish reviewers assigned by ethics review chairs.</li> <li>It would be very, very helpful if there is an explicit additional functionality that could make managing Ethics flagged papers and their workflow directly in Openreview (instead of keeping things in spreadsheets)</li> <li>It would help with ethics review planning to clarify ahead of the conference how involved/available ARR ethics chairs can be for the specific event. Technical processes can also be shared with the conference ethics chairs ahead of time as it is not intuitive to understand what happens through Open Review and what has to be handled separately.</li> <li>2/ the ability to be notified when ethics reviews are submitted. Currently, there is no other way for chairs to check that than accessing the paper channel on Open Review. 3/ the ability to communicate with ethics reviewers through Open Review, including some way for reviewers to differentiate notifications pertaining to scientific vs. ethics reviewing. </li> </ul>"},{"location":"resources/ethical-review-recommendations/#other-suggestions-to-facilitate-ethics-chairs-work","title":"Other suggestions to facilitate ethics chairs\u2019 work","text":"<ul> <li>Clarify the extent of the ethics committee action: does it include the workshops? The demo or industry papers? The conditional-accept papers shepherding?</li> <li>We recommend that a checkbox on the submission form be provided to allow authors to aver that they have legally binding permission to publish their data; and to indemnify the ACL and committees for any legal repercussions.</li> <li>Review scheduling should incorporate the ethics review process from the initial planning stages. Streamlining the sharing of submissions flagged for ethics issues with the ethics committee would greatly enhance efficiency.</li> </ul>"},{"location":"resources/ethics-reading-list/","title":"Ethics Union Bibliography","text":"<p>A list of ethics related resources for researchers and practitioners of Natural Language Processing and Computational Linguistics.  This is a public list moderated by the current ACL Ethics Committee.  Please issue a pull request against the repository to have your suggestions discussed before they are approved for integration with the list.  Thanks!</p> <p>This list is intentionally kept with simple formatting in Markdown to allow machine-readable processing of the resource.</p>"},{"location":"resources/ethics-reading-list/#guidelines","title":"Guidelines","text":"<ul> <li>Add your name to the contributors section as part of your PR.  Include an affiliation and a weblink if you'd like.</li> <li>References follow a two-tier organization: by year, then by first-author surname.  #tag papers with topics so that they can be found on a per topic basis.</li> <li>Use APA style where possible.  Confine references to a single line.</li> <li>Add minimally a <code>paper</code> link to direct readers directly to the <code>.pdf</code> or metadata page (ACL Anthology for example) of the paper.</li> <li>Papers are organized by tags.  We accept PRs to add or re-organize tags.  Please help tag your own papers!</li> <li>Tags for topics: starting with <code>t</code></li> <li>Tags for bibliographic type: starting with <code>type</code></li> <li>Simply copy the tags from the below #tags section to tag, ordering tags alphabetically and putting topic tags before type ones.</li> <li>Tags are provided using the shields.io service</li> <li>Prefer peer-reviewed conference or journal reference to link to ArXiv whenever possible.</li> </ul>"},{"location":"resources/ethics-reading-list/#contributed-by","title":"Contributed by","text":"<p>(put in alpha order by surname)</p> <ul> <li>Luciana Benotti (Universidad Nacional de C\u00f3rdoba)</li> <li>Fanny Ducel (Universit\u00e9 Paris-Saclay)</li> <li>Kar\u00ebn Fort (Sorbonne Universit\u00e9 and LORIA)</li> <li>Min-Yen Kan (National University of Singapore)</li> <li>Yisong Miao (National University of Singapore)</li> <li>Isar Nejadgholi (National Research Council Canada)</li> <li>Aur\u00e9lie N\u00e9v\u00e9ol (CNRS, Universit\u00e9 Paris-Saclay)</li> <li>Yulia Tsvetkov (University of Washington)</li> <li>Keenan Samway (Max Planck Institute for Intelligent Systems)</li> <li>Matthew Shardlow (Manchester Metropolitan University)</li> </ul>"},{"location":"resources/ethics-reading-list/#contents","title":"Contents","text":"<ul> <li>2025</li> <li>2024</li> <li>2023</li> <li>2022</li> <li>2021</li> <li>2020</li> <li>2019</li> <li>2018</li> <li>2017</li> <li>2016</li> <li>2015</li> <li>2014</li> <li>2013</li> <li>2012</li> <li>2011</li> <li>2010</li> <li>2006</li> </ul>"},{"location":"resources/ethics-reading-list/#tags","title":"Tags","text":"<p>We have tagged papers with several topic tags and bibliographic type.  You can click on these images to get to per-topic or per-type filtered versions of this list (automatically produced on new pushes to the repository).  These are indicative tags and not comprehensive.  We accept pull requests to change them!</p>"},{"location":"resources/ethics-reading-list/#by-topic","title":"By Topic","text":""},{"location":"resources/ethics-reading-list/#by-bibliographic-type","title":"By Bibliographic Type","text":""},{"location":"resources/ethics-reading-list/#2025","title":"2025","text":"<p>[Contents]</p> <ul> <li> <p>Chen, Y., Raghuram, V. C., Mattern, J., Mihalcea, R., &amp; Jin, Z. (2025). Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias. In Findings of the Association for Computational Linguistics: NAACL 2025, pages 4984\u20135004, Albuquerque, New Mexico. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Ducel, F., Hiebel, N., Ferret, O., Fort, K., &amp; N\u00e9v\u00e9ol, A. (2025). \u201cWomen do not have heart attacks!\" Gender Biases in Automatically Generated Clinical Cases in French. Findings of the Association for Computational Linguistics: NAACL 2025:7145\u20137159. [paper]  </p> </li> <li> <p>Jin, Z., Levine, S., Kleiman-Weiner, M., Piatti, G., Liu, J., Adauto, F.G., Ortu, F., Strausz, A., Sachan, M., Mihalcea, R., Choi, Y., &amp; Scholkopf, B. (2024). Language Model Alignment in Multilingual Trolley Problems. International Conference on Learning Representations. [paper]  </p> </li> <li> <p>Luccioni, S., Strubell, E., &amp; Crawford, K. (2025). From Efficiency Gains to Rebound Effects: The Problem of Jevons' Paradox in AI's Polarized Environmental Debate. Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25):76\u201388. [paper]  </p> </li> <li> <p>Mihalcea, R., Ignat, O., Bai, L., Borah, A., Chiruzzo, L., Jin, Z., Kwizera, C., Nwatu, J., Poria, S., &amp; Solorio, T. (2025). Why AI Is WEIRD and Shouldn\u2019t Be This Way: Towards AI for Everyone, with Everyone, by Everyone. Proceedings of the AAAI Conference on Artificial Intelligence, 39(27), 28657-28670. [paper]  </p> </li> <li> <p>Mitchell, M., Attanasio, G., Baldini, I., Clinciu, M., Clive, J., Delobelle, P., Dey, M., Hamilton, S., Dill, T., Doughman, J., Dutt, R., Ghosh, A., Zosa Forde, J., Holtermann, C., Kaffee, L. A., Laud, T., Lauscher, A., Lopez-Davila, R. L., Masoud, M., Nangia, N., Ovalle, A., Pistilli, G., Radev, D., Savoldi, B., Raheja, V., Qin, J., Ploeger, E., Subramonian, A., Dhole, K., Sun, K., Djanibekov, A., Mansurov, J., Yin, K., Villa Cueva, E., Mukherjee, S., Huang, J., Shen, X., Gala, J., Al-Ali, H., Djanibekov, T., Mukhituly, N., Nie, S., Sharma, S., Stanczak, K., Szczechla, E., Timponi Torrent, T., Tunuguntla, D., Viridiano, M., Van Der Wal, O., Yakefu, A., N\u00e9v\u00e9ol, A., Zhang, M., Zink, S., &amp; Talat, Z. (2025). SHADES: Towards a Multilingual Assessment of Stereotypes in Large Language Models. Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), 2025:11995\u201312041.  [paper]  </p> </li> <li> <p>Morand, C., N\u00e9v\u00e9ol, A., &amp; Ligozat, A. L. (2025). Does Efficiency Lead to Green Machine Learning Model Training? Analyzing Historical Trends in Impacts from Hardware, Algorithmic and Carbon Optimizations. [paper]   </p> </li> <li> <p>Varoquaux, G., Luccioni, S., &amp; Whittaker, M. (2025). Hype, Sustainability, and the Price of the Bigger-is-Better Paradigm in AI. In Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25):61\u201375  [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2024","title":"2024","text":"<p>[Contents]</p> <ul> <li> <p>Curry, A. C., Attanasio, G., Talat, Z. &amp; Hovy, D. (2024, August). Classist Tools: Social Class Correlates with Performance in NLP. In Proceedings of the 62<sup>nd</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12643\u201312655, Bangkok, Thailand. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Ducel F, N\u00e9v\u00e9ol A, Fort K. (2024). \u201cYou\u2019ll be a nurse, my son!\u201d Automatically assessing gender biases in autoregressive language models in French and Italian. Language Resources and Evaluation. Springer, Berlin Heidelberg, Germany. 2024:1-29 [paper]  </p> </li> <li> <p>Helm, P., Bella, G., Koch, G. et al. (2024). Diversity and language technology: how language modeling bias causes epistemic injustice. Ethics and Information Technology.  [paper]  </p> </li> <li> <p>Hofmann, V., Kalluri, P.R., Jurafsky, D. et al. (2024). AI generates covertly racist decisions about people based on their dialect. Nature 633, 147\u2013154. https://doi.org/10.1038/s41586-024-07856-5   </p> </li> <li> <p>Jin, Z., Heil, N., Liu, J., Dhuliawala, S., Qi, Y., Sch\u00f6lkopf, B., Mihalcea, R., &amp; Sachan, M. (2024). Implicit Personalization in Language Models: A Systematic Study. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 12309\u201312325, Miami, Florida, USA. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Jin, Z., Levine, S., Kleiman-Weiner, M., Piatti, G., Liu, J., Adauto, F.G., Ortu, F., Strausz, A., Sachan, M., Mihalcea, R., Choi, Y., &amp; Scholkopf, B. (2024). Language Model Alignment in Multilingual Trolley Problems. International Conference on Learning Representations. [paper]  </p> </li> <li> <p>Kantharuban, A., Milbauer, J., Strubell, E., &amp; Neubig, G. (2024). Stereotype or personalization? user identity biases chatbot recommendations [paper]  </p> </li> <li> <p>Karamolegkou, A., Hansen, S. S., Christopoulou, A., Stamatiou, F., Lauscher, A., &amp; S\u00f8gaard, A. (2024). Ethical Concern Identification in NLP: A Corpus of ACL Anthology Ethics Statements. [paper]  </p> </li> <li> <p>Liu, J., Li, W., Jin, Z., &amp; Diab, M.T. (2024). Automatic Generation of Model and Data Cards: A Step Towards Responsible AI. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 1975\u20131997, Mexico City, Mexico. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Morand C, N\u00e9v\u00e9ol A, Ligozat AL. MLCA: a tool for Machine Learning Life Cycle Assessment. International Conference on ICT for Sustainability (ICT4S). 2024. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2023","title":"2023","text":"<p>[Contents]</p> <ul> <li> <p>Ahia, O., Kumar, S. Gonen, H., Kasai, J., Mortensen, D., Smith, N. &amp; Tsvetkov, Y. (2023, December). Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 9904\u20139923, Singapore. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Coghlan, S., &amp; Parker, C. (2023). Harm to Nonhuman Animals from AI: a Systematic Account and Framework. Philosophy &amp; Technology. [paper]  </p> </li> <li> <p>Gon\u00e7alves, G. &amp; Strubell, E. (2023). Understanding the Effect of Model Compression on Social Bias in Large Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 2663\u20132675, Singapore. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Kirk, H. R., Vidgen, B., R\u00f6ttger, P., Thrush, T., &amp; Hale, S. A. (2023). Hatemoji: A test suite and adversarially-generated dataset for benchmarking and detecting emoji-based hate. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. (NAACL '23') 10.18653/v1/2022.naacl-main.97 [paper]  </p> </li> <li> <p>Li, P., Yang, J., Islam, M. A., &amp; Ren, S. (2023). Making ai less\" thirsty\": Uncovering and addressing the secret water footprint of ai models.  [paper]  </p> </li> <li> <p>Luccioni, S., Jernite, Y. &amp; Strubell, E. (2024). Power Hungry Processing: Watts Driving the Cost of AI Deployment? In Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '24). Association for Computing Machinery, New York, NY, USA, 85\u201399.  [paper]  </p> </li> <li> <p>McMillan-Major, A., Bender, E. M. &amp; Friedman, B. (2023). Data Statements: From Technical Concept to Community Practice, ACM Journal on Responsible Computing. [paper]  </p> </li> <li> <p>Nejadgholi, I., Kiritchenko, S., Fraser, K. C., &amp; Balkir, E. (2023) Concept-Based Explanations to Test for False Causal Relationships Learned by Abusive Language Classifiers. In Proceedings of the 7<sup>th</sup> Workshop on Online Abuse and Harms (WOAH), pages 138\u2013149, Toronto, Canada. Association for Computational Linguistics. [paper]   </p> </li> <li> <p>Parmar, M., Mishra, S., Geva, M., &amp; Baral, C. (2023). Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions. In Proceedings of the 17<sup>th</sup> Conference of the European Chapter of the Association for Computational Linguistics, pages 1779\u20131789. [paper]  </p> </li> <li> <p>Pyatkin, V., Yung, F., Scholman, M. C., Tsarfaty, R., Dagan, I., &amp; Demberg, V. (2023). Design Choices for Crowdsourcing Implicit Discourse Relations: Revealing the Biases Introduced by Task Design. Transaction of Association for Computational Linguistics (TACL '23). [paper]  </p> </li> <li> <p>Vicente, L., &amp; Matute, H. (2023). Humans inherit artificial intelligence biases. Scientific Reports, 13(1), 15737. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2022","title":"2022","text":"<p>[Contents]</p> <ul> <li> <p>Alorwu, A., Savage, S., van Berkel, N., Ustalov, D., Drutsa, A., Oppenlaender, J., Bates, O., Hettiachchi, D., Gadiraju, U., Goncalves, J., &amp; Hosio, S. (2022). REGROW: Reimagining Global Crowdsourcing for Better Human-AI Collaboration. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems (CHI EA '22). Association for Computing Machinery, New York, NY, USA, Article 88, 1\u20137 [paper]  </p> </li> <li> <p>Benotti L, Blackburn P. 2022. Ethics consideration sections in natural language processing papers. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 4509\u20134516, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Balkir, E., Kiritchenko, S., Nejadgholi, I., Fraser, K.C. (2022) Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models. In Proceedings of the 2<sup>nd</sup> Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), pages 80\u201392, Seattle, U.S.A. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Balkir, E., Nejadgholi, I., Fraser, K.C., Kiritchenko, S. (2022). Necessity and Sufficiency for Explaining Text Classifiers: A Case Study in Hate Speech Detection. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2672\u20132686, Seattle, United States. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Chalkidis I., Pasini T., Zhang S., Tomada L., Schwemer S., &amp; S\u00f8gaard A. (2022). FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4389\u20134406, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>D'Ignazio, C. (2022). The Urgency of Moving From Bias to Power. European Data Protection Law Review. Volume 8, Issue 4 (pp. 451 - 454). [paper]  </p> </li> <li> <p>Fraser, K.C., Kiritchenko, S., Balkir, E. (2022) Does Moral Code Have a Moral Code? Probing Delphi's Moral Philosophy. In Proceedings of the 2<sup>nd</sup> Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), pages 26\u201342, Seattle, U.S.A. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Fraser, K.C., Kiritchenko, S., Nejadgholi, I. (2022). Computational Modelling of Stereotype Content in Text. Frontiers in Artificial Intelligence, 5, 2022. doi:10.3389/frai.2022.826207. [paper]  </p> </li> <li> <p>Meade N., Poole-Dayan E., &amp; Reddy S. (2022). An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1878\u20131898, Dublin, Ireland. Association for Computational Linguistics.  [paper]  </p> </li> <li> <p>Meehan C., Mrini K., &amp; Chaudhuri K. (2022). Sentence-level Privacy for Document Embeddings. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3367\u20133380, Dublin, Ireland. Association for Computational Linguistics.  [paper]  </p> </li> <li> <p>Miceli, M., Posada, J., &amp; Yang, T. (2022). Studying up machine learning data: Why talk about bias when we mean power?. Proceedings of the ACM on Human-Computer Interaction, 6(GROUP), 1-14. [paper]   </p> </li> <li> <p>Mohammad, S. (2022). Ethics Sheets for AI Tasks. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8368\u20138379, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Nejadgholi, I., Balkir, E., Fraser, K.C., &amp; Kiritchenko, S. (2022). Towards Procedural Fairness: Uncovering Biases in How a Toxic Language Classifier Uses Sentiment Information.In Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 225\u2013237, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics. [paper]  </p> </li> <li> <p>N\u00e9v\u00e9ol, A., Dupont, Y., Bezan\u00e7on, J., &amp; Fort, K. (2022). French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8521\u20138531, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Przyby\u0142a, P., &amp; Shardlow M. (2022). Using NLP to quantify the environmental cost and diversity benefits of in-person NLP conferences. In Findings of the Association for Computational Linguistics: ACL 2022, pages 3853\u20133863, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Talat, Z., N\u00e9v\u00e9ol, A., Biderman, S., Clinciu, M., Dey, M., Longpre, S., Luccioni, S., Masoud, M., Mitchell, M., Radev, D., Sharma, S., Subramonian, A., Tae, J., Tan, S., Tunuguntla, D. &amp; Van Der Wal, O. (2022). You reap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings. In Proceedings of BigScience Episode #5 -- Workshop on Challenges &amp; Perspectives in Creating Large Language Models, pages 26\u201341, virtual+Dublin. Association for Computational Linguistics. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2021","title":"2021","text":"<p>[Contents]</p> <ul> <li> <p>Abdalla, M. &amp; Abdalla, M. (2021). The Grey Hoodie Project: Big Tobacco, Big Tech, and the Threat on Academic Integrity Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, Association for Computing Machinery, 2021, 287-297. [paper]  </p> </li> <li> <p>Aka, O., Burke, K., B\u00e4uerle, A., Greer, C., &amp; Mitchell, M. (2021). Measuring Model Biases in the Absence of Ground Truth. DOI:10.1145/3461702.3462557. AIES '21: AAAI/ACM Conference on AI, Ethics, and Society. [paper]  </p> </li> <li> <p>Bannour, N., Ghannay, S., N\u00e9v\u00e9ol, A. and Ligozat, A.-L. 2021. Evaluating the carbon footprint of NLP methods: a survey and analysis of existing tools. In Proceedings of the Second Workshop on Simple and Efficient Natural Language Processing, pages 11\u201321, Virtual. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Bender, Emily M., Friedman, B. and McMillan-Major, A. (2021). A Guide for Writing Data Statements for Natural Language Processing [paper]  </p> </li> <li> <p>Bender, E. M., Gebru, T., McMillan-Major, A., &amp; Shmitchell, S. (2021, March). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\ud83e\udd9c. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (pp. 610-623). doi:10.1145/3442188.3445922 [paper]  </p> </li> <li> <p>Birhane, A., Prabhu, V. U., &amp; Kahembwe, E. (2021). Multimodal datasets: misogyny, pornography, and malignant stereotypes. arXiv preprint arXiv:2110.01963. [paper]  </p> </li> <li> <p>Dev, S., Monajatipoor, M., Ovalle, A., Subramonian, A., Phillips, J., and Chang, K. (2021). Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1968\u20131994. [paper]  </p> </li> <li> <p>Dodge, J., Sap, M., Marasovic, A., Agnew, W., Ilharco, G., Groeneveld, D., ... &amp; Face, H. (2021, September). Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1286\u20131305, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Field, A., Blodgett, S. L., Talat, Z., &amp; Tsvetkov, Y. (2021, August). A Survey of Race, Racism, and Anti-Racism in NLP. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1905\u20131925, Online. Association for Computational Linguistics. doi:10.18653/v1/2021.acl-long.149 [paper]  </p> </li> <li> <p>Fraser K. C., Nejadgholi, I. and Kiritchenko, S. (2021). Understanding and Countering Stereotypes: A Computational Approach to the Stereotype Content Model. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 600\u2013616, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Hooker, S. (2021). Moving beyond \u201calgorithmic bias is a data problem\u201d. Patterns, 2(4).[paper]  </p> </li> <li> <p>Kiritchenko, S., Nejadgholi, I., and Fraser, K. C. (2021). Confronting Abusive Language Online: A Survey from the Ethical and Human Rights Perspective. Journal of Artificial Intelligence Research, 71: 431-478, July 2021. doi:10.1613/jair.1.12590. [paper]  </p> </li> <li> <p>Kreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., ... &amp; Adeyemi, M. (2021). Quality at a glance: An audit of web-crawled multilingual datasets.Transactions of the Association for Computational Linguistics, The MIT Press, 2022, 10, pp.50-72. [paper]  </p> </li> <li> <p>Kummerfeld, J. K. (2021). Quantifying and Avoiding Unfair Qualification Labour in Crowdsourcing. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 343\u2013349, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Lannelongue, L., Grealey, J., &amp; Inouye, M. (2021). Green algorithms: Quantifying the carbon footprint of computation. Advanced Science, 2100707. doi:10.1002/advs.202100707. [paper]  </p> </li> <li> <p>Markl, N., &amp; Lai, C. (2021, April). Context-sensitive evaluation of automatic speech recognition: considering user experience &amp; . In Proceedings of the First Workshop on Bridging Human\u2013Computer Interaction and Natural Language Processing (pp. 34-40). [paper]  </p> </li> <li> <p>Moss, E., Watkins, E. A., Singh, R., Elish, M. C., &amp; Metcalf, J. (2021). Assembling Accountability: Algorithmic Impact Assessment for the Public Interest. Available at SSRN 3877437. [paper]  </p> </li> <li> <p>Shmueli, B., Fell, J., Ray, S., &amp; Ku, L. W. (2021). Beyond fair pay: Ethical implications of NLP crowdsourcing. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3758\u20133769, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Tan, S., &amp; Joty, S. (2021). Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. doi:10.18653/v1/2021.naacl-main.282 [paper]  </p> </li> <li> <p>Tan, S., Joty, S., Baxter, K., Taeihagh, A., Bennett, G. A., &amp; Kan, M. Y. (2021). Reliability Testing for Natural Language Processing Systems.  In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4153\u20134169, Online. Association for Computational Linguistics. doi:10.18653/v1/2021.acl-long.321 [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2020","title":"2020","text":"<p>[Contents]</p> <ul> <li> <p>Anthony, L. F. W., Kanding, B., &amp; Selvan, R. (2020). Carbontracker: Tracking and predicting the carbon footprint of training deep learning models. arXiv preprint arXiv:2007.03051. [paper]  </p> </li> <li> <p>Bird, S. (2020, December). Decolonising speech and language technology. In Proceedings of the 28<sup>th</sup> International Conference on Computational Linguistics (pp. 3504-3519). doi:10.18653/v1/2020.coling-main.313 [paper]  </p> </li> <li> <p>Blodgett, S. L., Barocas, S., Daum\u00e9 III, H., &amp; Wallach, H. (2020). Language (technology) is power: A critical survey of \"bias\" in NLP.  In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 5454\u20135476, Online. Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.485. [paper]  </p> </li> <li> <p>Bonastre, J. F. (2020). 1990-2020: retours sur 30 ans d'\u00e9changes autour de l'identification de voix en milieu judiciaire. In 6e conf\u00e9rence conjointe Journ\u00e9es d'\u00c9tudes sur la Parole (JEP, 33e \u00e9dition), Traitement Automatique des Langues Naturelles (TALN, 27e \u00e9dition), Rencontre des \u00c9tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R\u00c9CITAL, 22e \u00e9dition). 2e atelier \u00c9thique et TRaitemeNt Automatique des Langues (ETeRNAL) (pp. 38-47). ATALA; AFCP. [paper]  </p> </li> <li> <p>Caglayan, O., Madhyastha, P., &amp; Specia, L. (2020). Curious case of language generation evaluation metrics: A cautionary tale.  In Proceedings of the 28<sup>th</sup> International Conference on Computational Linguistics, pages 2322\u20132328, Barcelona, Spain (Online). International Committee on Computational Linguistics. doi:10.18653/v1/2020.coling-main.210. [paper]  </p> </li> <li> <p>Ethayarajh, K., &amp; Jurafsky, D. (2020, November). Utility is in the eye of the user: A critique of NLP leaderboards. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) doi:10.18653/v1/2020.emnlp-main.393. [paper]  </p> </li> <li> <p>Floridi, L., Chiriatti, M. GPT-3: Its Nature, Scope, Limits, and Consequences. Minds &amp; Machines 30, 681\u2013694 (2020). https://doi.org/10.1007/s11023-020-09548-1 [paper]  </p> </li> <li> <p>Garnerin, M., Rossato, S., &amp; Besacier, L. (2020). Pratiques d'\u00e9valuation en ASR et biais de performance (Evaluation methodology in ASR and performance bias). In Actes de la 6e conf\u00e9rence conjointe Journ\u00e9es d'\u00c9tudes sur la Parole (JEP, 33e \u00e9dition), Traitement Automatique des Langues Naturelles (TALN, 27e \u00e9dition), Rencontre des \u00c9tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R\u00c9CITAL, 22e \u00e9dition). 2e atelier \u00c9thique et TRaitemeNt Automatique des Langues (ETeRNAL) (pp. 1-9). [paper]  </p> </li> <li> <p>Goldfarb-Tarrant, S., Marchant, R., Sanchez, R. M., Pandya, M., &amp; Lopez, A. (2020). Intrinsic bias metrics do not correlate with application bias. Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers) [paper].  </p> </li> <li> <p>Hagendorff, T. The Ethics of AI Ethics: An Evaluation of Guidelines Minds &amp; Machines, 2020, 30, 99-120. [paper]  </p> </li> <li> <p>Henderson, P., Hu, J., Romoff, J., Brunskill, E., Jurafsky, D., &amp; Pineau, J. (2020). Towards the systematic reporting of the energy and carbon footprints of machine learning. Journal of Machine Learning Research, 21(248), 1-43. [paper]  </p> </li> <li> <p>Jo, E. S., &amp; Gebru, T. (2020, January). Lessons from archives: Strategies for collecting sociocultural data in machine learning. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 306-316). [paper]  </p> </li> <li> <p>Joshi, P., Santy, S., Budhiraja, A., Bali, K., &amp; Choudhury, M. (2020). The state and fate of linguistic diversity and inclusion in the NLP world. In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, 2020, 6282-6293. doi:10.18653/v1/2020.acl-main.560 [paper]  </p> </li> <li> <p>Kalluri P. (2020). Don't ask if artificial intelligence is good or fair, ask how it shifts power. Nature, 583(7815), 169. [paper]  </p> </li> <li> <p>Koenecke, A., Nam, A., Lake, E., Nudell, J., Quartey, M., Mengesha, Z., ... &amp; Goel, S. (2020). Racial disparities in automated speech recognition. Proceedings of the National Academy of Sciences, 117(14), 7684-7689. [paper]  </p> </li> <li> <p>Kulynych, B., Overdorf, R., Troncoso, C., &amp; G\u00fcrses, S. (2020). POTs: protective optimization technologies. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT* '20). Association for Computing Machinery, New York, NY, USA, 177\u2013188. DOI:https://doi.org/10.1145/3351095.3372853. [paper]  </p> </li> <li> <p>Leins, K. Lau, J. H., &amp; Baldwin, T. (2020, July). Give Me Convenience and Give Her Death: Who Should Decide What Uses of NLP are Appropriate, and on What Basis?. In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (pp 2908\u20132913) [paper]  </p> </li> <li> <p>Linzen, T. (2020, July). How can we accelerate progress towards human-like linguistic generalization?.  Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.465 [paper]  </p> </li> <li> <p>Mathur, N., Baldwin, T., &amp; Cohn, T. (2020, July). Tangled up in BLEU: Reevaluating the evaluation of automatic machine translation evaluation metrics.  Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.448 [paper]  </p> </li> <li> <p>Mohammad, S. M. (2020, July). Gender gap in natural language processing research: Disparities in authorship and citations. Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.702 [paper]  </p> </li> <li> <p>Nangia, N., Vania, C., Bhalerao, R., &amp; Bowman, S. R. (2020, November). CrowS-pairs: A challenge dataset for measuring social biases in masked language models. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP).  doi:10.18653/v1/2020.emnlp-main.154 [paper]  </p> </li> <li> <p>Nissim, M., van Noord, R., &amp; van der Goot, R. (2020). Fair is better than sensational: Man is to doctor as woman is to doctor. Computational Linguistics, 46(2), 487-497. doi:10.1162/coli_a_00379 [paper]  </p> </li> <li> <p>Paullada, A., Raji, I. D., Bender, E. M., Denton, E., &amp; Hanna, A. (2020). Data and its (dis) contents: A survey of dataset development and use in machine learning research. Patterns, Volume 2, Issue 11, 12 November 2021, Pages 100388. [paper]  </p> </li> <li> <p>Schneider, J. M., Rehm, G., Montiel-Ponsoda, E., Doncel, V. R., Revenko, A., Karampatakis, S., ... &amp; Maganza, F. (2020, May). Orchestrating NLP Services for the Legal Domain. In Proceedings of the 12<sup>th</sup> Language Resources and Evaluation Conference (pp. 2332-2340). [paper]  </p> </li> <li> <p>Schwartz, R., Dodge, J., Smith, N. A., &amp; Etzioni, O. (2020). Green AI. Communications of the ACM, 63(12), 54-63. [paper]  </p> </li> <li> <p>Tan, S., Joty, S., Kan, M. Y., &amp; Socher, R. (2020, July). It's Morphin'Time! Combating Linguistic Discrimination with Inflectional Perturbations. Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Tan, S., Joty, S., Varshney, L. R., &amp; Kan, M. Y. (2020, November). Mind your inflections! Improving NLP for non-standard Englishes with Base-Inflection Encoding. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). [paper]  </p> </li> <li> <p>Trebaol, M. J. T., Hartley, M.-A., &amp; Ghadikolaei, H. S. (2020). A tool to quantify and report the carbon footprint of machine learning computations and communication in academia and healthcare. Infoscience EPFL: record 278189. [report]  </p> </li> <li> <p>Vidgen, B., &amp; Derczynski, L. (2020). Directions in abusive language training data, a systematic review: Garbage in, garbage out. PloS one, 15(12), e0243300. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2019","title":"2019","text":"<p>[Contents]</p> <ul> <li> <p>Bender, E. M. (2019). The # benderrule: On naming the languages we study and why it matters. The Gradient, 14. [paper]  </p> </li> <li> <p>Bregeon, D., Antoine, J. Y., Villaneau, J., &amp; Lefeuvre-Halftermeyer, A. (2019). Redonner du sens \u00e0 l'accord interannotateurs: vers une interpr\u00e9tation des mesures d'accord en termes de reproductibilit\u00e9 de l'annotation. Traitement Automatique des Langues, 60(2), 23.  [paper]  </p> </li> <li> <p>Garimella, A., Banea, C., Hovy, D., &amp; Mihalcea, R. (2019, July). Women's syntactic resilience and men's grammatical luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing. In Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (pp. 3493-3498). [paper]  </p> </li> <li> <p>Green, B. (2019). \"Good\" isn't good enough. In Proceedings of the AI for Social Good workshop at NeurIPS. [paper]  </p> </li> <li> <p>Hara, K.; Adams, A.; Milland, K.; Savage, S.; Hanrahan, B. V.; Bigham, J. P. &amp; Callison-Burch, C. (2019). Worker Demographics and Earnings on Amazon Mechanical Turk: An Exploratory Analysis Association for Computing Machinery, 1-6. [paper]  </p> </li> <li> <p>Huang, X., &amp; Paul, M. (2019, June). Neural user factor adaptation for text classification: Learning to generalize across author demographics. In Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (* SEM 2019) (pp. 136-146). [paper]  </p> </li> <li> <p>Kann, K., Cho, K., &amp; Bowman, S. R. (2019). Towards realistic practices in low-resource natural language processing: the development set. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9<sup>th</sup> International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3342\u20133349, Hong Kong, China. Association for Computational Linguistics. doi:10.18653/v1/D19-1329 [paper]  </p> </li> <li> <p>Lacoste A., Luccioni A., Schmidt V., &amp; Dandres T. (2019). Quantifying the carbon emissions of machine learning. In Climate Change workshop, NeurIPS 2019. [paper]  </p> </li> <li> <p>Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., ... &amp; Gebru, T. (2019, January). Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency (pp. 220-229). [paper]  </p> </li> <li> <p>Monteiro, M. (2019). Ruined by design: How designers destroyed the world, and what we can do to fix it. Mule Design.  </p> </li> <li> <p>Raji, I. D., &amp; Yang, J. (2019). About ML: Annotation and benchmarking on understanding and transparency of machine learning lifecycles. arXiv preprint arXiv:1912.06166. [paper]  </p> </li> <li> <p>Sap, M., Gabriel, S., Qin, L., Jurafsky, D., Smith, N. A., &amp; Choi, Y. (2019). Social bias frames: Reasoning about social and power implications of language.  In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 5477\u20135490, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Strubell, E., Ganesh, A., &amp; McCallum, A. (2019). Energy and policy considerations for deep learning in NLP. In Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 3645\u20133650, Florence, Italy. Association for Computational Linguistics. doi:10.18653/v1/P19-1355. [paper]  </p> </li> <li> <p>Zmigrod, R., Mielke, S. J., Wallach, H., &amp; Cotterell, R. (2019). Counterfactual data augmentation for mitigating gender stereotypes in languages with rich morphology. In Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 1651\u20131661, Florence, Italy. Association for Computational Linguistics. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2018","title":"2018","text":"<p>[Contents]</p> <ul> <li>Bender, E. M., &amp; Friedman, B. (2018). Data statements for natural language processing: Toward mitigating system bias and enabling better science. Transactions of the Association for Computational Linguistics, 6, 587-604 doi:10.1162/tacl_a_00041 [paper]  </li> </ul> <ul> <li> <p>Curry, A. C., &amp; Rieser, V. (2018, June). # MeToo Alexa: How conversational systems respond to sexual harassment. In Proceedings of the second ACL workshop on ethics in natural language processing (pp. 7-14). [paper]  </p> </li> <li> <p>Fort, K., &amp; N\u00e9v\u00e9ol, A. (2018, January). Pr\u00e9sence et repr\u00e9sentation des femmes dans le traitement automatique des langues en France. In Penser la Recherche en Informatique comme pouvant \u00eatre Situ\u00e9e, Multidisciplinaire Et Genr\u00e9e (PRISME-G). [paper]  </p> </li> <li> <p>Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Daum\u00e9 III, H., &amp; Crawford, K. (2018). Datasheets for datasets. Commun. ACM 64, 12 (December 2021), 86\u201392. DOI:https://doi.org/10.1145/3458723. [paper]  </p> </li> <li> <p>Hara, K.; Adams, A.; Milland, K.; Savage, S.; Callison-Burch, C. &amp; Bigham, J. P. (2018). A Data-Driven Analysis of Workers' Earnings on Amazon Mechanical Turk CHI 2018. [paper]  </p> </li> <li> <p>Holland, S., Hosny, A., Newman, S., Joseph, J., &amp; Chmielinski, K. (2018). The dataset nutrition label: A framework to drive higher data quality standards. arXiv preprint arXiv:1805.03677. [paper]  </p> </li> <li> <p>Kiritchenko S. and Mohammad S. (2018). Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems. In Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, pages 43\u201353, New Orleans, Louisiana. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Schluter, N. (2018). The glass ceiling in NLP. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 2793-2798). doi:10.18653/v1/D18-1301 [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2017","title":"2017","text":"<p>[Contents]</p> <ul> <li> <p>Caliskan, A., Bryson, J. J., &amp; Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. Science, 356(6334), 183-186.  </p> </li> <li> <p>Jurgens, D., Tsvetkov, Y., &amp; Jurafsky, D. (2017, July). Incorporating dialectal variability for socially equitable language identification. In Proceedings of the 55<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 51-57). [paper]  </p> </li> <li> <p>Koolen, C. &amp; van Cranenburgh, A. These are not the Stereotypes You are Looking For: Bias and Fairness in Authorial Gender Attribution. In Proceedings of the first ACL workshop on ethics in natural language processing (pp. 12-22). [paper]  </p> </li> <li> <p>Larson, B. (2017). Gender as a Variable in Natural-Language Processing: Ethical Considerations. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 1\u201311). [paper]  </p> </li> <li> <p>Leidner, J. L. &amp; Plachouras, V. Ethical by Design: Ethics Best Practices for Natural Language Processing. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, Association for Computational Linguistics, 2017, 30-40.  [paper]  </p> </li> <li> <p>Mieskes, M. (2017, April). A quantitative study of data in the NLP community. In Proceedings of the first ACL workshop on ethics in natural language processing (pp. 23-29). [paper]  </p> </li> <li> <p>Parra Escartin, C.; Reijers, W.; Lynn, T.; Moorkens, J.; Way, A. &amp; Liu, C.-H. Ethical Considerations in NLP Shared Tasks. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, Association for Computational Linguistics, 2017, 66-73.  [paper]  </p> </li> <li> <p>Rudinger, R., May, C., &amp; Van Durme, B. (2017, April). Social bias in elicited natural language inferences. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 74-79). [paper]  </p> </li> <li> <p>\u0160uster, S., Tulkens, S., &amp; Daelemans, W. (2017). A short review of ethical challenges in clinical natural language processing.  In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing. [paper]  </p> </li> <li> <p>Tatman, R. (2017, April). Gender and dialect bias in YouTube's automatic captions. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 53-59). [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2016","title":"2016","text":"<p>[Contents]</p> <ul> <li>Amblard, M. (2016). Pour un TAL responsable. Traitement Automatique des Langues, 57(2), 21-45. [paper]  </li> </ul> <ul> <li> <p>Cohen, K. B.; Fort, K.; Adda, G.; Zhou, S. &amp; Farri, D. Ethical Issues in Corpus Linguistics And Annotation: Pay Per Hit Does Not Affect Effective Hourly Rate For Linguistic Resource Development On Amazon Mechanical Turk ETHics In Corpus collection, Annotation and Application workshop, 2016. [paper]  </p> </li> <li> <p>Fort, K., &amp; Couillault, A. (2016, May). Yes, we care! results of the ethics and natural language processing surveys. In international Language Resources and Evaluation Conference (LREC) 2016. [paper]  </p> </li> <li> <p>Hovy, D., &amp; Spruit, S. L. (2016, August). The social impact of natural language processing. In Proceedings of the 54<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 591-598) doi:10.18653/v1/P16-2096. [paper]  </p> </li> <li> <p>Larson, J., Angwin, J., &amp; Parris, T. (2016). Breaking the black box: How machines learn to be racist. ProPublica. [paper]  </p> </li> <li> <p>Lefeuvre-Halftermeyer, A., Govaere, V., Antoine, J. Y., Allegre, W., Pouplin, S., Departe, J. P., ... &amp; Spagnulo, A. (2016). Typologie des risques pour une analyse \u00e9thique de l'impact des technologies du TAL. Traitement Automatique des Langues, 57(2), 47-71. [paper]  </p> </li> <li> <p>Mathet, Y., &amp; Widl\u00f6cher, A. (2016). \u00c9valuation des annotations: ses principes et ses pi\u00e8ges. Traitement Automatique des Langues, 57(2), 73-98. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2015","title":"2015","text":"<p>[Contents]</p> <ul> <li> <p>Bretonnel Cohen, K.; Pestian, J. P. &amp; Fort, K. (2015, June). Annotating suicide notes : ethical issues at a glance. In Proc. of ETeRNAL (Ethique et Traitement Automatique des Langues), Caen, France. [paper]  </p> </li> <li> <p>Ferraro, F., Mostafazadeh, N., Vanderwende, L., Devlin, J., Galley, M., &amp; Mitchell, M. (2015). A survey of current datasets for vision and language research.  In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 207\u2013213, Lisbon, Portugal. Association for Computational Linguistics. doi:10.18653/v1/D15-1021 [paper]  </p> </li> <li> <p>Hovy, D., &amp; S\u00f8gaard, A. (2015, July). Tagging performance correlates with author age. In Proceedings of the 53<sup>rd</sup> annual meeting of the Association for Computational Linguistics and the 7<sup>th</sup> international joint conference on natural language processing (volume 2: Short papers) (pp. 483-488). [paper]  </p> </li> <li> <p>J\u00f8rgensen, A., Hovy, D., &amp; S\u00f8gaard, A. (2015, July). Challenges of studying and processing dialects in social media. In Proceedings of the workshop on noisy user-generated text (pp. 9-18). [paper]  </p> </li> <li> <p>Lefeuvre A., Antoine J-Y., Allegre W. Ethique cons\u00e9quentialiste et traitement automatique des langues : une typologie de facteurs de risques adapt\u00e9e aux technologies langagi\u00e8res. Atelier Ethique et TRaitemeNt Automatique des Langues (ETeRNAL'2015), conf\u00e9rence TALN'2015, Jun 2015, Caen, France. pp.53-66. \u27e8hal-01170630\u27e9 [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2014","title":"2014","text":"<p>[Contents]</p> <ul> <li> <p>Callison-Burch, C. (2014, September). Crowd-workers: Aggregating information across turkers to help them find higher paying work. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing (Vol. 2, No. 1). [paper]  </p> </li> <li> <p>Couillault, A., Fort, K., Adda, G., &amp; De Mazancourt, H. (2014, May). Evaluating corpora documentation with regards to the ethics and big data charter. In International Conference on Language Resources and Evaluation (LREC). [paper]  </p> </li> <li> <p>Fort K., Adda G., Sagot B., Mariani J., Couillault A.. Crowdsourcing for Language Resource Development: Criticisms About Amazon Mechanical Turk Overpowering Use. Vetulani, Zygmunt and Mariani, Joseph. Human Language Technology Challenges for Computer Science and Linguistics, 8387, Springer International Publishing, pp.303-314, 2014, Lecture Notes in Computer Science, 978-3-319-08957-7. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2013","title":"2013","text":"<p>[Contents]</p> <ul> <li>Irani, L. C., &amp; Silberman, M. S. (2013, April). Turkopticon: Interrupting worker invisibility in amazon mechanical turk. In Proceedings of the SIGCHI conference on human factors in computing systems (pp. 611-620). [paper]  </li> </ul>"},{"location":"resources/ethics-reading-list/#2012","title":"2012","text":"<p>[Contents]</p> <ul> <li>Wagstaff, K. (2012). Machine learning that matters. In Proceedings of the 29<sup>th</sup> International Coference on International Conference on Machine Learning (ICML'12). [paper]  </li> </ul>"},{"location":"resources/ethics-reading-list/#2011","title":"2011","text":"<p>[Contents]</p> <ul> <li> <p>Bederson, B. B., &amp; Quinn, A. J. (2011). Web workers unite! addressing challenges of online laborers. In CHI'11 Extended Abstracts on Human Factors in Computing Systems (pp. 97-106).  </p> </li> <li> <p>Fort, K., Adda, G., &amp; Cohen, K. B. (2011). Amazon Mechanical Turk: Gold mine or coal mine?. Computational Linguistics, 37(2), 413-420. doi:10.1162/COLI_a_00057 [paper]  </p> </li> <li> <p>Kenny, D. The ethics of machine translation. (2011). New Zealand Society of Translators and Interpreters Annual Conference 2011. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2010","title":"2010","text":"<p>[Contents]</p> <ul> <li> <p>Adda, G. &amp; Mariani, J. (2010). Language resources and Amazon Mechanical Turk: legal, ethical and other issues. Proceedings of Legal Issues for Sharing Language Resources workshop in International Conference on Language Resources and Evaluation (LREC), European Language Resources Association (ELRA). [paper]  </p> </li> <li> <p>Drugan, J. &amp; Babych, B. (2010). Shared Resources, Shared Values? Ethical Implications of Sharing Translation Resources. Proceedings of the Second Joint EM+/CNGL Workshop: Bringing MT to the User: Research on Integrating MT in the Translation Industry, Association for Machine Translation in the Americas, 3-10. [paper]  </p> </li> <li> <p>Snyder, J. (2010). Exploitation and sweatshop labor: Perspectives and issues. Business Ethics Quarterly, 20(2), 187-213. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/#2006","title":"2006","text":"<p>[Contents]</p> <ul> <li>Kacmarcik, G., &amp; Gamon, M. (2006, July). Obfuscating document stylometry to preserve author anonymity. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions (pp. 444-451). [paper]  </li> </ul>"},{"location":"resources/ethics-reading-list/t-biases/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Chen, Y., Raghuram, V. C., Mattern, J., Mihalcea, R., &amp; Jin, Z. (2025). Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias. In Findings of the Association for Computational Linguistics: NAACL 2025, pages 4984\u20135004, Albuquerque, New Mexico. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Ducel, F., Hiebel, N., Ferret, O., Fort, K., &amp; N\u00e9v\u00e9ol, A. (2025). \u201cWomen do not have heart attacks!\" Gender Biases in Automatically Generated Clinical Cases in French. Findings of the Association for Computational Linguistics: NAACL 2025:7145\u20137159. [paper]  </p> </li> <li> <p>Jin, Z., Levine, S., Kleiman-Weiner, M., Piatti, G., Liu, J., Adauto, F.G., Ortu, F., Strausz, A., Sachan, M., Mihalcea, R., Choi, Y., &amp; Scholkopf, B. (2024). Language Model Alignment in Multilingual Trolley Problems. International Conference on Learning Representations. [paper]  </p> </li> <li> <p>Mitchell, M., Attanasio, G., Baldini, I., Clinciu, M., Clive, J., Delobelle, P., Dey, M., Hamilton, S., Dill, T., Doughman, J., Dutt, R., Ghosh, A., Zosa Forde, J., Holtermann, C., Kaffee, L. A., Laud, T., Lauscher, A., Lopez-Davila, R. L., Masoud, M., Nangia, N., Ovalle, A., Pistilli, G., Radev, D., Savoldi, B., Raheja, V., Qin, J., Ploeger, E., Subramonian, A., Dhole, K., Sun, K., Djanibekov, A., Mansurov, J., Yin, K., Villa Cueva, E., Mukherjee, S., Huang, J., Shen, X., Gala, J., Al-Ali, H., Djanibekov, T., Mukhituly, N., Nie, S., Sharma, S., Stanczak, K., Szczechla, E., Timponi Torrent, T., Tunuguntla, D., Viridiano, M., Van Der Wal, O., Yakefu, A., N\u00e9v\u00e9ol, A., Zhang, M., Zink, S., &amp; Talat, Z. (2025). SHADES: Towards a Multilingual Assessment of Stereotypes in Large Language Models. Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), 2025:11995\u201312041.  [paper]  </p> </li> <li> <p>Curry, A. C., Attanasio, G., Talat, Z. &amp; Hovy, D. (2024, August). Classist Tools: Social Class Correlates with Performance in NLP. In Proceedings of the 62<sup>nd</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12643\u201312655, Bangkok, Thailand. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Ducel F, N\u00e9v\u00e9ol A, Fort K. (2024). \u201cYou\u2019ll be a nurse, my son!\u201d Automatically assessing gender biases in autoregressive language models in French and Italian. Language Resources and Evaluation. Springer, Berlin Heidelberg, Germany. 2024:1-29 [paper]  </p> </li> <li> <p>Helm, P., Bella, G., Koch, G. et al. (2024). Diversity and language technology: how language modeling bias causes epistemic injustice. Ethics and Information Technology.  [paper]  </p> </li> <li> <p>Hofmann, V., Kalluri, P.R., Jurafsky, D. et al. (2024). AI generates covertly racist decisions about people based on their dialect. Nature 633, 147\u2013154. https://doi.org/10.1038/s41586-024-07856-5   </p> </li> <li> <p>Jin, Z., Heil, N., Liu, J., Dhuliawala, S., Qi, Y., Sch\u00f6lkopf, B., Mihalcea, R., &amp; Sachan, M. (2024). Implicit Personalization in Language Models: A Systematic Study. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 12309\u201312325, Miami, Florida, USA. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Jin, Z., Levine, S., Kleiman-Weiner, M., Piatti, G., Liu, J., Adauto, F.G., Ortu, F., Strausz, A., Sachan, M., Mihalcea, R., Choi, Y., &amp; Scholkopf, B. (2024). Language Model Alignment in Multilingual Trolley Problems. International Conference on Learning Representations. [paper]  </p> </li> <li> <p>Kantharuban, A., Milbauer, J., Strubell, E., &amp; Neubig, G. (2024). Stereotype or personalization? user identity biases chatbot recommendations [paper]  </p> </li> <li> <p>Gon\u00e7alves, G. &amp; Strubell, E. (2023). Understanding the Effect of Model Compression on Social Bias in Large Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 2663\u20132675, Singapore. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Kirk, H. R., Vidgen, B., R\u00f6ttger, P., Thrush, T., &amp; Hale, S. A. (2023). Hatemoji: A test suite and adversarially-generated dataset for benchmarking and detecting emoji-based hate. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. (NAACL '23') 10.18653/v1/2022.naacl-main.97 [paper]  </p> </li> <li> <p>Nejadgholi, I., Kiritchenko, S., Fraser, K. C., &amp; Balkir, E. (2023) Concept-Based Explanations to Test for False Causal Relationships Learned by Abusive Language Classifiers. In Proceedings of the 7<sup>th</sup> Workshop on Online Abuse and Harms (WOAH), pages 138\u2013149, Toronto, Canada. Association for Computational Linguistics. [paper]   </p> </li> <li> <p>Parmar, M., Mishra, S., Geva, M., &amp; Baral, C. (2023). Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions. In Proceedings of the 17<sup>th</sup> Conference of the European Chapter of the Association for Computational Linguistics, pages 1779\u20131789. [paper]  </p> </li> <li> <p>Vicente, L., &amp; Matute, H. (2023). Humans inherit artificial intelligence biases. Scientific Reports, 13(1), 15737. [paper]  </p> </li> <li> <p>Balkir, E., Kiritchenko, S., Nejadgholi, I., Fraser, K.C. (2022) Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models. In Proceedings of the 2<sup>nd</sup> Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), pages 80\u201392, Seattle, U.S.A. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Balkir, E., Nejadgholi, I., Fraser, K.C., Kiritchenko, S. (2022). Necessity and Sufficiency for Explaining Text Classifiers: A Case Study in Hate Speech Detection. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2672\u20132686, Seattle, United States. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Chalkidis I., Pasini T., Zhang S., Tomada L., Schwemer S., &amp; S\u00f8gaard A. (2022). FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4389\u20134406, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>D'Ignazio, C. (2022). The Urgency of Moving From Bias to Power. European Data Protection Law Review. Volume 8, Issue 4 (pp. 451 - 454). [paper]  </p> </li> <li> <p>Fraser, K.C., Kiritchenko, S., Nejadgholi, I. (2022). Computational Modelling of Stereotype Content in Text. Frontiers in Artificial Intelligence, 5, 2022. doi:10.3389/frai.2022.826207. [paper]  </p> </li> <li> <p>Meade N., Poole-Dayan E., &amp; Reddy S. (2022). An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1878\u20131898, Dublin, Ireland. Association for Computational Linguistics.  [paper]  </p> </li> <li> <p>Miceli, M., Posada, J., &amp; Yang, T. (2022). Studying up machine learning data: Why talk about bias when we mean power?. Proceedings of the ACM on Human-Computer Interaction, 6(GROUP), 1-14. [paper]   </p> </li> <li> <p>Nejadgholi, I., Balkir, E., Fraser, K.C., &amp; Kiritchenko, S. (2022). Towards Procedural Fairness: Uncovering Biases in How a Toxic Language Classifier Uses Sentiment Information.In Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 225\u2013237, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics. [paper]  </p> </li> <li> <p>N\u00e9v\u00e9ol, A., Dupont, Y., Bezan\u00e7on, J., &amp; Fort, K. (2022). French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8521\u20138531, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Talat, Z., N\u00e9v\u00e9ol, A., Biderman, S., Clinciu, M., Dey, M., Longpre, S., Luccioni, S., Masoud, M., Mitchell, M., Radev, D., Sharma, S., Subramonian, A., Tae, J., Tan, S., Tunuguntla, D. &amp; Van Der Wal, O. (2022). You reap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings. In Proceedings of BigScience Episode #5 -- Workshop on Challenges &amp; Perspectives in Creating Large Language Models, pages 26\u201341, virtual+Dublin. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Aka, O., Burke, K., B\u00e4uerle, A., Greer, C., &amp; Mitchell, M. (2021). Measuring Model Biases in the Absence of Ground Truth. DOI:10.1145/3461702.3462557. AIES '21: AAAI/ACM Conference on AI, Ethics, and Society. [paper]  </p> </li> <li> <p>Bender, E. M., Gebru, T., McMillan-Major, A., &amp; Shmitchell, S. (2021, March). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\ud83e\udd9c. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (pp. 610-623). doi:10.1145/3442188.3445922 [paper]  </p> </li> <li> <p>Dev, S., Monajatipoor, M., Ovalle, A., Subramonian, A., Phillips, J., and Chang, K. (2021). Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1968\u20131994. [paper]  </p> </li> <li> <p>Field, A., Blodgett, S. L., Talat, Z., &amp; Tsvetkov, Y. (2021, August). A Survey of Race, Racism, and Anti-Racism in NLP. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1905\u20131925, Online. Association for Computational Linguistics. doi:10.18653/v1/2021.acl-long.149 [paper]  </p> </li> <li> <p>Fraser K. C., Nejadgholi, I. and Kiritchenko, S. (2021). Understanding and Countering Stereotypes: A Computational Approach to the Stereotype Content Model. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 600\u2013616, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Hooker, S. (2021). Moving beyond \u201calgorithmic bias is a data problem\u201d. Patterns, 2(4).[paper]  </p> </li> <li> <p>Blodgett, S. L., Barocas, S., Daum\u00e9 III, H., &amp; Wallach, H. (2020). Language (technology) is power: A critical survey of \"bias\" in NLP.  In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 5454\u20135476, Online. Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.485. [paper]  </p> </li> <li> <p>Mohammad, S. M. (2020, July). Gender gap in natural language processing research: Disparities in authorship and citations. Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.702 [paper]  </p> </li> <li> <p>Nissim, M., van Noord, R., &amp; van der Goot, R. (2020). Fair is better than sensational: Man is to doctor as woman is to doctor. Computational Linguistics, 46(2), 487-497. doi:10.1162/coli_a_00379 [paper]  </p> </li> <li> <p>Garimella, A., Banea, C., Hovy, D., &amp; Mihalcea, R. (2019, July). Women's syntactic resilience and men's grammatical luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing. In Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (pp. 3493-3498). [paper]  </p> </li> <li> <p>Sap, M., Gabriel, S., Qin, L., Jurafsky, D., Smith, N. A., &amp; Choi, Y. (2019). Social bias frames: Reasoning about social and power implications of language.  In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 5477\u20135490, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Curry, A. C., &amp; Rieser, V. (2018, June). # MeToo Alexa: How conversational systems respond to sexual harassment. In Proceedings of the second ACL workshop on ethics in natural language processing (pp. 7-14). [paper]  </p> </li> <li> <p>Fort, K., &amp; N\u00e9v\u00e9ol, A. (2018, January). Pr\u00e9sence et repr\u00e9sentation des femmes dans le traitement automatique des langues en France. In Penser la Recherche en Informatique comme pouvant \u00eatre Situ\u00e9e, Multidisciplinaire Et Genr\u00e9e (PRISME-G). [paper]  </p> </li> <li> <p>Kiritchenko S. and Mohammad S. (2018). Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems. In Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, pages 43\u201353, New Orleans, Louisiana. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Schluter, N. (2018). The glass ceiling in NLP. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 2793-2798). doi:10.18653/v1/D18-1301 [paper]  </p> </li> <li> <p>Koolen, C. &amp; van Cranenburgh, A. These are not the Stereotypes You are Looking For: Bias and Fairness in Authorial Gender Attribution. In Proceedings of the first ACL workshop on ethics in natural language processing (pp. 12-22). [paper]  </p> </li> <li> <p>Rudinger, R., May, C., &amp; Van Durme, B. (2017, April). Social bias in elicited natural language inferences. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 74-79). [paper]  </p> </li> </ul> <ul> <li>Larson, J., Angwin, J., &amp; Parris, T. (2016). Breaking the black box: How machines learn to be racist. ProPublica. [paper]  </li> </ul>"},{"location":"resources/ethics-reading-list/t-crowdsourcing-issues/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Mihalcea, R., Ignat, O., Bai, L., Borah, A., Chiruzzo, L., Jin, Z., Kwizera, C., Nwatu, J., Poria, S., &amp; Solorio, T. (2025). Why AI Is WEIRD and Shouldn\u2019t Be This Way: Towards AI for Everyone, with Everyone, by Everyone. Proceedings of the AAAI Conference on Artificial Intelligence, 39(27), 28657-28670. [paper]  </p> </li> <li> <p>Pyatkin, V., Yung, F., Scholman, M. C., Tsarfaty, R., Dagan, I., &amp; Demberg, V. (2023). Design Choices for Crowdsourcing Implicit Discourse Relations: Revealing the Biases Introduced by Task Design. Transaction of Association for Computational Linguistics (TACL '23). [paper]  </p> </li> <li> <p>Alorwu, A., Savage, S., van Berkel, N., Ustalov, D., Drutsa, A., Oppenlaender, J., Bates, O., Hettiachchi, D., Gadiraju, U., Goncalves, J., &amp; Hosio, S. (2022). REGROW: Reimagining Global Crowdsourcing for Better Human-AI Collaboration. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems (CHI EA '22). Association for Computing Machinery, New York, NY, USA, Article 88, 1\u20137 [paper]  </p> </li> <li> <p>Kreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., ... &amp; Adeyemi, M. (2021). Quality at a glance: An audit of web-crawled multilingual datasets.Transactions of the Association for Computational Linguistics, The MIT Press, 2022, 10, pp.50-72. [paper]  </p> </li> <li> <p>Kummerfeld, J. K. (2021). Quantifying and Avoiding Unfair Qualification Labour in Crowdsourcing. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 343\u2013349, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Shmueli, B., Fell, J., Ray, S., &amp; Ku, L. W. (2021). Beyond fair pay: Ethical implications of NLP crowdsourcing. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3758\u20133769, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Hara, K.; Adams, A.; Milland, K.; Savage, S.; Hanrahan, B. V.; Bigham, J. P. &amp; Callison-Burch, C. (2019). Worker Demographics and Earnings on Amazon Mechanical Turk: An Exploratory Analysis Association for Computing Machinery, 1-6. [paper]  </p> </li> <li> <p>Hara, K.; Adams, A.; Milland, K.; Savage, S.; Callison-Burch, C. &amp; Bigham, J. P. (2018). A Data-Driven Analysis of Workers' Earnings on Amazon Mechanical Turk CHI 2018. [paper]  </p> </li> <li> <p>Cohen, K. B.; Fort, K.; Adda, G.; Zhou, S. &amp; Farri, D. Ethical Issues in Corpus Linguistics And Annotation: Pay Per Hit Does Not Affect Effective Hourly Rate For Linguistic Resource Development On Amazon Mechanical Turk ETHics In Corpus collection, Annotation and Application workshop, 2016. [paper]  </p> </li> <li> <p>Callison-Burch, C. (2014, September). Crowd-workers: Aggregating information across turkers to help them find higher paying work. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing (Vol. 2, No. 1). [paper]  </p> </li> <li> <p>Fort K., Adda G., Sagot B., Mariani J., Couillault A.. Crowdsourcing for Language Resource Development: Criticisms About Amazon Mechanical Turk Overpowering Use. Vetulani, Zygmunt and Mariani, Joseph. Human Language Technology Challenges for Computer Science and Linguistics, 8387, Springer International Publishing, pp.303-314, 2014, Lecture Notes in Computer Science, 978-3-319-08957-7. [paper]  </p> </li> <li> <p>Irani, L. C., &amp; Silberman, M. S. (2013, April). Turkopticon: Interrupting worker invisibility in amazon mechanical turk. In Proceedings of the SIGCHI conference on human factors in computing systems (pp. 611-620). [paper]  </p> </li> <li> <p>Bederson, B. B., &amp; Quinn, A. J. (2011). Web workers unite! addressing challenges of online laborers. In CHI'11 Extended Abstracts on Human Factors in Computing Systems (pp. 97-106).  </p> </li> <li> <p>Fort, K., Adda, G., &amp; Cohen, K. B. (2011). Amazon Mechanical Turk: Gold mine or coal mine?. Computational Linguistics, 37(2), 413-420. doi:10.1162/COLI_a_00057 [paper]  </p> </li> <li> <p>Adda, G. &amp; Mariani, J. (2010). Language resources and Amazon Mechanical Turk: legal, ethical and other issues. Proceedings of Legal Issues for Sharing Language Resources workshop in International Conference on Language Resources and Evaluation (LREC), European Language Resources Association (ELRA). [paper]  </p> </li> <li> <p>Snyder, J. (2010). Exploitation and sweatshop labor: Perspectives and issues. Business Ethics Quarterly, 20(2), 187-213. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/t-data/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Mihalcea, R., Ignat, O., Bai, L., Borah, A., Chiruzzo, L., Jin, Z., Kwizera, C., Nwatu, J., Poria, S., &amp; Solorio, T. (2025). Why AI Is WEIRD and Shouldn\u2019t Be This Way: Towards AI for Everyone, with Everyone, by Everyone. Proceedings of the AAAI Conference on Artificial Intelligence, 39(27), 28657-28670. [paper]  </p> </li> <li> <p>Liu, J., Li, W., Jin, Z., &amp; Diab, M.T. (2024). Automatic Generation of Model and Data Cards: A Step Towards Responsible AI. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 1975\u20131997, Mexico City, Mexico. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>McMillan-Major, A., Bender, E. M. &amp; Friedman, B. (2023). Data Statements: From Technical Concept to Community Practice, ACM Journal on Responsible Computing. [paper]  </p> </li> <li> <p>Bender, Emily M., Friedman, B. and McMillan-Major, A. (2021). A Guide for Writing Data Statements for Natural Language Processing [paper]  </p> </li> <li> <p>Birhane, A., Prabhu, V. U., &amp; Kahembwe, E. (2021). Multimodal datasets: misogyny, pornography, and malignant stereotypes. arXiv preprint arXiv:2110.01963. [paper]  </p> </li> <li> <p>Dodge, J., Sap, M., Marasovic, A., Agnew, W., Ilharco, G., Groeneveld, D., ... &amp; Face, H. (2021, September). Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1286\u20131305, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Moss, E., Watkins, E. A., Singh, R., Elish, M. C., &amp; Metcalf, J. (2021). Assembling Accountability: Algorithmic Impact Assessment for the Public Interest. Available at SSRN 3877437. [paper]  </p> </li> <li> <p>Bird, S. (2020, December). Decolonising speech and language technology. In Proceedings of the 28<sup>th</sup> International Conference on Computational Linguistics (pp. 3504-3519). doi:10.18653/v1/2020.coling-main.313 [paper]  </p> </li> <li> <p>Jo, E. S., &amp; Gebru, T. (2020, January). Lessons from archives: Strategies for collecting sociocultural data in machine learning. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 306-316). [paper]  </p> </li> <li> <p>Joshi, P., Santy, S., Budhiraja, A., Bali, K., &amp; Choudhury, M. (2020). The state and fate of linguistic diversity and inclusion in the NLP world. In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, 2020, 6282-6293. doi:10.18653/v1/2020.acl-main.560 [paper]  </p> </li> <li> <p>Paullada, A., Raji, I. D., Bender, E. M., Denton, E., &amp; Hanna, A. (2020). Data and its (dis) contents: A survey of dataset development and use in machine learning research. Patterns, Volume 2, Issue 11, 12 November 2021, Pages 100388. [paper]  </p> </li> <li> <p>Vidgen, B., &amp; Derczynski, L. (2020). Directions in abusive language training data, a systematic review: Garbage in, garbage out. PloS one, 15(12), e0243300. [paper]  </p> </li> <li> <p>Kann, K., Cho, K., &amp; Bowman, S. R. (2019). Towards realistic practices in low-resource natural language processing: the development set. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9<sup>th</sup> International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3342\u20133349, Hong Kong, China. Association for Computational Linguistics. doi:10.18653/v1/D19-1329 [paper]  </p> </li> <li> <p>Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., ... &amp; Gebru, T. (2019, January). Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency (pp. 220-229). [paper]  </p> </li> <li> <p>Raji, I. D., &amp; Yang, J. (2019). About ML: Annotation and benchmarking on understanding and transparency of machine learning lifecycles. arXiv preprint arXiv:1912.06166. [paper]  </p> </li> <li> <p>Bender, E. M., &amp; Friedman, B. (2018). Data statements for natural language processing: Toward mitigating system bias and enabling better science. Transactions of the Association for Computational Linguistics, 6, 587-604 doi:10.1162/tacl_a_00041 [paper]  </p> </li> <li> <p>Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Daum\u00e9 III, H., &amp; Crawford, K. (2018). Datasheets for datasets. Commun. ACM 64, 12 (December 2021), 86\u201392. DOI:https://doi.org/10.1145/3458723. [paper]  </p> </li> <li> <p>Holland, S., Hosny, A., Newman, S., Joseph, J., &amp; Chmielinski, K. (2018). The dataset nutrition label: A framework to drive higher data quality standards. arXiv preprint arXiv:1805.03677. [paper]  </p> </li> <li> <p>Mieskes, M. (2017, April). A quantitative study of data in the NLP community. In Proceedings of the first ACL workshop on ethics in natural language processing (pp. 23-29). [paper]  </p> </li> <li> <p>Bretonnel Cohen, K.; Pestian, J. P. &amp; Fort, K. (2015, June). Annotating suicide notes : ethical issues at a glance. In Proc. of ETeRNAL (Ethique et Traitement Automatique des Langues), Caen, France. [paper]  </p> </li> <li> <p>Couillault, A., Fort, K., Adda, G., &amp; De Mazancourt, H. (2014, May). Evaluating corpora documentation with regards to the ethics and big data charter. In International Conference on Language Resources and Evaluation (LREC). [paper]  </p> </li> <li> <p>Drugan, J. &amp; Babych, B. (2010). Shared Resources, Shared Values? Ethical Implications of Sharing Translation Resources. Proceedings of the Second Joint EM+/CNGL Workshop: Bringing MT to the User: Research on Integrating MT in the Translation Industry, Association for Machine Translation in the Americas, 3-10. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/t-dual-use/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Bonastre, J. F. (2020). 1990-2020: retours sur 30 ans d'\u00e9changes autour de l'identification de voix en milieu judiciaire. In 6e conf\u00e9rence conjointe Journ\u00e9es d'\u00c9tudes sur la Parole (JEP, 33e \u00e9dition), Traitement Automatique des Langues Naturelles (TALN, 27e \u00e9dition), Rencontre des \u00c9tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R\u00c9CITAL, 22e \u00e9dition). 2e atelier \u00c9thique et TRaitemeNt Automatique des Langues (ETeRNAL) (pp. 38-47). ATALA; AFCP. [paper]  </p> </li> <li> <p>Kacmarcik, G., &amp; Gamon, M. (2006, July). Obfuscating document stylometry to preserve author anonymity. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions (pp. 444-451). [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/t-environmental-impact/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Luccioni, S., Strubell, E., &amp; Crawford, K. (2025). From Efficiency Gains to Rebound Effects: The Problem of Jevons' Paradox in AI's Polarized Environmental Debate. Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25):76\u201388. [paper]  </p> </li> <li> <p>Morand, C., N\u00e9v\u00e9ol, A., &amp; Ligozat, A. L. (2025). Does Efficiency Lead to Green Machine Learning Model Training? Analyzing Historical Trends in Impacts from Hardware, Algorithmic and Carbon Optimizations. [paper]   </p> </li> <li> <p>Varoquaux, G., Luccioni, S., &amp; Whittaker, M. (2025). Hype, Sustainability, and the Price of the Bigger-is-Better Paradigm in AI. In Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25):61\u201375  [paper]  </p> </li> <li> <p>Morand C, N\u00e9v\u00e9ol A, Ligozat AL. MLCA: a tool for Machine Learning Life Cycle Assessment. International Conference on ICT for Sustainability (ICT4S). 2024. [paper]  </p> </li> <li> <p>Li, P., Yang, J., Islam, M. A., &amp; Ren, S. (2023). Making ai less\" thirsty\": Uncovering and addressing the secret water footprint of ai models.  [paper]  </p> </li> <li> <p>Luccioni, S., Jernite, Y. &amp; Strubell, E. (2024). Power Hungry Processing: Watts Driving the Cost of AI Deployment? In Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '24). Association for Computing Machinery, New York, NY, USA, 85\u201399.  [paper]  </p> </li> <li> <p>Przyby\u0142a, P., &amp; Shardlow M. (2022). Using NLP to quantify the environmental cost and diversity benefits of in-person NLP conferences. In Findings of the Association for Computational Linguistics: ACL 2022, pages 3853\u20133863, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Bannour, N., Ghannay, S., N\u00e9v\u00e9ol, A. and Ligozat, A.-L. 2021. Evaluating the carbon footprint of NLP methods: a survey and analysis of existing tools. In Proceedings of the Second Workshop on Simple and Efficient Natural Language Processing, pages 11\u201321, Virtual. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Lannelongue, L., Grealey, J., &amp; Inouye, M. (2021). Green algorithms: Quantifying the carbon footprint of computation. Advanced Science, 2100707. doi:10.1002/advs.202100707. [paper]  </p> </li> <li> <p>Anthony, L. F. W., Kanding, B., &amp; Selvan, R. (2020). Carbontracker: Tracking and predicting the carbon footprint of training deep learning models. arXiv preprint arXiv:2007.03051. [paper]  </p> </li> <li> <p>Henderson, P., Hu, J., Romoff, J., Brunskill, E., Jurafsky, D., &amp; Pineau, J. (2020). Towards the systematic reporting of the energy and carbon footprints of machine learning. Journal of Machine Learning Research, 21(248), 1-43. [paper]  </p> </li> <li> <p>Schwartz, R., Dodge, J., Smith, N. A., &amp; Etzioni, O. (2020). Green AI. Communications of the ACM, 63(12), 54-63. [paper]  </p> </li> <li> <p>Trebaol, M. J. T., Hartley, M.-A., &amp; Ghadikolaei, H. S. (2020). A tool to quantify and report the carbon footprint of machine learning computations and communication in academia and healthcare. Infoscience EPFL: record 278189. [report]  </p> </li> <li> <p>Lacoste A., Luccioni A., Schmidt V., &amp; Dandres T. (2019). Quantifying the carbon emissions of machine learning. In Climate Change workshop, NeurIPS 2019. [paper]  </p> </li> <li> <p>Strubell, E., Ganesh, A., &amp; McCallum, A. (2019). Energy and policy considerations for deep learning in NLP. In Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 3645\u20133650, Florence, Italy. Association for Computational Linguistics. doi:10.18653/v1/P19-1355. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/t-evaluation/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Ducel F, N\u00e9v\u00e9ol A, Fort K. (2024). \u201cYou\u2019ll be a nurse, my son!\u201d Automatically assessing gender biases in autoregressive language models in French and Italian. Language Resources and Evaluation. Springer, Berlin Heidelberg, Germany. 2024:1-29 [paper]  </p> </li> <li> <p>Kirk, H. R., Vidgen, B., R\u00f6ttger, P., Thrush, T., &amp; Hale, S. A. (2023). Hatemoji: A test suite and adversarially-generated dataset for benchmarking and detecting emoji-based hate. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. (NAACL '23') 10.18653/v1/2022.naacl-main.97 [paper]  </p> </li> <li> <p>Tan, S., Joty, S., Baxter, K., Taeihagh, A., Bennett, G. A., &amp; Kan, M. Y. (2021). Reliability Testing for Natural Language Processing Systems.  In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4153\u20134169, Online. Association for Computational Linguistics. doi:10.18653/v1/2021.acl-long.321 [paper]  </p> </li> <li> <p>Caglayan, O., Madhyastha, P., &amp; Specia, L. (2020). Curious case of language generation evaluation metrics: A cautionary tale.  In Proceedings of the 28<sup>th</sup> International Conference on Computational Linguistics, pages 2322\u20132328, Barcelona, Spain (Online). International Committee on Computational Linguistics. doi:10.18653/v1/2020.coling-main.210. [paper]  </p> </li> <li> <p>Ethayarajh, K., &amp; Jurafsky, D. (2020, November). Utility is in the eye of the user: A critique of NLP leaderboards. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) doi:10.18653/v1/2020.emnlp-main.393. [paper]  </p> </li> <li> <p>Garnerin, M., Rossato, S., &amp; Besacier, L. (2020). Pratiques d'\u00e9valuation en ASR et biais de performance (Evaluation methodology in ASR and performance bias). In Actes de la 6e conf\u00e9rence conjointe Journ\u00e9es d'\u00c9tudes sur la Parole (JEP, 33e \u00e9dition), Traitement Automatique des Langues Naturelles (TALN, 27e \u00e9dition), Rencontre des \u00c9tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R\u00c9CITAL, 22e \u00e9dition). 2e atelier \u00c9thique et TRaitemeNt Automatique des Langues (ETeRNAL) (pp. 1-9). [paper]  </p> </li> <li> <p>Goldfarb-Tarrant, S., Marchant, R., Sanchez, R. M., Pandya, M., &amp; Lopez, A. (2020). Intrinsic bias metrics do not correlate with application bias. Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers) [paper].  </p> </li> <li> <p>Linzen, T. (2020, July). How can we accelerate progress towards human-like linguistic generalization?.  Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.465 [paper]  </p> </li> <li> <p>Mathur, N., Baldwin, T., &amp; Cohn, T. (2020, July). Tangled up in BLEU: Reevaluating the evaluation of automatic machine translation evaluation metrics.  Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.448 [paper]  </p> </li> <li> <p>Nangia, N., Vania, C., Bhalerao, R., &amp; Bowman, S. R. (2020, November). CrowS-pairs: A challenge dataset for measuring social biases in masked language models. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP).  doi:10.18653/v1/2020.emnlp-main.154 [paper]  </p> </li> <li> <p>Bregeon, D., Antoine, J. Y., Villaneau, J., &amp; Lefeuvre-Halftermeyer, A. (2019). Redonner du sens \u00e0 l'accord interannotateurs: vers une interpr\u00e9tation des mesures d'accord en termes de reproductibilit\u00e9 de l'annotation. Traitement Automatique des Langues, 60(2), 23.  [paper]  </p> </li> <li> <p>Caliskan, A., Bryson, J. J., &amp; Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. Science, 356(6334), 183-186.  </p> </li> <li> <p>Mathet, Y., &amp; Widl\u00f6cher, A. (2016). \u00c9valuation des annotations: ses principes et ses pi\u00e8ges. Traitement Automatique des Langues, 57(2), 73-98. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/t-general-resources/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Karamolegkou, A., Hansen, S. S., Christopoulou, A., Stamatiou, F., Lauscher, A., &amp; S\u00f8gaard, A. (2024). Ethical Concern Identification in NLP: A Corpus of ACL Anthology Ethics Statements. [paper]  </p> </li> <li> <p>Liu, J., Li, W., Jin, Z., &amp; Diab, M.T. (2024). Automatic Generation of Model and Data Cards: A Step Towards Responsible AI. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 1975\u20131997, Mexico City, Mexico. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Coghlan, S., &amp; Parker, C. (2023). Harm to Nonhuman Animals from AI: a Systematic Account and Framework. Philosophy &amp; Technology. [paper]  </p> </li> <li> <p>Benotti L, Blackburn P. 2022. Ethics consideration sections in natural language processing papers. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 4509\u20134516, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Fraser, K.C., Kiritchenko, S., Balkir, E. (2022) Does Moral Code Have a Moral Code? Probing Delphi's Moral Philosophy. In Proceedings of the 2<sup>nd</sup> Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), pages 26\u201342, Seattle, U.S.A. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Mohammad, S. (2022). Ethics Sheets for AI Tasks. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8368\u20138379, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Abdalla, M. &amp; Abdalla, M. (2021). The Grey Hoodie Project: Big Tobacco, Big Tech, and the Threat on Academic Integrity Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, Association for Computing Machinery, 2021, 287-297. [paper]  </p> </li> <li> <p>Kiritchenko, S., Nejadgholi, I., and Fraser, K. C. (2021). Confronting Abusive Language Online: A Survey from the Ethical and Human Rights Perspective. Journal of Artificial Intelligence Research, 71: 431-478, July 2021. doi:10.1613/jair.1.12590. [paper]  </p> </li> <li> <p>Hagendorff, T. The Ethics of AI Ethics: An Evaluation of Guidelines Minds &amp; Machines, 2020, 30, 99-120. [paper]  </p> </li> <li> <p>Kalluri P. (2020). Don't ask if artificial intelligence is good or fair, ask how it shifts power. Nature, 583(7815), 169. [paper]  </p> </li> <li> <p>Kulynych, B., Overdorf, R., Troncoso, C., &amp; G\u00fcrses, S. (2020). POTs: protective optimization technologies. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT* '20). Association for Computing Machinery, New York, NY, USA, 177\u2013188. DOI:https://doi.org/10.1145/3351095.3372853. [paper]  </p> </li> <li> <p>Leins, K. Lau, J. H., &amp; Baldwin, T. (2020, July). Give Me Convenience and Give Her Death: Who Should Decide What Uses of NLP are Appropriate, and on What Basis?. In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (pp 2908\u20132913) [paper]  </p> </li> <li> <p>Green, B. (2019). \"Good\" isn't good enough. In Proceedings of the AI for Social Good workshop at NeurIPS. [paper]  </p> </li> <li> <p>Monteiro, M. (2019). Ruined by design: How designers destroyed the world, and what we can do to fix it. Mule Design.  </p> </li> <li> <p>Larson, B. (2017). Gender as a Variable in Natural-Language Processing: Ethical Considerations. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 1\u201311). [paper]  </p> </li> <li> <p>Leidner, J. L. &amp; Plachouras, V. Ethical by Design: Ethics Best Practices for Natural Language Processing. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, Association for Computational Linguistics, 2017, 30-40.  [paper]  </p> </li> <li> <p>Parra Escartin, C.; Reijers, W.; Lynn, T.; Moorkens, J.; Way, A. &amp; Liu, C.-H. Ethical Considerations in NLP Shared Tasks. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, Association for Computational Linguistics, 2017, 66-73.  [paper]  </p> </li> <li> <p>\u0160uster, S., Tulkens, S., &amp; Daelemans, W. (2017). A short review of ethical challenges in clinical natural language processing.  In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing. [paper]  </p> </li> <li> <p>Amblard, M. (2016). Pour un TAL responsable. Traitement Automatique des Langues, 57(2), 21-45. [paper]  </p> </li> <li> <p>Fort, K., &amp; Couillault, A. (2016, May). Yes, we care! results of the ethics and natural language processing surveys. In international Language Resources and Evaluation Conference (LREC) 2016. [paper]  </p> </li> <li> <p>Hovy, D., &amp; Spruit, S. L. (2016, August). The social impact of natural language processing. In Proceedings of the 54<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 591-598) doi:10.18653/v1/P16-2096. [paper]  </p> </li> <li> <p>Lefeuvre-Halftermeyer, A., Govaere, V., Antoine, J. Y., Allegre, W., Pouplin, S., Departe, J. P., ... &amp; Spagnulo, A. (2016). Typologie des risques pour une analyse \u00e9thique de l'impact des technologies du TAL. Traitement Automatique des Langues, 57(2), 47-71. [paper]  </p> </li> <li> <p>Ferraro, F., Mostafazadeh, N., Vanderwende, L., Devlin, J., Galley, M., &amp; Mitchell, M. (2015). A survey of current datasets for vision and language research.  In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 207\u2013213, Lisbon, Portugal. Association for Computational Linguistics. doi:10.18653/v1/D15-1021 [paper]  </p> </li> <li> <p>Lefeuvre A., Antoine J-Y., Allegre W. Ethique cons\u00e9quentialiste et traitement automatique des langues : une typologie de facteurs de risques adapt\u00e9e aux technologies langagi\u00e8res. Atelier Ethique et TRaitemeNt Automatique des Langues (ETeRNAL'2015), conf\u00e9rence TALN'2015, Jun 2015, Caen, France. pp.53-66. \u27e8hal-01170630\u27e9 [paper]  </p> </li> <li> <p>Wagstaff, K. (2012). Machine learning that matters. In Proceedings of the 29<sup>th</sup> International Coference on International Conference on Machine Learning (ICML'12). [paper]  </p> </li> <li> <p>Kenny, D. The ethics of machine translation. (2011). New Zealand Society of Translators and Interpreters Annual Conference 2011. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/t-language-diversity/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Jin, Z., Levine, S., Kleiman-Weiner, M., Piatti, G., Liu, J., Adauto, F.G., Ortu, F., Strausz, A., Sachan, M., Mihalcea, R., Choi, Y., &amp; Scholkopf, B. (2024). Language Model Alignment in Multilingual Trolley Problems. International Conference on Learning Representations. [paper]  </p> </li> <li> <p>Jin, Z., Levine, S., Kleiman-Weiner, M., Piatti, G., Liu, J., Adauto, F.G., Ortu, F., Strausz, A., Sachan, M., Mihalcea, R., Choi, Y., &amp; Scholkopf, B. (2024). Language Model Alignment in Multilingual Trolley Problems. International Conference on Learning Representations. [paper]  </p> </li> <li> <p>Markl, N., &amp; Lai, C. (2021, April). Context-sensitive evaluation of automatic speech recognition: considering user experience &amp; . In Proceedings of the First Workshop on Bridging Human\u2013Computer Interaction and Natural Language Processing (pp. 34-40). [paper]  </p> </li> <li> <p>Tan, S., &amp; Joty, S. (2021). Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. doi:10.18653/v1/2021.naacl-main.282 [paper]  </p> </li> <li> <p>Bird, S. (2020, December). Decolonising speech and language technology. In Proceedings of the 28<sup>th</sup> International Conference on Computational Linguistics (pp. 3504-3519). doi:10.18653/v1/2020.coling-main.313 [paper]  </p> </li> <li> <p>Joshi, P., Santy, S., Budhiraja, A., Bali, K., &amp; Choudhury, M. (2020). The state and fate of linguistic diversity and inclusion in the NLP world. In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, 2020, 6282-6293. doi:10.18653/v1/2020.acl-main.560 [paper]  </p> </li> <li> <p>Koenecke, A., Nam, A., Lake, E., Nudell, J., Quartey, M., Mengesha, Z., ... &amp; Goel, S. (2020). Racial disparities in automated speech recognition. Proceedings of the National Academy of Sciences, 117(14), 7684-7689. [paper]  </p> </li> <li> <p>Tan, S., Joty, S., Kan, M. Y., &amp; Socher, R. (2020, July). It's Morphin'Time! Combating Linguistic Discrimination with Inflectional Perturbations. Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Tan, S., Joty, S., Varshney, L. R., &amp; Kan, M. Y. (2020, November). Mind your inflections! Improving NLP for non-standard Englishes with Base-Inflection Encoding. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). [paper]  </p> </li> <li> <p>Bender, E. M. (2019). The # benderrule: On naming the languages we study and why it matters. The Gradient, 14. [paper]  </p> </li> <li> <p>Huang, X., &amp; Paul, M. (2019, June). Neural user factor adaptation for text classification: Learning to generalize across author demographics. In Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (* SEM 2019) (pp. 136-146). [paper]  </p> </li> <li> <p>Zmigrod, R., Mielke, S. J., Wallach, H., &amp; Cotterell, R. (2019). Counterfactual data augmentation for mitigating gender stereotypes in languages with rich morphology. In Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 1651\u20131661, Florence, Italy. Association for Computational Linguistics. [paper]  </p> </li> </ul> <ul> <li> <p>Jurgens, D., Tsvetkov, Y., &amp; Jurafsky, D. (2017, July). Incorporating dialectal variability for socially equitable language identification. In Proceedings of the 55<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 51-57). [paper]  </p> </li> <li> <p>Tatman, R. (2017, April). Gender and dialect bias in YouTube's automatic captions. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 53-59). [paper]  </p> </li> <li> <p>Hovy, D., &amp; S\u00f8gaard, A. (2015, July). Tagging performance correlates with author age. In Proceedings of the 53<sup>rd</sup> annual meeting of the Association for Computational Linguistics and the 7<sup>th</sup> international joint conference on natural language processing (volume 2: Short papers) (pp. 483-488). [paper]  </p> </li> <li> <p>J\u00f8rgensen, A., Hovy, D., &amp; S\u00f8gaard, A. (2015, July). Challenges of studying and processing dialects in social media. In Proceedings of the workshop on noisy user-generated text (pp. 9-18). [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/t-model-issues/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Ahia, O., Kumar, S. Gonen, H., Kasai, J., Mortensen, D., Smith, N. &amp; Tsvetkov, Y. (2023, December). Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 9904\u20139923, Singapore. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Gon\u00e7alves, G. &amp; Strubell, E. (2023). Understanding the Effect of Model Compression on Social Bias in Large Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 2663\u20132675, Singapore. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Nejadgholi, I., Kiritchenko, S., Fraser, K. C., &amp; Balkir, E. (2023) Concept-Based Explanations to Test for False Causal Relationships Learned by Abusive Language Classifiers. In Proceedings of the 7<sup>th</sup> Workshop on Online Abuse and Harms (WOAH), pages 138\u2013149, Toronto, Canada. Association for Computational Linguistics. [paper]   </p> </li> <li> <p>Nejadgholi, I., Balkir, E., Fraser, K.C., &amp; Kiritchenko, S. (2022). Towards Procedural Fairness: Uncovering Biases in How a Toxic Language Classifier Uses Sentiment Information.In Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 225\u2013237, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Bender, E. M., Gebru, T., McMillan-Major, A., &amp; Shmitchell, S. (2021, March). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\ud83e\udd9c. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (pp. 610-623). doi:10.1145/3442188.3445922 [paper]  </p> </li> <li> <p>Field, A., Blodgett, S. L., Talat, Z., &amp; Tsvetkov, Y. (2021, August). A Survey of Race, Racism, and Anti-Racism in NLP. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1905\u20131925, Online. Association for Computational Linguistics. doi:10.18653/v1/2021.acl-long.149 [paper]  </p> </li> <li> <p>Floridi, L., Chiriatti, M. GPT-3: Its Nature, Scope, Limits, and Consequences. Minds &amp; Machines 30, 681\u2013694 (2020). https://doi.org/10.1007/s11023-020-09548-1 [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/t-uncategorized/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Meehan C., Mrini K., &amp; Chaudhuri K. (2022). Sentence-level Privacy for Document Embeddings. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3367\u20133380, Dublin, Ireland. Association for Computational Linguistics.  [paper]  </p> </li> <li> <p>Schneider, J. M., Rehm, G., Montiel-Ponsoda, E., Doncel, V. R., Revenko, A., Karampatakis, S., ... &amp; Maganza, F. (2020, May). Orchestrating NLP Services for the Legal Domain. In Proceedings of the 12<sup>th</sup> Language Resources and Evaluation Conference (pp. 2332-2340). [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/type-post/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Kalluri P. (2020). Don't ask if artificial intelligence is good or fair, ask how it shifts power. Nature, 583(7815), 169. [paper]  </p> </li> <li> <p>Bender, E. M. (2019). The # benderrule: On naming the languages we study and why it matters. The Gradient, 14. [paper]  </p> </li> </ul> <ul> <li>Larson, J., Angwin, J., &amp; Parris, T. (2016). Breaking the black box: How machines learn to be racist. ProPublica. [paper]  </li> </ul>"},{"location":"resources/ethics-reading-list/type-preprint/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Morand, C., N\u00e9v\u00e9ol, A., &amp; Ligozat, A. L. (2025). Does Efficiency Lead to Green Machine Learning Model Training? Analyzing Historical Trends in Impacts from Hardware, Algorithmic and Carbon Optimizations. [paper]   </p> </li> <li> <p>Kantharuban, A., Milbauer, J., Strubell, E., &amp; Neubig, G. (2024). Stereotype or personalization? user identity biases chatbot recommendations [paper]  </p> </li> <li> <p>Karamolegkou, A., Hansen, S. S., Christopoulou, A., Stamatiou, F., Lauscher, A., &amp; S\u00f8gaard, A. (2024). Ethical Concern Identification in NLP: A Corpus of ACL Anthology Ethics Statements. [paper]  </p> </li> <li> <p>Li, P., Yang, J., Islam, M. A., &amp; Ren, S. (2023). Making ai less\" thirsty\": Uncovering and addressing the secret water footprint of ai models.  [paper]  </p> </li> <li> <p>Luccioni, S., Jernite, Y. &amp; Strubell, E. (2024). Power Hungry Processing: Watts Driving the Cost of AI Deployment? In Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '24). Association for Computing Machinery, New York, NY, USA, 85\u201399.  [paper]  </p> </li> <li> <p>Birhane, A., Prabhu, V. U., &amp; Kahembwe, E. (2021). Multimodal datasets: misogyny, pornography, and malignant stereotypes. arXiv preprint arXiv:2110.01963. [paper]  </p> </li> <li> <p>Anthony, L. F. W., Kanding, B., &amp; Selvan, R. (2020). Carbontracker: Tracking and predicting the carbon footprint of training deep learning models. arXiv preprint arXiv:2007.03051. [paper]  </p> </li> <li> <p>Raji, I. D., &amp; Yang, J. (2019). About ML: Annotation and benchmarking on understanding and transparency of machine learning lifecycles. arXiv preprint arXiv:1912.06166. [paper]  </p> </li> <li> <p>Holland, S., Hosny, A., Newman, S., Joseph, J., &amp; Chmielinski, K. (2018). The dataset nutrition label: A framework to drive higher data quality standards. arXiv preprint arXiv:1805.03677. [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/type-published/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Chen, Y., Raghuram, V. C., Mattern, J., Mihalcea, R., &amp; Jin, Z. (2025). Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias. In Findings of the Association for Computational Linguistics: NAACL 2025, pages 4984\u20135004, Albuquerque, New Mexico. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Ducel, F., Hiebel, N., Ferret, O., Fort, K., &amp; N\u00e9v\u00e9ol, A. (2025). \u201cWomen do not have heart attacks!\" Gender Biases in Automatically Generated Clinical Cases in French. Findings of the Association for Computational Linguistics: NAACL 2025:7145\u20137159. [paper]  </p> </li> <li> <p>Jin, Z., Levine, S., Kleiman-Weiner, M., Piatti, G., Liu, J., Adauto, F.G., Ortu, F., Strausz, A., Sachan, M., Mihalcea, R., Choi, Y., &amp; Scholkopf, B. (2024). Language Model Alignment in Multilingual Trolley Problems. International Conference on Learning Representations. [paper]  </p> </li> <li> <p>Luccioni, S., Strubell, E., &amp; Crawford, K. (2025). From Efficiency Gains to Rebound Effects: The Problem of Jevons' Paradox in AI's Polarized Environmental Debate. Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25):76\u201388. [paper]  </p> </li> <li> <p>Mihalcea, R., Ignat, O., Bai, L., Borah, A., Chiruzzo, L., Jin, Z., Kwizera, C., Nwatu, J., Poria, S., &amp; Solorio, T. (2025). Why AI Is WEIRD and Shouldn\u2019t Be This Way: Towards AI for Everyone, with Everyone, by Everyone. Proceedings of the AAAI Conference on Artificial Intelligence, 39(27), 28657-28670. [paper]  </p> </li> <li> <p>Mitchell, M., Attanasio, G., Baldini, I., Clinciu, M., Clive, J., Delobelle, P., Dey, M., Hamilton, S., Dill, T., Doughman, J., Dutt, R., Ghosh, A., Zosa Forde, J., Holtermann, C., Kaffee, L. A., Laud, T., Lauscher, A., Lopez-Davila, R. L., Masoud, M., Nangia, N., Ovalle, A., Pistilli, G., Radev, D., Savoldi, B., Raheja, V., Qin, J., Ploeger, E., Subramonian, A., Dhole, K., Sun, K., Djanibekov, A., Mansurov, J., Yin, K., Villa Cueva, E., Mukherjee, S., Huang, J., Shen, X., Gala, J., Al-Ali, H., Djanibekov, T., Mukhituly, N., Nie, S., Sharma, S., Stanczak, K., Szczechla, E., Timponi Torrent, T., Tunuguntla, D., Viridiano, M., Van Der Wal, O., Yakefu, A., N\u00e9v\u00e9ol, A., Zhang, M., Zink, S., &amp; Talat, Z. (2025). SHADES: Towards a Multilingual Assessment of Stereotypes in Large Language Models. Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), 2025:11995\u201312041.  [paper]  </p> </li> <li> <p>Varoquaux, G., Luccioni, S., &amp; Whittaker, M. (2025). Hype, Sustainability, and the Price of the Bigger-is-Better Paradigm in AI. In Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25):61\u201375  [paper]  </p> </li> <li> <p>Curry, A. C., Attanasio, G., Talat, Z. &amp; Hovy, D. (2024, August). Classist Tools: Social Class Correlates with Performance in NLP. In Proceedings of the 62<sup>nd</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12643\u201312655, Bangkok, Thailand. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Ducel F, N\u00e9v\u00e9ol A, Fort K. (2024). \u201cYou\u2019ll be a nurse, my son!\u201d Automatically assessing gender biases in autoregressive language models in French and Italian. Language Resources and Evaluation. Springer, Berlin Heidelberg, Germany. 2024:1-29 [paper]  </p> </li> <li> <p>Helm, P., Bella, G., Koch, G. et al. (2024). Diversity and language technology: how language modeling bias causes epistemic injustice. Ethics and Information Technology.  [paper]  </p> </li> <li> <p>Hofmann, V., Kalluri, P.R., Jurafsky, D. et al. (2024). AI generates covertly racist decisions about people based on their dialect. Nature 633, 147\u2013154. https://doi.org/10.1038/s41586-024-07856-5   </p> </li> <li> <p>Jin, Z., Heil, N., Liu, J., Dhuliawala, S., Qi, Y., Sch\u00f6lkopf, B., Mihalcea, R., &amp; Sachan, M. (2024). Implicit Personalization in Language Models: A Systematic Study. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 12309\u201312325, Miami, Florida, USA. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Jin, Z., Levine, S., Kleiman-Weiner, M., Piatti, G., Liu, J., Adauto, F.G., Ortu, F., Strausz, A., Sachan, M., Mihalcea, R., Choi, Y., &amp; Scholkopf, B. (2024). Language Model Alignment in Multilingual Trolley Problems. International Conference on Learning Representations. [paper]  </p> </li> <li> <p>Liu, J., Li, W., Jin, Z., &amp; Diab, M.T. (2024). Automatic Generation of Model and Data Cards: A Step Towards Responsible AI. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 1975\u20131997, Mexico City, Mexico. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Morand C, N\u00e9v\u00e9ol A, Ligozat AL. MLCA: a tool for Machine Learning Life Cycle Assessment. International Conference on ICT for Sustainability (ICT4S). 2024. [paper]  </p> </li> <li> <p>Ahia, O., Kumar, S. Gonen, H., Kasai, J., Mortensen, D., Smith, N. &amp; Tsvetkov, Y. (2023, December). Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 9904\u20139923, Singapore. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Coghlan, S., &amp; Parker, C. (2023). Harm to Nonhuman Animals from AI: a Systematic Account and Framework. Philosophy &amp; Technology. [paper]  </p> </li> <li> <p>Gon\u00e7alves, G. &amp; Strubell, E. (2023). Understanding the Effect of Model Compression on Social Bias in Large Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 2663\u20132675, Singapore. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Kirk, H. R., Vidgen, B., R\u00f6ttger, P., Thrush, T., &amp; Hale, S. A. (2023). Hatemoji: A test suite and adversarially-generated dataset for benchmarking and detecting emoji-based hate. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. (NAACL '23') 10.18653/v1/2022.naacl-main.97 [paper]  </p> </li> <li> <p>McMillan-Major, A., Bender, E. M. &amp; Friedman, B. (2023). Data Statements: From Technical Concept to Community Practice, ACM Journal on Responsible Computing. [paper]  </p> </li> <li> <p>Nejadgholi, I., Kiritchenko, S., Fraser, K. C., &amp; Balkir, E. (2023) Concept-Based Explanations to Test for False Causal Relationships Learned by Abusive Language Classifiers. In Proceedings of the 7<sup>th</sup> Workshop on Online Abuse and Harms (WOAH), pages 138\u2013149, Toronto, Canada. Association for Computational Linguistics. [paper]   </p> </li> <li> <p>Parmar, M., Mishra, S., Geva, M., &amp; Baral, C. (2023). Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions. In Proceedings of the 17<sup>th</sup> Conference of the European Chapter of the Association for Computational Linguistics, pages 1779\u20131789. [paper]  </p> </li> <li> <p>Pyatkin, V., Yung, F., Scholman, M. C., Tsarfaty, R., Dagan, I., &amp; Demberg, V. (2023). Design Choices for Crowdsourcing Implicit Discourse Relations: Revealing the Biases Introduced by Task Design. Transaction of Association for Computational Linguistics (TACL '23). [paper]  </p> </li> <li> <p>Vicente, L., &amp; Matute, H. (2023). Humans inherit artificial intelligence biases. Scientific Reports, 13(1), 15737. [paper]  </p> </li> <li> <p>Alorwu, A., Savage, S., van Berkel, N., Ustalov, D., Drutsa, A., Oppenlaender, J., Bates, O., Hettiachchi, D., Gadiraju, U., Goncalves, J., &amp; Hosio, S. (2022). REGROW: Reimagining Global Crowdsourcing for Better Human-AI Collaboration. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems (CHI EA '22). Association for Computing Machinery, New York, NY, USA, Article 88, 1\u20137 [paper]  </p> </li> <li> <p>Benotti L, Blackburn P. 2022. Ethics consideration sections in natural language processing papers. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 4509\u20134516, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Balkir, E., Kiritchenko, S., Nejadgholi, I., Fraser, K.C. (2022) Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models. In Proceedings of the 2<sup>nd</sup> Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), pages 80\u201392, Seattle, U.S.A. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Balkir, E., Nejadgholi, I., Fraser, K.C., Kiritchenko, S. (2022). Necessity and Sufficiency for Explaining Text Classifiers: A Case Study in Hate Speech Detection. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2672\u20132686, Seattle, United States. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Chalkidis I., Pasini T., Zhang S., Tomada L., Schwemer S., &amp; S\u00f8gaard A. (2022). FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4389\u20134406, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>D'Ignazio, C. (2022). The Urgency of Moving From Bias to Power. European Data Protection Law Review. Volume 8, Issue 4 (pp. 451 - 454). [paper]  </p> </li> <li> <p>Fraser, K.C., Kiritchenko, S., Balkir, E. (2022) Does Moral Code Have a Moral Code? Probing Delphi's Moral Philosophy. In Proceedings of the 2<sup>nd</sup> Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), pages 26\u201342, Seattle, U.S.A. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Fraser, K.C., Kiritchenko, S., Nejadgholi, I. (2022). Computational Modelling of Stereotype Content in Text. Frontiers in Artificial Intelligence, 5, 2022. doi:10.3389/frai.2022.826207. [paper]  </p> </li> <li> <p>Meade N., Poole-Dayan E., &amp; Reddy S. (2022). An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1878\u20131898, Dublin, Ireland. Association for Computational Linguistics.  [paper]  </p> </li> <li> <p>Meehan C., Mrini K., &amp; Chaudhuri K. (2022). Sentence-level Privacy for Document Embeddings. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3367\u20133380, Dublin, Ireland. Association for Computational Linguistics.  [paper]  </p> </li> <li> <p>Miceli, M., Posada, J., &amp; Yang, T. (2022). Studying up machine learning data: Why talk about bias when we mean power?. Proceedings of the ACM on Human-Computer Interaction, 6(GROUP), 1-14. [paper]   </p> </li> <li> <p>Mohammad, S. (2022). Ethics Sheets for AI Tasks. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8368\u20138379, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Nejadgholi, I., Balkir, E., Fraser, K.C., &amp; Kiritchenko, S. (2022). Towards Procedural Fairness: Uncovering Biases in How a Toxic Language Classifier Uses Sentiment Information.In Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 225\u2013237, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics. [paper]  </p> </li> <li> <p>N\u00e9v\u00e9ol, A., Dupont, Y., Bezan\u00e7on, J., &amp; Fort, K. (2022). French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8521\u20138531, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Przyby\u0142a, P., &amp; Shardlow M. (2022). Using NLP to quantify the environmental cost and diversity benefits of in-person NLP conferences. In Findings of the Association for Computational Linguistics: ACL 2022, pages 3853\u20133863, Dublin, Ireland. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Talat, Z., N\u00e9v\u00e9ol, A., Biderman, S., Clinciu, M., Dey, M., Longpre, S., Luccioni, S., Masoud, M., Mitchell, M., Radev, D., Sharma, S., Subramonian, A., Tae, J., Tan, S., Tunuguntla, D. &amp; Van Der Wal, O. (2022). You reap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings. In Proceedings of BigScience Episode #5 -- Workshop on Challenges &amp; Perspectives in Creating Large Language Models, pages 26\u201341, virtual+Dublin. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Abdalla, M. &amp; Abdalla, M. (2021). The Grey Hoodie Project: Big Tobacco, Big Tech, and the Threat on Academic Integrity Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, Association for Computing Machinery, 2021, 287-297. [paper]  </p> </li> <li> <p>Aka, O., Burke, K., B\u00e4uerle, A., Greer, C., &amp; Mitchell, M. (2021). Measuring Model Biases in the Absence of Ground Truth. DOI:10.1145/3461702.3462557. AIES '21: AAAI/ACM Conference on AI, Ethics, and Society. [paper]  </p> </li> <li> <p>Bannour, N., Ghannay, S., N\u00e9v\u00e9ol, A. and Ligozat, A.-L. 2021. Evaluating the carbon footprint of NLP methods: a survey and analysis of existing tools. In Proceedings of the Second Workshop on Simple and Efficient Natural Language Processing, pages 11\u201321, Virtual. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Bender, E. M., Gebru, T., McMillan-Major, A., &amp; Shmitchell, S. (2021, March). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\ud83e\udd9c. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (pp. 610-623). doi:10.1145/3442188.3445922 [paper]  </p> </li> <li> <p>Dev, S., Monajatipoor, M., Ovalle, A., Subramonian, A., Phillips, J., and Chang, K. (2021). Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1968\u20131994. [paper]  </p> </li> <li> <p>Dodge, J., Sap, M., Marasovic, A., Agnew, W., Ilharco, G., Groeneveld, D., ... &amp; Face, H. (2021, September). Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1286\u20131305, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Field, A., Blodgett, S. L., Talat, Z., &amp; Tsvetkov, Y. (2021, August). A Survey of Race, Racism, and Anti-Racism in NLP. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1905\u20131925, Online. Association for Computational Linguistics. doi:10.18653/v1/2021.acl-long.149 [paper]  </p> </li> <li> <p>Fraser K. C., Nejadgholi, I. and Kiritchenko, S. (2021). Understanding and Countering Stereotypes: A Computational Approach to the Stereotype Content Model. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 600\u2013616, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Hooker, S. (2021). Moving beyond \u201calgorithmic bias is a data problem\u201d. Patterns, 2(4).[paper]  </p> </li> <li> <p>Kiritchenko, S., Nejadgholi, I., and Fraser, K. C. (2021). Confronting Abusive Language Online: A Survey from the Ethical and Human Rights Perspective. Journal of Artificial Intelligence Research, 71: 431-478, July 2021. doi:10.1613/jair.1.12590. [paper]  </p> </li> <li> <p>Kreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., ... &amp; Adeyemi, M. (2021). Quality at a glance: An audit of web-crawled multilingual datasets.Transactions of the Association for Computational Linguistics, The MIT Press, 2022, 10, pp.50-72. [paper]  </p> </li> <li> <p>Kummerfeld, J. K. (2021). Quantifying and Avoiding Unfair Qualification Labour in Crowdsourcing. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 343\u2013349, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Lannelongue, L., Grealey, J., &amp; Inouye, M. (2021). Green algorithms: Quantifying the carbon footprint of computation. Advanced Science, 2100707. doi:10.1002/advs.202100707. [paper]  </p> </li> <li> <p>Markl, N., &amp; Lai, C. (2021, April). Context-sensitive evaluation of automatic speech recognition: considering user experience &amp; . In Proceedings of the First Workshop on Bridging Human\u2013Computer Interaction and Natural Language Processing (pp. 34-40). [paper]  </p> </li> <li> <p>Shmueli, B., Fell, J., Ray, S., &amp; Ku, L. W. (2021). Beyond fair pay: Ethical implications of NLP crowdsourcing. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3758\u20133769, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Tan, S., &amp; Joty, S. (2021). Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. doi:10.18653/v1/2021.naacl-main.282 [paper]  </p> </li> <li> <p>Tan, S., Joty, S., Baxter, K., Taeihagh, A., Bennett, G. A., &amp; Kan, M. Y. (2021). Reliability Testing for Natural Language Processing Systems.  In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4153\u20134169, Online. Association for Computational Linguistics. doi:10.18653/v1/2021.acl-long.321 [paper]  </p> </li> <li> <p>Bird, S. (2020, December). Decolonising speech and language technology. In Proceedings of the 28<sup>th</sup> International Conference on Computational Linguistics (pp. 3504-3519). doi:10.18653/v1/2020.coling-main.313 [paper]  </p> </li> <li> <p>Blodgett, S. L., Barocas, S., Daum\u00e9 III, H., &amp; Wallach, H. (2020). Language (technology) is power: A critical survey of \"bias\" in NLP.  In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 5454\u20135476, Online. Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.485. [paper]  </p> </li> <li> <p>Bonastre, J. F. (2020). 1990-2020: retours sur 30 ans d'\u00e9changes autour de l'identification de voix en milieu judiciaire. In 6e conf\u00e9rence conjointe Journ\u00e9es d'\u00c9tudes sur la Parole (JEP, 33e \u00e9dition), Traitement Automatique des Langues Naturelles (TALN, 27e \u00e9dition), Rencontre des \u00c9tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R\u00c9CITAL, 22e \u00e9dition). 2e atelier \u00c9thique et TRaitemeNt Automatique des Langues (ETeRNAL) (pp. 38-47). ATALA; AFCP. [paper]  </p> </li> <li> <p>Caglayan, O., Madhyastha, P., &amp; Specia, L. (2020). Curious case of language generation evaluation metrics: A cautionary tale.  In Proceedings of the 28<sup>th</sup> International Conference on Computational Linguistics, pages 2322\u20132328, Barcelona, Spain (Online). International Committee on Computational Linguistics. doi:10.18653/v1/2020.coling-main.210. [paper]  </p> </li> <li> <p>Ethayarajh, K., &amp; Jurafsky, D. (2020, November). Utility is in the eye of the user: A critique of NLP leaderboards. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) doi:10.18653/v1/2020.emnlp-main.393. [paper]  </p> </li> <li> <p>Floridi, L., Chiriatti, M. GPT-3: Its Nature, Scope, Limits, and Consequences. Minds &amp; Machines 30, 681\u2013694 (2020). https://doi.org/10.1007/s11023-020-09548-1 [paper]  </p> </li> <li> <p>Garnerin, M., Rossato, S., &amp; Besacier, L. (2020). Pratiques d'\u00e9valuation en ASR et biais de performance (Evaluation methodology in ASR and performance bias). In Actes de la 6e conf\u00e9rence conjointe Journ\u00e9es d'\u00c9tudes sur la Parole (JEP, 33e \u00e9dition), Traitement Automatique des Langues Naturelles (TALN, 27e \u00e9dition), Rencontre des \u00c9tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R\u00c9CITAL, 22e \u00e9dition). 2e atelier \u00c9thique et TRaitemeNt Automatique des Langues (ETeRNAL) (pp. 1-9). [paper]  </p> </li> <li> <p>Goldfarb-Tarrant, S., Marchant, R., Sanchez, R. M., Pandya, M., &amp; Lopez, A. (2020). Intrinsic bias metrics do not correlate with application bias. Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers) [paper].  </p> </li> <li> <p>Hagendorff, T. The Ethics of AI Ethics: An Evaluation of Guidelines Minds &amp; Machines, 2020, 30, 99-120. [paper]  </p> </li> <li> <p>Henderson, P., Hu, J., Romoff, J., Brunskill, E., Jurafsky, D., &amp; Pineau, J. (2020). Towards the systematic reporting of the energy and carbon footprints of machine learning. Journal of Machine Learning Research, 21(248), 1-43. [paper]  </p> </li> <li> <p>Jo, E. S., &amp; Gebru, T. (2020, January). Lessons from archives: Strategies for collecting sociocultural data in machine learning. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 306-316). [paper]  </p> </li> <li> <p>Joshi, P., Santy, S., Budhiraja, A., Bali, K., &amp; Choudhury, M. (2020). The state and fate of linguistic diversity and inclusion in the NLP world. In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, 2020, 6282-6293. doi:10.18653/v1/2020.acl-main.560 [paper]  </p> </li> <li> <p>Koenecke, A., Nam, A., Lake, E., Nudell, J., Quartey, M., Mengesha, Z., ... &amp; Goel, S. (2020). Racial disparities in automated speech recognition. Proceedings of the National Academy of Sciences, 117(14), 7684-7689. [paper]  </p> </li> <li> <p>Kulynych, B., Overdorf, R., Troncoso, C., &amp; G\u00fcrses, S. (2020). POTs: protective optimization technologies. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT* '20). Association for Computing Machinery, New York, NY, USA, 177\u2013188. DOI:https://doi.org/10.1145/3351095.3372853. [paper]  </p> </li> <li> <p>Leins, K. Lau, J. H., &amp; Baldwin, T. (2020, July). Give Me Convenience and Give Her Death: Who Should Decide What Uses of NLP are Appropriate, and on What Basis?. In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (pp 2908\u20132913) [paper]  </p> </li> <li> <p>Linzen, T. (2020, July). How can we accelerate progress towards human-like linguistic generalization?.  Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.465 [paper]  </p> </li> <li> <p>Mathur, N., Baldwin, T., &amp; Cohn, T. (2020, July). Tangled up in BLEU: Reevaluating the evaluation of automatic machine translation evaluation metrics.  Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.448 [paper]  </p> </li> <li> <p>Mohammad, S. M. (2020, July). Gender gap in natural language processing research: Disparities in authorship and citations. Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.702 [paper]  </p> </li> <li> <p>Nangia, N., Vania, C., Bhalerao, R., &amp; Bowman, S. R. (2020, November). CrowS-pairs: A challenge dataset for measuring social biases in masked language models. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP).  doi:10.18653/v1/2020.emnlp-main.154 [paper]  </p> </li> <li> <p>Nissim, M., van Noord, R., &amp; van der Goot, R. (2020). Fair is better than sensational: Man is to doctor as woman is to doctor. Computational Linguistics, 46(2), 487-497. doi:10.1162/coli_a_00379 [paper]  </p> </li> <li> <p>Paullada, A., Raji, I. D., Bender, E. M., Denton, E., &amp; Hanna, A. (2020). Data and its (dis) contents: A survey of dataset development and use in machine learning research. Patterns, Volume 2, Issue 11, 12 November 2021, Pages 100388. [paper]  </p> </li> <li> <p>Schneider, J. M., Rehm, G., Montiel-Ponsoda, E., Doncel, V. R., Revenko, A., Karampatakis, S., ... &amp; Maganza, F. (2020, May). Orchestrating NLP Services for the Legal Domain. In Proceedings of the 12<sup>th</sup> Language Resources and Evaluation Conference (pp. 2332-2340). [paper]  </p> </li> <li> <p>Schwartz, R., Dodge, J., Smith, N. A., &amp; Etzioni, O. (2020). Green AI. Communications of the ACM, 63(12), 54-63. [paper]  </p> </li> <li> <p>Tan, S., Joty, S., Kan, M. Y., &amp; Socher, R. (2020, July). It's Morphin'Time! Combating Linguistic Discrimination with Inflectional Perturbations. Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Tan, S., Joty, S., Varshney, L. R., &amp; Kan, M. Y. (2020, November). Mind your inflections! Improving NLP for non-standard Englishes with Base-Inflection Encoding. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). [paper]  </p> </li> <li> <p>Vidgen, B., &amp; Derczynski, L. (2020). Directions in abusive language training data, a systematic review: Garbage in, garbage out. PloS one, 15(12), e0243300. [paper]  </p> </li> <li> <p>Bregeon, D., Antoine, J. Y., Villaneau, J., &amp; Lefeuvre-Halftermeyer, A. (2019). Redonner du sens \u00e0 l'accord interannotateurs: vers une interpr\u00e9tation des mesures d'accord en termes de reproductibilit\u00e9 de l'annotation. Traitement Automatique des Langues, 60(2), 23.  [paper]  </p> </li> <li> <p>Garimella, A., Banea, C., Hovy, D., &amp; Mihalcea, R. (2019, July). Women's syntactic resilience and men's grammatical luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing. In Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (pp. 3493-3498). [paper]  </p> </li> <li> <p>Green, B. (2019). \"Good\" isn't good enough. In Proceedings of the AI for Social Good workshop at NeurIPS. [paper]  </p> </li> <li> <p>Hara, K.; Adams, A.; Milland, K.; Savage, S.; Hanrahan, B. V.; Bigham, J. P. &amp; Callison-Burch, C. (2019). Worker Demographics and Earnings on Amazon Mechanical Turk: An Exploratory Analysis Association for Computing Machinery, 1-6. [paper]  </p> </li> <li> <p>Huang, X., &amp; Paul, M. (2019, June). Neural user factor adaptation for text classification: Learning to generalize across author demographics. In Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (* SEM 2019) (pp. 136-146). [paper]  </p> </li> <li> <p>Kann, K., Cho, K., &amp; Bowman, S. R. (2019). Towards realistic practices in low-resource natural language processing: the development set. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9<sup>th</sup> International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3342\u20133349, Hong Kong, China. Association for Computational Linguistics. doi:10.18653/v1/D19-1329 [paper]  </p> </li> <li> <p>Lacoste A., Luccioni A., Schmidt V., &amp; Dandres T. (2019). Quantifying the carbon emissions of machine learning. In Climate Change workshop, NeurIPS 2019. [paper]  </p> </li> <li> <p>Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., ... &amp; Gebru, T. (2019, January). Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency (pp. 220-229). [paper]  </p> </li> <li> <p>Monteiro, M. (2019). Ruined by design: How designers destroyed the world, and what we can do to fix it. Mule Design.  </p> </li> <li> <p>Sap, M., Gabriel, S., Qin, L., Jurafsky, D., Smith, N. A., &amp; Choi, Y. (2019). Social bias frames: Reasoning about social and power implications of language.  In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 5477\u20135490, Online. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Strubell, E., Ganesh, A., &amp; McCallum, A. (2019). Energy and policy considerations for deep learning in NLP. In Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 3645\u20133650, Florence, Italy. Association for Computational Linguistics. doi:10.18653/v1/P19-1355. [paper]  </p> </li> <li> <p>Zmigrod, R., Mielke, S. J., Wallach, H., &amp; Cotterell, R. (2019). Counterfactual data augmentation for mitigating gender stereotypes in languages with rich morphology. In Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 1651\u20131661, Florence, Italy. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Bender, E. M., &amp; Friedman, B. (2018). Data statements for natural language processing: Toward mitigating system bias and enabling better science. Transactions of the Association for Computational Linguistics, 6, 587-604 doi:10.1162/tacl_a_00041 [paper]  </p> </li> <li> <p>Curry, A. C., &amp; Rieser, V. (2018, June). # MeToo Alexa: How conversational systems respond to sexual harassment. In Proceedings of the second ACL workshop on ethics in natural language processing (pp. 7-14). [paper]  </p> </li> <li> <p>Fort, K., &amp; N\u00e9v\u00e9ol, A. (2018, January). Pr\u00e9sence et repr\u00e9sentation des femmes dans le traitement automatique des langues en France. In Penser la Recherche en Informatique comme pouvant \u00eatre Situ\u00e9e, Multidisciplinaire Et Genr\u00e9e (PRISME-G). [paper]  </p> </li> <li> <p>Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Daum\u00e9 III, H., &amp; Crawford, K. (2018). Datasheets for datasets. Commun. ACM 64, 12 (December 2021), 86\u201392. DOI:https://doi.org/10.1145/3458723. [paper]  </p> </li> <li> <p>Hara, K.; Adams, A.; Milland, K.; Savage, S.; Callison-Burch, C. &amp; Bigham, J. P. (2018). A Data-Driven Analysis of Workers' Earnings on Amazon Mechanical Turk CHI 2018. [paper]  </p> </li> <li> <p>Kiritchenko S. and Mohammad S. (2018). Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems. In Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, pages 43\u201353, New Orleans, Louisiana. Association for Computational Linguistics. [paper]  </p> </li> <li> <p>Schluter, N. (2018). The glass ceiling in NLP. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 2793-2798). doi:10.18653/v1/D18-1301 [paper]  </p> </li> <li> <p>Caliskan, A., Bryson, J. J., &amp; Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. Science, 356(6334), 183-186.  </p> </li> <li> <p>Jurgens, D., Tsvetkov, Y., &amp; Jurafsky, D. (2017, July). Incorporating dialectal variability for socially equitable language identification. In Proceedings of the 55<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 51-57). [paper]  </p> </li> <li> <p>Koolen, C. &amp; van Cranenburgh, A. These are not the Stereotypes You are Looking For: Bias and Fairness in Authorial Gender Attribution. In Proceedings of the first ACL workshop on ethics in natural language processing (pp. 12-22). [paper]  </p> </li> <li> <p>Larson, B. (2017). Gender as a Variable in Natural-Language Processing: Ethical Considerations. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 1\u201311). [paper]  </p> </li> <li> <p>Leidner, J. L. &amp; Plachouras, V. Ethical by Design: Ethics Best Practices for Natural Language Processing. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, Association for Computational Linguistics, 2017, 30-40.  [paper]  </p> </li> <li> <p>Mieskes, M. (2017, April). A quantitative study of data in the NLP community. In Proceedings of the first ACL workshop on ethics in natural language processing (pp. 23-29). [paper]  </p> </li> <li> <p>Parra Escartin, C.; Reijers, W.; Lynn, T.; Moorkens, J.; Way, A. &amp; Liu, C.-H. Ethical Considerations in NLP Shared Tasks. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, Association for Computational Linguistics, 2017, 66-73.  [paper]  </p> </li> <li> <p>Rudinger, R., May, C., &amp; Van Durme, B. (2017, April). Social bias in elicited natural language inferences. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 74-79). [paper]  </p> </li> <li> <p>\u0160uster, S., Tulkens, S., &amp; Daelemans, W. (2017). A short review of ethical challenges in clinical natural language processing.  In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing. [paper]  </p> </li> <li> <p>Tatman, R. (2017, April). Gender and dialect bias in YouTube's automatic captions. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 53-59). [paper]  </p> </li> <li> <p>Amblard, M. (2016). Pour un TAL responsable. Traitement Automatique des Langues, 57(2), 21-45. [paper]  </p> </li> <li> <p>Cohen, K. B.; Fort, K.; Adda, G.; Zhou, S. &amp; Farri, D. Ethical Issues in Corpus Linguistics And Annotation: Pay Per Hit Does Not Affect Effective Hourly Rate For Linguistic Resource Development On Amazon Mechanical Turk ETHics In Corpus collection, Annotation and Application workshop, 2016. [paper]  </p> </li> <li> <p>Fort, K., &amp; Couillault, A. (2016, May). Yes, we care! results of the ethics and natural language processing surveys. In international Language Resources and Evaluation Conference (LREC) 2016. [paper]  </p> </li> <li> <p>Hovy, D., &amp; Spruit, S. L. (2016, August). The social impact of natural language processing. In Proceedings of the 54<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 591-598) doi:10.18653/v1/P16-2096. [paper]  </p> </li> <li> <p>Lefeuvre-Halftermeyer, A., Govaere, V., Antoine, J. Y., Allegre, W., Pouplin, S., Departe, J. P., ... &amp; Spagnulo, A. (2016). Typologie des risques pour une analyse \u00e9thique de l'impact des technologies du TAL. Traitement Automatique des Langues, 57(2), 47-71. [paper]  </p> </li> <li> <p>Mathet, Y., &amp; Widl\u00f6cher, A. (2016). \u00c9valuation des annotations: ses principes et ses pi\u00e8ges. Traitement Automatique des Langues, 57(2), 73-98. [paper]  </p> </li> <li> <p>Bretonnel Cohen, K.; Pestian, J. P. &amp; Fort, K. (2015, June). Annotating suicide notes : ethical issues at a glance. In Proc. of ETeRNAL (Ethique et Traitement Automatique des Langues), Caen, France. [paper]  </p> </li> <li> <p>Ferraro, F., Mostafazadeh, N., Vanderwende, L., Devlin, J., Galley, M., &amp; Mitchell, M. (2015). A survey of current datasets for vision and language research.  In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 207\u2013213, Lisbon, Portugal. Association for Computational Linguistics. doi:10.18653/v1/D15-1021 [paper]  </p> </li> <li> <p>Hovy, D., &amp; S\u00f8gaard, A. (2015, July). Tagging performance correlates with author age. In Proceedings of the 53<sup>rd</sup> annual meeting of the Association for Computational Linguistics and the 7<sup>th</sup> international joint conference on natural language processing (volume 2: Short papers) (pp. 483-488). [paper]  </p> </li> <li> <p>J\u00f8rgensen, A., Hovy, D., &amp; S\u00f8gaard, A. (2015, July). Challenges of studying and processing dialects in social media. In Proceedings of the workshop on noisy user-generated text (pp. 9-18). [paper]  </p> </li> <li> <p>Lefeuvre A., Antoine J-Y., Allegre W. Ethique cons\u00e9quentialiste et traitement automatique des langues : une typologie de facteurs de risques adapt\u00e9e aux technologies langagi\u00e8res. Atelier Ethique et TRaitemeNt Automatique des Langues (ETeRNAL'2015), conf\u00e9rence TALN'2015, Jun 2015, Caen, France. pp.53-66. \u27e8hal-01170630\u27e9 [paper]  </p> </li> <li> <p>Callison-Burch, C. (2014, September). Crowd-workers: Aggregating information across turkers to help them find higher paying work. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing (Vol. 2, No. 1). [paper]  </p> </li> <li> <p>Couillault, A., Fort, K., Adda, G., &amp; De Mazancourt, H. (2014, May). Evaluating corpora documentation with regards to the ethics and big data charter. In International Conference on Language Resources and Evaluation (LREC). [paper]  </p> </li> <li> <p>Fort K., Adda G., Sagot B., Mariani J., Couillault A.. Crowdsourcing for Language Resource Development: Criticisms About Amazon Mechanical Turk Overpowering Use. Vetulani, Zygmunt and Mariani, Joseph. Human Language Technology Challenges for Computer Science and Linguistics, 8387, Springer International Publishing, pp.303-314, 2014, Lecture Notes in Computer Science, 978-3-319-08957-7. [paper]  </p> </li> <li> <p>Irani, L. C., &amp; Silberman, M. S. (2013, April). Turkopticon: Interrupting worker invisibility in amazon mechanical turk. In Proceedings of the SIGCHI conference on human factors in computing systems (pp. 611-620). [paper]  </p> </li> <li> <p>Wagstaff, K. (2012). Machine learning that matters. In Proceedings of the 29<sup>th</sup> International Coference on International Conference on Machine Learning (ICML'12). [paper]  </p> </li> <li> <p>Bederson, B. B., &amp; Quinn, A. J. (2011). Web workers unite! addressing challenges of online laborers. In CHI'11 Extended Abstracts on Human Factors in Computing Systems (pp. 97-106).  </p> </li> <li> <p>Fort, K., Adda, G., &amp; Cohen, K. B. (2011). Amazon Mechanical Turk: Gold mine or coal mine?. Computational Linguistics, 37(2), 413-420. doi:10.1162/COLI_a_00057 [paper]  </p> </li> <li> <p>Kenny, D. The ethics of machine translation. (2011). New Zealand Society of Translators and Interpreters Annual Conference 2011. [paper]  </p> </li> <li> <p>Adda, G. &amp; Mariani, J. (2010). Language resources and Amazon Mechanical Turk: legal, ethical and other issues. Proceedings of Legal Issues for Sharing Language Resources workshop in International Conference on Language Resources and Evaluation (LREC), European Language Resources Association (ELRA). [paper]  </p> </li> <li> <p>Drugan, J. &amp; Babych, B. (2010). Shared Resources, Shared Values? Ethical Implications of Sharing Translation Resources. Proceedings of the Second Joint EM+/CNGL Workshop: Bringing MT to the User: Research on Integrating MT in the Translation Industry, Association for Machine Translation in the Americas, 3-10. [paper]  </p> </li> <li> <p>Snyder, J. (2010). Exploitation and sweatshop labor: Perspectives and issues. Business Ethics Quarterly, 20(2), 187-213. [paper]  </p> </li> <li> <p>Kacmarcik, G., &amp; Gamon, M. (2006, July). Obfuscating document stylometry to preserve author anonymity. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions (pp. 444-451). [paper]  </p> </li> </ul>"},{"location":"resources/ethics-reading-list/type-report/","title":"Filtered Union Bibliography","text":"<p>This automatically-generated file contains references from the main union bibliography that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p> <p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p> <p> </p> <p></p> <ul> <li> <p>Bender, Emily M., Friedman, B. and McMillan-Major, A. (2021). A Guide for Writing Data Statements for Natural Language Processing [paper]  </p> </li> <li> <p>Moss, E., Watkins, E. A., Singh, R., Elish, M. C., &amp; Metcalf, J. (2021). Assembling Accountability: Algorithmic Impact Assessment for the Public Interest. Available at SSRN 3877437. [paper]  </p> </li> <li> <p>Trebaol, M. J. T., Hartley, M.-A., &amp; Ghadikolaei, H. S. (2020). A tool to quantify and report the carbon footprint of machine learning computations and communication in academia and healthcare. Infoscience EPFL: record 278189. [report]  </p> </li> </ul>"},{"location":"roles/","title":"Roles","text":"<p>If you are involved in Natural Language Processing, whether as a researcher, educator, or practitioner, understanding and addressing ethical implications is crucial.  We've cross-listed and organized our website's resources by roles that relevant to NLP.    </p> <ul> <li>Authors seeking guidance on ethical considerations for paper submissions</li> <li>Instructors looking to incorporate ethics into NLP curricula</li> <li>Organizers planning conferences with ethical guidelines in mind  </li> <li>Researchers exploring responsible approaches to NLP development</li> <li>Reviewers evaluating submissions through an ethical lens</li> </ul>"},{"location":"roles/authors/","title":"Authors","text":"<p>As authors, your role is crucial: your research and your participation in the scientific community have an impact. You need to try and make sure that you do not contribute to causing any harm. A few key principles to help you think about possible ethical issues and how to report them are listed down below:</p>"},{"location":"roles/authors/#1-include-ethics-from-the-start-and-throughout-the-pipeline","title":"1. Include ethics from the start, and throughout the pipeline","text":"<p>Ethics is not an afterthought, and is not limited to filling an ethical consideration section or to tick boxes when submitting your papers. To make sure your research is not raising ethical concerns, ethical reflections should start from the conception of the experiment, and be present at all steps, then diligently reported in papers.</p> <p>Try and ask yourself questions about ethics while thinking about research questions, experiment and methodology design, tools and datasets choice/conception, tools evaluation, ... </p> <p>The following principles are examples of elements to keep in mind and apply in your research, at every step.</p>"},{"location":"roles/authors/#2-take-into-consideration-all-stakeholders","title":"2. Take into consideration all stakeholders","text":"<p>It takes a village to do research: from annotators, human participants, to involved researchers and even downstream users, many people can contribute or be affected by your work. It is important that all of them are taken into account, treated with respect and that you do not cause them any harm. Be transparent about who contributed to your research, how so, etc. This ensures that everyone was treated correctly, and also helps to signal possible bias (e.g., if a majority of men participated in an experiment, the results may only apply to men).</p> <p>Some more specific advice depending on the target population:</p>"},{"location":"roles/authors/#about-human-annotatorscrowdworkersinterns-and-human-participants","title":"About human annotators/crowdworkers/interns and human participants","text":"<p>Report how they were recruited, their level of \"expertise\"/education, some basic demographic information that could be relevant (e.g., gender, country of origin, spoken languages, ...), ... Also specify what their task was, what guidelines/specific training they followed, and if the task presented any risk (e.g., offensive content that had to be annotated, etc.).</p> <p>For human participants, also provide details about their informed consent, the procedures that were used to pseudonymize/anonymize when applicable, and whether or not a debrief took place after the experiment. </p>"},{"location":"roles/authors/#about-downstream-users","title":"About downstream users","text":"<p>Make sure that possible users will benefit from your research, and try and document the possible gaps: did you take into consideration a variety of possible users? Is one population less well represented? Will your system work less well on specific populations? What could be used to mitigate these problems?</p>"},{"location":"roles/authors/#3-think-about-the-possible-impact-of-your-research","title":"3. Think about the possible impact of your research","text":"<p>Other important elements are related to ethics and should be taken into account from the start, and reported, as precisely as possible. For instance:</p>"},{"location":"roles/authors/#limitations","title":"Limitations","text":"<p>Even before filling the Limitations section of your papers, limitations of your work should be addressed. The scope of your work should be clear, and what it does and does not do should be explicitly stated. For instance, what (variety of) language(s) does your system support? What population is (not) represented? What could be improved? Are there any possible conflicts of interest and/or (unconscious) bias? Stating these limitations allows for better transparency, but also allows readers to better frame your research and to mitigate their own possible biases. It also highlights the future directions that should be prioritized.</p>"},{"location":"roles/authors/#potential-for-misuse-dual-use-and-possible-risks","title":"Potential for misuse, dual use and possible risks:","text":"<p>While your work was probably conducted with good intentions, it is important to consider if/how it could be misused and the risks it could create. Be especially careful about marginalized populations that could be even more impacted. If in doubt, feel free to discuss with others, and especially with possibly concerned people. If the risks seem too high, ask yourself if it is really worth it, and how so.</p>"},{"location":"roles/authors/#environmental-impact","title":"Environmental impact","text":"<p>If you used computational resources, your work had an environmental impact. This should be thought about while conceiving the experiment, in order to estimate the impact and try and see if less costly alternatives exist. For example, to use LLMs, libraries such as VLLM (https://docs.vllm.ai/en/latest/) exist and make inference faster and less environmentaly costly. In any case, you should report the used resources (GPUs, time, ...). Tools, such as https://calculator.green-algorithms.org/ or https://github.com/blubrom/MLCA, help you compute estimated environmental impact (carbon footprint, ...).</p>"},{"location":"roles/authors/#about-data-collectioncreation","title":"About data collection/creation","text":"<p>Creating or collecting data raises a lot of ethical questions: was the collected data under a permissive license/did the authors gave their informed consent? Is the resulting collection representative of different populations? Does it contain offensive content? Does it contain sensitive information? Was everything properly documented?</p>"},{"location":"roles/authors/#4-ethics-is-a-discussion-the-more-the-merrier","title":"4. Ethics is a discussion: the more the merrier!","text":"<p>Remember that ethics is not all about theory, but it is an ongoing, dynamic discussion. To enrich your perspectives, reach out to people around you: colleagues, students, even friends and family. Whether it is to discuss an ethical dilemma, to share your research ideas, or to brainstorm, it could enlarge your views and add perspectives you had not thought about.</p>"},{"location":"roles/authors/#5-extend-your-knowledge-on-ethics","title":"5. Extend your knowledge on ethics","text":"<p>The ACL ethics committee gathered resources on ethics and NLP. Feel free to consult our reading list https://ethics.aclweb.org/resources/ethics-reading-list/ ! </p> <p>The ARR Responsible NLP Research (https://aclrollingreview.org/responsibleNLPresearch/) is also a useful, complementary resource to the present webpage. </p> <p>Remember that keeping yourself informed and raising awareness is a first, crucial step to aim at a more ethical research.</p>"},{"location":"roles/instructors/","title":"Instructors","text":"<p>Natural Language Processing continues to transform both academic interests, practical industries and reshape how we interact with technology, ethical challenges associated with these powerful tools have become more pressing than ever. As instructors, we have the unique opportunity \u2014 and responsibility \u2014 to help tomorrow\u2019s NLP practitioners navigate the ethical dimensions of their work. Our website is designed specifically to support educators.</p>"},{"location":"roles/instructors/#1-integrate-ethics-into-your-lecturing-curriculum","title":"1. Integrate Ethics into Your Lecturing Curriculum","text":"<p>Ethics is a core component of responsible NLP education. Integrating ethical discussions and case studies into your syllabus helps students identify, analyze, and address complex issues they may encounter in academia or industry.  This is an absolutely essential topic that creates the necessary awareness of ethical issues that graduates will need in their future job roles. </p> <p>Relevant Resources:</p> <ul> <li>Sample Syllabi: Find ready-made course outlines that weave ethics into NLP modules.</li> <li>Lecture Presentation Slides: Download editable slide decks on topics like fairness, bias, and privacy.</li> <li>Assignment Templates: Use our assignments and reflection prompts to challenge students to think critically about ethical issues.</li> </ul>"},{"location":"roles/instructors/#2-stay-informed-about-emerging-ethical-challenges","title":"2. Stay Informed About Emerging Ethical Challenges","text":"<p>As the landscape of NLP ethics evolves rapidly, new risks and debates emerge. Staying updated ensures your teaching remains relevant and forward-looking.</p> <p>Relevant Resources:</p> <ul> <li>Trends &amp; News Feed: Access curated news articles and commentary on the latest ethical controversies in NLP.</li> <li>Ethical Reading List: Our website also maintains a crowdsourced bibliography of published academic work from major NLP conferences.  It features faceted classification, so you can filter the primary scholarly materials for topic, publication type and year.  </li> </ul>"},{"location":"roles/instructors/#3-educate-your-students-on-concerns-about-bias-fairness-and-inclusion","title":"3. Educate your students on concerns about Bias, Fairness, and Inclusion","text":"<p>NLP models can perpetuate and amplify biases related to inequity with respect to dimensions such as gender, race, or culture, when trained improperly. Educating students on these topics is essential to ensure that future production technologies will address these issues.</p> <p>Relevant Resources:</p> <ul> <li>Interactive Demos: Use web-based tools that visualize bias in popular NLP models.</li> <li>Case Studies: Explore real-world incidents of bias in language technologies and how they were addressed.</li> <li>Guidelines &amp; Checklists: Access actionable frameworks for evaluating and mitigating bias.</li> </ul>"},{"location":"roles/instructors/#4-address-data-privacy-and-consent","title":"4. Address Data Privacy and Consent","text":"<p>Responsible data stewardship is a critical part of building and deploying NLP systems. Teaching best practices around data privacy prepares students for ethical research and development.</p> <p>Relevant Resources:</p> <ul> <li>Privacy Guidelines: Download checklists for ethical data collection, anonymization, and storage.</li> <li>Discussion Scenarios: Engage your class with dilemmas related to consent, data sharing, and user rights.</li> </ul>"},{"location":"roles/instructors/#5-spark-meaningful-classroom-discussions","title":"5. Spark Meaningful Classroom Discussions","text":"<p>Ethical gray areas in NLP benefit from open discussion and debate. Providing students with structured materials can help foster these important conversations.</p> <p>Relevant Resources:</p> <ul> <li>Debate Kits: Get starter packs with opposing viewpoints, prompts, and background readings.</li> <li>Ethical Case Scenarios: Present your students with real or hypothetical cases to analyze and discuss.</li> </ul>"},{"location":"roles/instructors/#6-support-capstone-and-research-projects","title":"6. Support Capstone and Research Projects","text":"<p>Capstone projects and student research require ethical oversight and critical thinking. Our resources help instructors and students consider ethical implications from the outset.</p> <p>Relevant Resources:</p> <ul> <li>Project Planning Worksheets: Checklists to help students identify potential ethical pitfalls early.</li> <li>Ethics Review Templates: Forms and guidelines for student-led ethical review processes.</li> </ul>"},{"location":"roles/instructors/#7-access-community-and-expert-guidance","title":"7. Access Community and Expert Guidance","text":"<p>Connecting with peers and experts fosters knowledge-sharing and continuous improvement in how we teach NLP ethics.</p> <p>Relevant Resources:</p> <ul> <li>Online Forums: Participate in educator discussion boards to share ideas and ask questions.</li> <li>Expert Webinars: Attend live or recorded talks from leading voices in NLP and AI ethics.</li> </ul>"},{"location":"roles/instructors/#8-discover-teaching-aids-and-multimedia-content","title":"8. Discover Teaching Aids and Multimedia Content","text":"<p>Engaging multimedia and interactive tools enhance student learning and make complex ethical concepts more accessible.</p> <p>Relevant Resources:</p> <ul> <li>Video Explainers: Short, expert-led videos introducing key ethical topics.</li> <li>Infographics &amp; Visual Guides: Downloadable resources to use in lectures or assignments.</li> </ul>"},{"location":"roles/organizers/","title":"Organizers","text":"<p>Organizers and convenors of community events carry heightened ethical responsibilities, especially as NLP systems move into production and everyday use. They must set and enforce clear standards for submissions and presentations, including requirements on data provenance and consent, privacy protections, bias and fairness assessment, safety and red\u2011teaming, environmental impact reporting, and disclosure of funding, conflicts of interest, and potential dual\u2011use risks. </p> <p>They should ensure accessibility and inclusion, provide channels for community feedback and harm reporting, and require authors to articulate real\u2011world impacts, mitigation plans, and limits of generalization. By embedding ethics into calls for papers, reviewing rubrics, speaker guidelines, and on\u2011site practices, organizers shape a culture of accountability that protects participants, affected communities, and the broader public.</p> <p>Below, we outline considerations for prospective organizers planning workshops or conferences, followed by timelines and logistics for organizers executing the event.</p>"},{"location":"roles/organizers/#prospective-organizers","title":"Prospective Organizers","text":""},{"location":"roles/organizers/#1-ensure-appropriate-gender-geographic-and-cultural-balance","title":"1. Ensure Appropriate Gender, Geographic and Cultural balance","text":"<ul> <li>Scientific events often feature plenary talks and panels where speakers are seen as representing the community or stakeholder perspectives. Aim for balanced representation, especially in plenaries and keynotes across multiple days.</li> <li>Panels should include diverse and, where appropriate, opposing viewpoints to enrich discussion. Budget extra time and resources to identify, invite, and support underrepresented voices (e.g., travel support, remote participation options, childcare). Appoint a Diversity, Equity, and Inclusion (DEI) chair to coordinate with sponsorship leads to enable these accommodations.</li> </ul>"},{"location":"roles/organizers/#2-reserve-sufficient-time-for-ethical-review","title":"2. Reserve Sufficient Time for Ethical Review","text":"<ul> <li>Ethical and scientific reviews should be given comparable attention and time. Ensure your reviewing timeline explicitly includes adequate time for ethics review, not just technical evaluation.</li> <li>See Recommendations for Conference Chairs has a full rundown of the timeline; review it even before submitting your proposal. </li> <li>Engage us as the current ACL Ethics Committee early to help seed your ethics reviewer pool and to advise on review criteria and triage processes.</li> </ul>"},{"location":"roles/organizers/#3-signal-that-ethics-is-a-first-order-priority","title":"3. Signal that ethics is a first-order priority","text":"<ul> <li>Event webpages and calls for papers (CFPs) should clearly communicate ethical expectations and review policies. Include explicit ethics sections in CFPs, submission checklists, and reviewer guidelines.</li> <li>Publicly list the officers responsible for ethics (e.g., Ethics Chair, DEI Chair) and provide a contact channel for concerns, harm reports, and requests for guidance.</li> <li>Reinforce ethical commitments in author instructions, speaker agreements, and session moderation guidelines, and highlight them during opening remarks and author briefings.</li> </ul>"},{"location":"roles/organizers/#organizers","title":"Organizers","text":""},{"location":"roles/organizers/#ethics-reviewing","title":"Ethics Reviewing","text":""},{"location":"roles/organizers/#_1","title":"Organizers","text":""},{"location":"roles/researchers/","title":"Researchers","text":"<p>You got here because you are worried about ethical aspects of your work. Here you find resources that help you ensure your work is ethically grounded. </p> <ul> <li>responsible research checklist: This checklist should be part of every scientific project in the domain of CL/NLP and should be the first point of reference if you come up with an interesting research question \u2013 even before you start working on it. Throughout the project, the checklist guides you to keep in mind questions of responsible research. Added benefit: On submission of your paper it is already filled in and you don\u2019t have to think about what you decided several weeks or months ago. See here how this can be put into practice.</li> <li>Or you are worried, what Ethics Reviewers are paying attention to. The resources for Reviewers can be found here</li> </ul> <p>Researchers.</p> <p>Prospective Researchers.</p>"},{"location":"roles/reviewers/","title":"Reviewers","text":"<p>As reviewers, you play a critical role in shaping the research landscape of the NLP field. Your assessments influence the quality of publications alongside the kinds of practices and standards which are rewarded. Ethical reviewing is a key part of this responsibility: it ensures that published research is rigorous, transparent, and mindful of its broader impacts across societal scales.</p> <p>This tutorial will guide you in using various tools as a starting point for your ethical reviewing practice. You\u2019ll also have the opportunity to test and deepen your understanding of research ethics through case studies and simulated reviewing exercises.</p>"},{"location":"roles/reviewers/#1-recognize-that-ethics-is-part-of-scientific-quality","title":"1. Recognize That Ethics is Part of Scientific Quality","text":"<p>Ethical concerns are not separate from questions of validity, reproducibility, or contribution \u2014 they are integral to assessing a paper\u2019s quality and impact. Raising an ethics flag is crucial to ensuring that potential risks, limitations, or harms are properly identified and addressed.</p> <p>When reviewing, ask yourself:</p> <ul> <li>Does the work show awareness of ethical implications in data collection, modeling, evaluation, or application?</li> <li>Are sensitive aspects (e.g., privacy, bias, harmful content) clearly acknowledged and documented?</li> <li>Is there adequate transparency about limitations, risks, or potential misuse?</li> </ul> <p>A helpful starting point is the Responsible Research Checklist provided by authors at submission time. This can guide your evaluation and help you see whether key considerations have been thoughtfully addressed across potential papers.</p>"},{"location":"roles/reviewers/#2-pay-attention-to-all-stakeholders","title":"2. Pay Attention to All Stakeholders","text":"<p>Any research project encompasses a wide range of stakeholders throughout its lifecycle. Many people contribute and have the potential to be affected by work in NLP:</p> <ul> <li>Annotators, crowdworkers, interns: Are recruitment, training, demographics, and potential risks described? Are contributors treated fairly and respectfully?</li> <li>Human participants: Is informed consent obtained? Is anonymity/pseudonymization handled responsibly? Are participants debriefed when appropriate?</li> <li>Downstream users and impacted communities: Does the paper address who might benefit from the system, who might be disadvantaged, and whether performance varies across populations?</li> </ul> <p>As a reviewer, you can flag omissions in such ethical reporting, ask clarifying questions, and encourage authors to be more transparent in their experimental setup and limitations. </p>"},{"location":"roles/reviewers/#3-consider-broader-impacts","title":"3. Consider Broader Impacts","text":"<p>Beyond technical contributions, NLP research may carry risks or unintended consequences such as hate speech amplification, exacerbating adversarial vulnerability, or amplifying anti-democratic values. Look for whether authors discuss:</p> <ul> <li> <p>Limitations: Are the boundaries of the work clearly stated (languages, populations, contexts)? Are biases or conflicts of interest acknowledged within the research project?</p> </li> <li> <p>Misuse and dual use: Could the work be applied in harmful ways, particularly for marginalized groups? Did the authors anticipate risks and suggest safeguards to mitigate such concerns?</p> </li> <li> <p>Environmental impact: Are computational resources (GPUs, training time, etc.) reported? Did the authors consider less resource-intensive alternatives or estimate their carbon footprint?</p> </li> <li> <p>Data sourcing and licensing: Is data collected or created under appropriate permissions? Does the dataset contain offensive, sensitive, or non-representative content? Is documentation provided?</p> </li> </ul>"},{"location":"roles/reviewers/#4-ethics-reviewing-is-a-discussion","title":"4. Ethics Reviewing is a Discussion","text":"<p>You are not alone in making these judgments. The ACL ethics review process is designed to provide support and consistency. If you\u2019re unsure whether a paper warrants further review, flag it \u2014 the dedicated ethics reviewers will handle deeper evaluation.</p> <p>Engage with your fellow reviewers: in meta-reviews and discussions, raise ethical aspects alongside technical ones. This helps normalize ethics as part of standard reviewing practice. You can also build your own judgment through our tutorial resources:</p> <ul> <li>Case Studies: Explore hands-on examples in our Tutorial section to see how ethical dilemmas can arise in NLP research.</li> <li>Review Guidelines: Refer to the Ethical Review Recommendations available in the Resources section for structured guidance on assessing submissions.</li> </ul>"},{"location":"roles/reviewers/#5-extend-your-knowledge-on-ethics-in-reviewing","title":"5. Extend Your Knowledge on Ethics in Reviewing","text":"<p>The ACL Ethics Committee has gathered resources to help reviewers deepen their understanding:</p> <ul> <li>Ethics Reading List: Curated articles and ethics related resources for NLP researchers and practitioners moderated by the current ACL Ethics Committee.</li> <li>ARR Responsible NLP Research Guidelines: Comprehensive guide from ARR focused on evaluating responsible research practices.</li> </ul> <p>Ethics reviewing is about helping authors improve their work, ensuring fairness and transparency, and protecting the integrity of our field. By engaging with these tutorials and resources, you become an essential part of building a more responsible and sustainable NLP community that can positively benefit society.</p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>We have developed a series of tutorials presented at ACL conferences to enhance understanding and application of research in computational linguistics. These tutorials are crafted by experts to be informative and accessible. We aim to continually expand our tutorial offerings to cover emerging topics and methodologies, supporting the growth of the ACL community and engagement with advancements in the field.</p>"},{"location":"tutorials/#what-you-will-find-here","title":"What You Will Find Here","text":""},{"location":"tutorials/#past-tutorials","title":"Past Tutorials","text":"<p>Explore the tutorials presented at previous ACL conferences:</p> <ul> <li>EACL 2023</li> <li>ACL 2025</li> </ul>"},{"location":"tutorials/#upcoming-tutorials","title":"Upcoming Tutorials","text":"<p>Stay tuned for upcoming tutorials at future ACL conferences.</p> <ul> <li>No upcoming tutorials scheduled yet</li> </ul> <p>We hope these resources will be valuable in your research and professional development.</p>"},{"location":"tutorials/ACL_2025/","title":"ACL 2025 Ethics Tutorial: Navigating Ethical Challenges in NLP","text":""},{"location":"tutorials/ACL_2025/#acl-2025-ethics-tutorial-navigating-ethical-challenges-in-nlp","title":"ACL 2025 Ethics Tutorial: Navigating Ethical Challenges in NLP","text":"<p>Materials for the ACL 2025 Ethics Tutorial: Navigating Ethical Challenges in NLP: Hands-on strategies for students and researchers.</p> <p>This repository archives the materials in a reusable form, related materials (ACL Stakeholder Survey) and also links to other contemporary resources.  If you see things missing or needing maintenance, please file an issue or a pull request.</p> <p>Authors:</p> <ul> <li> <p>Luciana Benotti (Universidad Nacional de C\u00f3rdoba)</p> </li> <li> <p>Fanny Ducel (LISN, Universit\u00e9 Paris-Saclay)</p> </li> <li> <p>Kar\u00ebn Fort (Laboratoire Lorrain de Recherche en Informatique et ses Applications \u2013 LORIA, Universit\u00e9 de Lorraine)</p> </li> <li> <p>Guido Ivetta (Universidad Nacional de C\u00f3rdoba)</p> </li> <li> <p>Zhijing Jin (University of Toronto and Max Planck Institute)</p> </li> <li> <p>Min-Yen Kan (National University of Singapore)</p> </li> <li> <p>Seunghun J. Lee (International Christian University and University of Venda)</p> </li> <li> <p>Margot Mieskes (University of Applied Sciences, Darmstadt)</p> </li> <li> <p>Minzhi Li (National University of Singapore)</p> </li> <li> <p>Adriana Pagano (Universidade Federal de Minas Gerais)</p> </li> </ul> <p>Additional Contributors:</p> <ul> <li>Alvin Grissom II (Haverford College)</li> </ul>"},{"location":"tutorials/ACL_2025/#how-to-run-your-own-tutorial-or-lesson","title":"How to run your own tutorial or lesson?","text":"<p>We recommend using our base materials here and adapting them to your setting.  Minimally, you need to create your own shortlinks and URL codes to your version of the materials before running, as the archived materials reference our ACL 2025 or EACL 2023 instances.</p> <p>For our tutorial setting in an audience participatory style and approximately 60+ participants and 6 organizers, it was important to:</p> <ul> <li> <p>Restrict the number of groups so that each group can present within the session's time limit;</p> </li> <li> <p>Designate a particular organizer to facilitate virtual participants;</p> </li> <li> <p>Have live edit access to online documents, to allow participant leads to note-take and present.</p> </li> </ul> <p>Other formats might consider:</p> <ul> <li> <p>Lecture only: use and adapt the lecture materials from the first and seventh segments of the tutorial.</p> </li> <li> <p>Experiential only: use and adapt Segments 2\u20136, which asks participants to read and critique abstracts that bring up common ethical issues in our community.</p> </li> <li> <p>Student (Homework) Assignment: curate sources from the accompanying Ethics Reading List that the committee maintains, and ask participants to read and write their reflections on.</p> </li> </ul> <p>If you run a course, tutorial or other session based on these materials, we'd love to hear from you! Please get in contact with us, and we may also (with your permission) list your course or materials in the Resource segment.  Also please do cite our tutorial abstract as a means of acknowledging the helpfulness of the materials.  Thank you!</p> <pre><code>@inproceedings{benotti-etal-2025-navigating,\n    title = \"Navigating Ethical Challenges in {NLP}: Hands-on strategies for students and researchers\",\n    author = {Benotti, Luciana  and\n      Ducel, Fanny  and\n      Fort, Kar{\\\"e}n  and\n      Ivetta, Guido  and\n      Jin, Zhijing  and\n      Kan, Min-Yen  and\n      Lee, Seunghun J.  and\n      Li, Minzhi  and\n      Mieskes, Margot  and\n      Pagano, Adriana},\n    editor = \"Arase, Yuki  and\n      Jurgens, David  and\n      Xia, Fei\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 5: Tutorial Abstracts)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-tutorials.5/\",\n    pages = \"7--8\",\n    ISBN = \"979-8-89176-255-8\",\n    abstract = \"With NLP research being rapidly productionized into real-world applications, it is important to be aware of and think through the consequences of our work. Such ethical considerations are important in both authoring and reviewing (e.g. privacy, consent, fairness, among others). This tutorial will equip participants with basic guidelines for thinking deeply about ethical issues and review common considerations that recur in NLP research. The methodology is interactive and participatory, including discussion of case studies and group work. Participants will gain practical experience on when to flag a paper for ethics review and how to write an ethical consideration section to be shared with the broader community. Most importantly, the participants will be co-creating the tutorial outcomes and extending tutorial materials to share as public outcomes.\"\n}\n</code></pre>"},{"location":"tutorials/ACL_2025/#table-of-contents","title":"Table of Contents","text":"<p>(these are internal links to the sections below)</p> <ul> <li>Introduction</li> <li>Tutorial Slides</li> <li>Tutorial Recording</li> <li>Activity</li> <li>Resources</li> </ul>"},{"location":"tutorials/ACL_2025/#introduction","title":"Introduction","text":"<p>In 2024, the ACL Ethics Committee (AEC) decided to propose to run a tutorial on ethics and its impact on ethics in both authoring and reviewing aspects for the community of CL/NLP scholars and practitioners.  As part of this process, the AEC Committee put together the proposal file and submitted it to the joint call for tutorial proposals. It is currently published in the ACL Anthology.</p> <p>The tutorial was accepted to run at ACL 2025 (Vienna, Austria, 27 July to 1 August) on Sundey, 27 July from 14:00 to 17:30hs in Hall M.1-M.2 at the venue. The tutorial will be hybrid and we will have online moderators for the virtual participants. </p> <p>The tutorial and its materials will be presented in English.  It will be structured as per the proposal, in seven segments, each approximately 30 minutes long.  It is participatory in nature, requiring the audience to work in groups on invented problematic abstracts written by the proposers that represent common ethical issues experienced by ethics review chairs.  There will be a good facilitator-to-group ratio, to ensure all of the participants have a chance to reflect, contribute and be heard, and for the facilitators to keep the session on track.</p> <p>We conducted the tutorial in an active classroom style, where participants were self-organized into small groups (in our instance, 2 groups of about 10 participants each), electing leads for subsequent group presentation and worked through the exercises to record their reactions to the materials and identify the issues and conducive outcomes.</p>"},{"location":"tutorials/ACL_2025/#tutorial-slides","title":"Tutorial Slides","text":"<p>Google Slides permalink for ACL 2025 tutorial: https://tinyurl.com/presentation-deck-ACL-2025</p>"},{"location":"tutorials/ACL_2025/#individual-slides-pdfs","title":"Individual Slides PDFs","text":"Philosophical bases Presented by Fanny Ducel &amp; Kar\u00ebn Fort Ethical fundamental questions Presented by Guido Ivetta &amp; Luciana Benotti Language use that creates Bias Presented by Adriana Pagano &amp; Min-Yen Kan"},{"location":"tutorials/ACL_2025/#tutorial-recording","title":"Tutorial Recording","text":"Opening remark Presented by Margot Mieskes &amp; Adriana Pagano Philosophical bases Presented by Fanny Ducel &amp; Kar\u00ebn Fort Fundamental questions on ethics Presented by Guido Ivetta &amp; Luciana Benotti Language representation creates bias Presented by Adriana Pagano &amp; Min-Yen Kan Team discussions Closing remark"},{"location":"tutorials/ACL_2025/#activity","title":"Activity","text":"<p>The hands-on activity in the tutorial starts with a 5-minute introduction of the activity and a short review of the individual abstracts, which are also described in the slides.  Participants were grouped into random groups, which had to elect a scribe and a presenter.  The scribe serves as a secretariat for typing in the notes from their group; and the presenter is delegated as the person in the group to present the findings to the entire tutorial audience.  Each group was assigned one of the abstracts to read and critique.</p> <p>The critique of the abstracts is run in two phases.  In the first phase, groups discuss first to prepare a single slide for silent sharing with other groups (Segment 2).  In this second phase (Segment 4), the groups could enlarge their thinking by reflecting on either additional abstracts, the single shared slide from each group, or both.</p> <p>After both phases were finished, each group presented elements of their findings, with the faciltators structuring and probing for issues and clarity on different aspects.  </p>"},{"location":"tutorials/ACL_2025/#materials","title":"Materials","text":"<p>The activity was run using a scribe document where the organizers communicated information (the abstracts below and the instructions) and solicited the audience's feedback on the overall session.  </p> <ul> <li>Template Scribe Document (.pdf) - scrubbed</li> <li>Template Scribe Document (.docx) - scrubbed</li> <li>Template Scribe Document (live Google Doc) - view-only; scrubbed</li> </ul> <p>However, for the group activities, we used an editable online presentation deck such that each group could create 1-3 slides (1 slide max in the first phease) in their respective subgroups.  </p> <ul> <li>Template Group Slide Presentation (.pdf) -scrubbed </li> <li>Template Group Slide Presentation (live Google Slide link) - view only; scrubbed </li> </ul> <p>We provide 9 abstracts below with a gloss of their topical concern. The first 6 were written for EACL 2023, but only the first three were ran, due to the smaller number of participants.</p> <ol> <li>Facial Recognition</li> <li>Social Media Dataset Collection</li> <li>Cost-prohibitive Language Models</li> <li>Language Resource Collection from Protected Groups</li> <li>Multilingual Sentiment and Crowdsourced Annotation</li> <li>Large language model use in healthcare</li> <li>Autism, LLMs and Risks of Overclaiming</li> <li>Human Experiments on LLM-generated Medical Myths</li> <li>LLM Attacks for Stereotypes</li> </ol>"},{"location":"tutorials/ACL_2025/#resources","title":"Resources","text":"<ul> <li>The ACL Ethics Stakeholder Survey - Prior to the tutorial, the AEC also conducted a survey of our ACL stakeholders, to help priortize ethics needs of our community.  This tutorial is a direct result of that mandate presented in person at ACL (Toronto, Canada) on 11 July 2023.</li> <li>Full report for the survey: Yes, We Care (more)! Results of the Ethics and Natural Language Processing Survey</li> <li>Associated presentation slides</li> <li>The ACL Ethics Reading List - https://github.com/acl-org/ethics-reading-list</li> </ul> <p>Here is a list of faculty courses (by our presenters, certainly there are more out there) that have also taught similar topics.  For expediency we list them directly here:</p> <ul> <li>(In French and English) Kar\u00ebn</li> <li>(In English) Yulia</li> <li>(In Spanish) Benotti and Alonso Alemany </li> </ul>"},{"location":"tutorials/ACL_2025/#copyright-and-acknowledgements","title":"Copyright and Acknowledgements","text":"<p>All materials in this repo are CC-BY-4.0</p> <p>Our presenters would also like to thank the entire ACL Ethics Committee (AEC) for their support and endorsement of the process.</p>"},{"location":"tutorials/EACL_2023/","title":"EACL 2023","text":"<p>Materials for the EACL 2023 Ethics Tutorial: Understanding Ethics in NLP Authoring and Reviewing.</p> <p>This repository archives the materials in a reusable form, related materials (ACL Stakeholder Survey) and also links to other contemporary resources.  If you see things missing or needing maintenance, please file an issue or a pull request.</p> <p>Authors:</p> <ul> <li> <p>Luciana Benotti (Universidad Nacional de C\u00f3rdoba)</p> </li> <li> <p>Kar\u00ebn Fort (Sorbonne Universit\u00e9 and LORIA)</p> </li> <li> <p>Min-Yen Kan (National University of Singapore)</p> </li> <li> <p>Yulia Tsvetkov (University of Washington)</p> </li> </ul>"},{"location":"tutorials/EACL_2023/#how-to-run-your-own-tutorial-or-lesson","title":"How to run your own tutorial or lesson?","text":"<p>We recommend using our base materials here and adapting them to your setting.  Minimally, you need to create your own shortlinks and URL codes to your version of the materials before running, as the archived materials reference our EACL 2023 instance.</p> <p>For our tutorial setting in an audience participatory style and approximately 20+ participants and 4 organizers, it was important to:</p> <ul> <li> <p>limit the number of groups so that each group could present within the session's time limit;</p> </li> <li> <p>designate a particular organizer to facilitate virtual participants;</p> </li> <li> <p>have live edit access to online documents, to allow participant leads to note take and present.</p> </li> </ul> <p>Other formats might consider:</p> <ul> <li> <p>Lecture only: use and adapt the lecture materials from the first and seventh segments of the tutorial.</p> </li> <li> <p>Experiential only: use and adapt Segments 2-6, which asks participants to read and critique abstracts that bring up common ethical issues in our community.</p> </li> <li> <p>Student (Homework) Assignment: curate sources from the accompanying Ethics Reading List that the committee maintains, and ask participants to read and write their reflections on.</p> </li> </ul> <p>If you run a course, tutorial or other session based on these materials, we'd love to hear from you! Please get in contact with us, and we may also (with your permission) list your course or materials in the Resource segment.  Also please do cite our tutorial abstract as a means of acknowledging the helpfulness of the materials.  Thank you!</p> <pre><code>@inproceedings{benotti-etal-2023-understanding,\n    title = \"Understanding Ethics in {NLP} Authoring and Reviewing\",\n    author = {Benotti, Luciana  and\n      Fort, Kar{\\\"e}n  and\n      Kan, Min-Yen  and\n      Tsvetkov, Yulia},\n    booktitle = \"Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts\",\n    month = may,\n    year = \"2023\",\n    address = \"Dubrovnik, Croatia\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.eacl-tutorials.4\",\n    pages = \"19--24\",\n    abstract = \"With NLP research now quickly being transferred into real-world applications, it is important to be aware of and think through the consequences of our scientific investigation. Such ethical considerations are important in both authoring and reviewing. This tutorial will equip participants with basic guidelines for thinking deeply about ethical issues and review common considerations that recur in NLP research. The methodology is interactive and participatory, including case studies and working in groups. Importantly, the participants will be co-building the tutorial outcomes and will be working to create further tutorial materials to share as public outcomes.\",\n}\n</code></pre>"},{"location":"tutorials/EACL_2023/#table-of-contents","title":"Table of Contents","text":"<p>(these are internal links to the sections below)</p> <ul> <li>Introduction</li> <li>Tutorial Slides</li> <li>Tutorial Recording</li> <li>Activity</li> <li>Resources</li> </ul>"},{"location":"tutorials/EACL_2023/#introduction","title":"Introduction","text":"<p>In 2022, the ACL Ethics Committee (AEC) decided to propose to run a tutorial on ethics and its impact on ethics in both authoring and reviewing aspects for the community of CL/NLP scholars and practitioners.  As part of this process, the committee chairs and Luciana Benotti (a member of the committee) put together a the proposal file and submitted it to the joint call for tutorial proposals.</p> <p>The tutorial was eventually accepted to run at EACL 2023 (Dubrovnik, Croatia, 2-6 May 2023) on Saturday, 6 May as part of the \u00bd-day AM events.  We produced a teaser to accompany the published tutorial abstract.</p> <p>The tutorial and its materials* were presented in English.  It was structured as per the proposal, in seven segments, each approximately 30 minutes long.  It was participatory in nature, requiring the audience to work in groups on synthetic problematic abstracts written by the proposers that represent common ethical issues experienced by ethics review chairs.  This required a good facilitator-to-group ratio, to ensure all of the participants had a chance to reflect, contribute and be heard, and for the facilitators to keep the session on track.</p> <p>*<sub>(Due to the sensitive nature of our EACL 2023 participants' contribution, we have scrubbed the QR coded and shortlinked materials of their presence; if any party wants to access the original document we have these archived but not in this repository nor linked to here; please contact us directly)</sub></p> Segment Topic Led By 1. Introduction and Foundations for Ethics Presenters 2. Case Studies: Problematic Ethical Research \u2014 First reading Participants 3. Structured Interaction / Dialogue Presenters,Participants 4. Case studies \u2014 Second reading (Rotation) Participants 5. Group Presentations Group Leads 6. Summary and Common Issues Presenters 7. Discussing and Troubleshooting Ethics and Further Resources Presenters <p>We conducted the tutorial in an active classroom style, where participants were self-organized into small groups (in our instance, 2 groups of about 10 participants each), electing leads for subsequent group presentation and worked through the exercises to record their reactions to the materials and identify the issues and conducive outcomes.</p>"},{"location":"tutorials/EACL_2023/#tutorial-slides","title":"Tutorial Slides","text":"<p>After introducing the organisers and the format and resources of the tutorial, the first segment featured two lecture segments, both focused on introductory and foundational material on ethics.</p> <p>The presentation deck for the tutorial lives in a public, shared Google Slides permalink: http://bit.ly/eacl23-ethics-slides but for posterity, we have also archived forms here in this repository:</p> <ul> <li>PDF, local copy - created from the Google Slides origin deck</li> <li>Microsoft Powerpoint, local copy - created from the Google Slides origin deck</li> </ul> <p>Segment 1A (Slides 6-39) covers the definition and scope of ethics; its origins; virtue, deontological and utilitarian forms of ethics; experiments and policy reactions to ethical violation (Nuremburg Trials and Code, Belmont Report).  This segment was presented by Kar\u00ebn Fort.</p> <p>Segment 1B (Slides 40-70) focuses on appropriate use and application, biases and evaluation, covering hypothetical and real instances of ethical problems in recent research (Chicken dilemma, IQ prediction, sexual orientation prediction -- the \"Gaydar\" paper, and how AI and NLP technology influences people both directly and indirectly.  This segment was presented by Yulia Tsvetkov.</p> <p>Segment 7A (Slides 86-99) reprised work from Benotti and Blackburn (2022) Ethical Consideration Sections in Natural Language Processing Papers, which examined such written ECS in NLP papers to analyze the issues covered in terms of 1) research benefits, 2) potential harms, and 3) vulnerable groups affected.  It covers the differences between geographical region's reporting of such issues.  This segment was presented by Luciana Benotti.</p> <p>The remainder of the slides (Segment 7B) are framing materials to help introduce the tutorial, and set up the abstract critique exercise.  This segment was presented by Min-Yen Kan and all presenters.</p>"},{"location":"tutorials/EACL_2023/#tutorial-recording","title":"Tutorial Recording","text":"<p>The files of the recordings are too large to fit into this repository, but the below links to the segments of the scrubbed recordings.  </p> <ul> <li>(Segment 1A) - Introduction and Foundations for Ethics - Part 1 - Kar\u00ebn; 22m49s</li> <li> <p>(Segment 1A) - Introduction and Foundations for Ethics - Part 1 (with Q/A) - Kar\u00ebn; 40m17s</p> </li> <li> <p>(Segment 1B) - Introduction and Foundations for Ethics - Part 2 - Yulia; 27m18s</p> </li> <li> <p>(Segment 1B) - Introduction and Foundations for Ethics - Part 2 (with Q/A) - Yulia; 46m47s</p> </li> <li> <p>(Segment 7A) - Ethical Consideration Sections - Luciana; 17m42s</p> </li> <li> <p>(Segment 7B) - Conclusion - Min; 4m54s</p> </li> </ul>"},{"location":"tutorials/EACL_2023/#activity","title":"Activity","text":"<p>The hands-on activity in the tutorial starts with a 5-minute introduction of the activity and a short review of the individual abstracts, which are also described in the slides.  Participants were grouped into random groups, which had to elect a scribe and a presenter.  The scribe serves as a secretariat for typing in the notes from their group; and the presenter is delegated as the person in the group to present the findings to the entire tutorial audience.  Each group was assigned one of the abstracts to read and critique.</p> <p>The critique of the abstracts is run in two phases.  In the first phase, groups discuss first to prepare a single slide for silent sharing with other groups (Segment 2).  In this second phase (Segment 4), the groups could enlarge their thinking by reflecting on either additional abstracts, the single shared slide from each group, or both.</p> <p>After both phases were finished, each group presented elements of their findings, with the faciltators structuring and probing for issues and clarity on different aspects.  </p>"},{"location":"tutorials/EACL_2023/#materials","title":"Materials","text":"<p>The activity was run using a scribe document where the organizers communicated information (the abstracts below and the instructions) and solicited the audience's feedback on the overall session.  </p> <ul> <li>Template Scribe Document (.pdf) - scrubbed</li> <li>Template Scribe Document (.docx) - scrubbed</li> <li>Template Scribe Document (live Google Doc) - view-only; scrubbed</li> </ul> <p>However, for the group activities, we used an editable online presentation deck such that each group could create 1-3 slides (1 slide max in the first phease) in their respective subgroups.  </p> <ul> <li>Template Group Slide Presentation (.pdf) -scrubbed </li> <li>Template Group Slide Presentation (live Google Slide link) - view only; scrubbed </li> </ul> <p>We provide 6 abstracts below with a gloss of their topical concern.  In our EACL 2023 instance, we ran only the first three, due to the smaller number of participants.</p> <ol> <li>Facial Recognition</li> <li>Social Media Dataset Collection</li> <li>Cost-prohibitive Language Models</li> <li>Language Resource Collection from Protected Groups</li> <li>Multilingual Sentiment and Crowdsourced Annotation</li> <li>Large language model use in healthcare</li> </ol>"},{"location":"tutorials/EACL_2023/#resources","title":"Resources","text":"<ul> <li>The ACL Ethics Stakeholder Survey - Prior to the tutorial, the AEC also conducted a survey of our ACL stakeholders, to help priortize ethics needs of our community.  This tutorial is a direct result of that mandate.  To be presented live at ACL (Toronto, Canada) on 11 July 2023.</li> <li>Full report for the survey (draft): Yes, We Care (more)! Results of the 2021 Ethics and Natural Language Processing Survey</li> <li>Associated presentation slides</li> <li>The ACL Ethics Reading List - https://github.com/acl-org/ethics-reading-list - also mentioned in Slide 110</li> </ul> <p>The tutorial (Slide 109) also concluded with a list of faculty courses (by our presenters, certainly there are more out there) that have also taught similar topics.  For expediency we list them directly here:</p> <ul> <li>(In French and English) Kar\u00ebn https://members.loria.fr/KFort/teaching/nancy-tours-etc/</li> <li>(In English) Yulia  https://courses.cs.washington.edu/courses/cse582/23sp/</li> <li>(In Spanish) Benotti and Alonso Alemany. \u00c9tica Pr\u00e1ctica para Ciencia de Datos.  https://sites.google.com/view/etica-practica-cd/ </li> </ul>"},{"location":"tutorials/EACL_2023/#copyright-and-acknowledgements","title":"Copyright and Acknowledgements","text":"<p>All materials in this repo are CC-BY-4.0</p> <p>Our presenters would also like to thank the entire ACL Ethics Committee (AEC) for their support and endorsement of the process.</p> <ul> <li>Luciana Benotti, committee member (Americas) [she/her] 2021\u20132024</li> <li>Mark Drezde, committee member (Americas) [he/him] 2021\u20132024</li> <li>Kar\u00ebn Fort, co-chair (Europe/Africa) [she/her] 2021\u20132026</li> <li>Pascale Fung, committee member (Asia/Oceania) [she/her] 2021\u20132024</li> <li>Dirk Hovy, committee member (Europe/Africa) [he/him] 2021\u20132024</li> <li>Min-Yen Kan, co-chair (Asia/Oceania) [he/him] 2021\u20132026</li> <li>Jin-Dong Kim, committee member (Asia/Oceania) [he/him] 2021\u20132024</li> <li>Malvina Nissim, committee member (Europe/Africa) [she/her] 2021\u20132024</li> <li>Yulia Tsvetkov, co-chair (Americas) [she/her] 2021\u20132026</li> </ul>"}]}