
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../t-crowdsourcing-issues/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.34">
    
    
      
        <title>topic-biases - ACL Ethics</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.35f28582.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#filtered-union-bibliography" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="ACL Ethics" class="md-header__button md-logo" aria-label="ACL Ethics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ACL Ethics
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              topic-biases
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../roles/" class="md-tabs__link">
          
  
    
  
  Roles

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../tutorials/" class="md-tabs__link">
          
  
    
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
    
  
  Resources

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../committee/" class="md-tabs__link">
        
  
    
  
  Committee

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="ACL Ethics" class="md-nav__button md-logo" aria-label="ACL Ethics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    ACL Ethics
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../roles/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Roles
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../tutorials/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Resources
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Resources
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Reading List
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Reading List
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    topic-biases
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t-crowdsourcing-issues/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    topic-crowdsourcing-issues
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t-data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    topic-data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t-dual-use/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    topic-dual-use
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t-environmental-impact/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    topic-environmental-impact
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t-evaluation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    topic-evaluation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t-general-resources/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    topic-general-resources
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t-language-diversity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    topic-language-diversity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t-model-issues/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    topic-model-issues
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t-uncategorized/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    topic-uncategorized
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../type-post/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    type-post
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../type-preprint/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    type-preprint
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../type-published/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    type-published
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../type-report/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    type-report
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ethical-review-recommendations/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ethical Reviewing Recommendations
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../committee/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Committee
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="filtered-union-bibliography">Filtered Union Bibliography<a class="headerlink" href="#filtered-union-bibliography" title="Permanent link">&para;</a></h1>
<p>This automatically-generated file contains references from the <a href="../">main union bibliography</a> that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!</p>
<p>The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.</p>
<p>
</p>

<p><a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a></p>
<ul>
<li>
<p>Chen, Y., Raghuram, V. C., Mattern, J., Mihalcea, R., &amp; Jin, Z. (2025). Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias. In Findings of the Association for Computational Linguistics: NAACL 2025, pages 4984–5004, Albuquerque, New Mexico. Association for Computational Linguistics. [<a href="https://aclanthology.org/2025.findings-naacl.281/">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Ducel, F., Hiebel, N., Ferret, O., Fort, K., &amp; Névéol, A. (2025). “Women do not have heart attacks!" Gender Biases in Automatically Generated Clinical Cases in French. Findings of the Association for Computational Linguistics: NAACL 2025:7145–7159. [<a href="https://aclanthology.org/2025.findings-naacl.398.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Jin, Z., Levine, S., Kleiman-Weiner, M., Piatti, G., Liu, J., Adauto, F.G., Ortu, F., Strausz, A., Sachan, M., Mihalcea, R., Choi, Y., &amp; Scholkopf, B. (2024). Language Model Alignment in Multilingual Trolley Problems. International Conference on Learning Representations. [<a href="https://arxiv.org/abs/2407.02273">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../t-language-diversity/"><img alt="Language Diversity" src="https://img.shields.io/badge/t-language%20diversity-blueviolet" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Mitchell, M., Attanasio, G., Baldini, I., Clinciu, M., Clive, J., Delobelle, P., Dey, M., Hamilton, S., Dill, T., Doughman, J., Dutt, R., Ghosh, A., Zosa Forde, J., Holtermann, C., Kaffee, L. A., Laud, T., Lauscher, A., Lopez-Davila, R. L., Masoud, M., Nangia, N., Ovalle, A., Pistilli, G., Radev, D., Savoldi, B., Raheja, V., Qin, J., Ploeger, E., Subramonian, A., Dhole, K., Sun, K., Djanibekov, A., Mansurov, J., Yin, K., Villa Cueva, E., Mukherjee, S., Huang, J., Shen, X., Gala, J., Al-Ali, H., Djanibekov, T., Mukhituly, N., Nie, S., Sharma, S., Stanczak, K., Szczechla, E., Timponi Torrent, T., Tunuguntla, D., Viridiano, M., Van Der Wal, O., Yakefu, A., Névéol, A., Zhang, M., Zink, S., &amp; Talat, Z. (2025). SHADES: Towards a Multilingual Assessment of Stereotypes in Large Language Models. Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), 2025:11995–12041.  [<a href="https://aclanthology.org/2025.naacl-long.600.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Curry, A. C., Attanasio, G., Talat, Z. &amp; Hovy, D. (2024, August). Classist Tools: Social Class Correlates with Performance in NLP. In Proceedings of the 62<sup>nd</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12643–12655, Bangkok, Thailand. Association for Computational Linguistics. [<a href="https://aclanthology.org/2024.acl-long.682.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Ducel F, Névéol A, Fort K. (2024). “You’ll be a nurse, my son!” Automatically assessing gender biases in autoregressive language models in French and Italian. Language Resources and Evaluation. Springer, Berlin Heidelberg, Germany. 2024:1-29 [<a href="https://link.springer.com/article/10.1007/s10579-024-09780-6">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../t-evaluation/"><img alt="Evaluation" src="https://img.shields.io/badge/t-evaluation-orange" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Helm, P., Bella, G., Koch, G. et al. (2024). Diversity and language technology: how language modeling bias causes epistemic injustice. Ethics and Information Technology.  [<a href="https://link.springer.com/article/10.1007/s10676-023-09742-6">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Hofmann, V., Kalluri, P.R., Jurafsky, D. et al. (2024). AI generates covertly racist decisions about people based on their dialect. Nature 633, 147–154. https://doi.org/10.1038/s41586-024-07856-5  <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Jin, Z., Heil, N., Liu, J., Dhuliawala, S., Qi, Y., Schölkopf, B., Mihalcea, R., &amp; Sachan, M. (2024). Implicit Personalization in Language Models: A Systematic Study. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 12309–12325, Miami, Florida, USA. Association for Computational Linguistics. [<a href="https://aclanthology.org/2024.findings-emnlp.717/">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Jin, Z., Levine, S., Kleiman-Weiner, M., Piatti, G., Liu, J., Adauto, F.G., Ortu, F., Strausz, A., Sachan, M., Mihalcea, R., Choi, Y., &amp; Scholkopf, B. (2024). Language Model Alignment in Multilingual Trolley Problems. International Conference on Learning Representations. [<a href="https://arxiv.org/abs/2407.02273">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../t-language-diversity/"><img alt="Language Diversity" src="https://img.shields.io/badge/t-language%20diversity-blueviolet" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Kantharuban, A., Milbauer, J., Strubell, E., &amp; Neubig, G. (2024). Stereotype or personalization? user identity biases chatbot recommendations [<a href="https://arxiv.org/pdf/2410.05613">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-preprint/"><img alt="preprint" src="https://img.shields.io/badge/type-preprint-lightgrey" /></a></p>
</li>
<li>
<p>Gonçalves, G. &amp; Strubell, E. (2023). Understanding the Effect of Model Compression on Social Bias in Large Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 2663–2675, Singapore. Association for Computational Linguistics. [<a href="https://aclanthology.org/2023.emnlp-main.161/">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../t-model-issues/"><img alt="Model Issues" src="https://img.shields.io/badge/t-model%20issues-yellow" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Kirk, H. R., Vidgen, B., Röttger, P., Thrush, T., &amp; Hale, S. A. (2023). Hatemoji: A test suite and adversarially-generated dataset for benchmarking and detecting emoji-based hate. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. (NAACL '23') 10.18653/v1/2022.naacl-main.97 [<a href="https://aclanthology.org/2022.naacl-main.97/">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../t-evaluation/"><img alt="Evaluation" src="https://img.shields.io/badge/t-evaluation-orange" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Nejadgholi, I., Kiritchenko, S., Fraser, K. C., &amp; Balkir, E. (2023) Concept-Based Explanations to Test for False Causal Relationships Learned by Abusive Language Classifiers. In Proceedings of the 7<sup>th</sup> Workshop on Online Abuse and Harms (WOAH), pages 138–149, Toronto, Canada. Association for Computational Linguistics. [<a href="https://aclanthology.org/2023.woah-1.14/">paper</a>]  <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../t-model-issues/"><img alt="Model Issues" src="https://img.shields.io/badge/t-model%20issues-yellow" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a>  </p>
</li>
<li>
<p>Parmar, M., Mishra, S., Geva, M., &amp; Baral, C. (2023). Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions. In Proceedings of the 17<sup>th</sup> Conference of the European Chapter of the Association for Computational Linguistics, pages 1779–1789. [<a href="https://aclanthology.org/2023.eacl-main.130.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a>  </p>
</li>
<li>
<p>Vicente, L., &amp; Matute, H. (2023). Humans inherit artificial intelligence biases. Scientific Reports, 13(1), 15737. [<a href="https://www.nature.com/articles/s41598-023-42384-8">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Balkir, E., Kiritchenko, S., Nejadgholi, I., Fraser, K.C. (2022) Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models. In Proceedings of the 2<sup>nd</sup> Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), pages 80–92, Seattle, U.S.A. Association for Computational Linguistics. [<a href="https://aclanthology.org/2022.trustnlp-1.8/">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Balkir, E., Nejadgholi, I., Fraser, K.C., Kiritchenko, S. (2022). Necessity and Sufficiency for Explaining Text Classifiers: A Case Study in Hate Speech Detection. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2672–2686, Seattle, United States. Association for Computational Linguistics. [<a href="https://aclanthology.org/2022.naacl-main.192/">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Chalkidis I., Pasini T., Zhang S., Tomada L., Schwemer S., &amp; Søgaard A. (2022). FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4389–4406, Dublin, Ireland. Association for Computational Linguistics. [<a href="https://aclanthology.org/2022.acl-long.301.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>D'Ignazio, C. (2022). The Urgency of Moving From Bias to Power. European Data Protection Law Review. Volume 8, Issue 4 (pp. 451 - 454). [<a href="https://edpl.lexxion.eu/article/EDPL/2022/4/4">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Fraser, K.C., Kiritchenko, S., Nejadgholi, I. (2022). Computational Modelling of Stereotype Content in Text. Frontiers in Artificial Intelligence, 5, 2022. doi:10.3389/frai.2022.826207. [<a href="https://www.frontiersin.org/articles/10.3389/frai.2022.826207">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Meade N., Poole-Dayan E., &amp; Reddy S. (2022). An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1878–1898, Dublin, Ireland. Association for Computational Linguistics.  [<a href="https://aclanthology.org/2022.acl-long.132.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Miceli, M., Posada, J., &amp; Yang, T. (2022). Studying up machine learning data: Why talk about bias when we mean power?. Proceedings of the ACM on Human-Computer Interaction, 6(GROUP), 1-14. [<a href="https://dl.acm.org/doi/abs/10.1145/3492853">paper</a>]  <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Nejadgholi, I., Balkir, E., Fraser, K.C., &amp; Kiritchenko, S. (2022). Towards Procedural Fairness: Uncovering Biases in How a Toxic Language Classifier Uses Sentiment Information.In Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 225–237, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics. [<a href="https://aclanthology.org/2022.blackboxnlp-1.18/">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../t-model-issues/"><img alt="Model Issues" src="https://img.shields.io/badge/t-model%20issues-yellow" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Névéol, A., Dupont, Y., Bezançon, J., &amp; Fort, K. (2022). French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English. In Proceedings of the 60<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8521–8531, Dublin, Ireland. Association for Computational Linguistics. [<a href="https://aclanthology.org/2022.acl-long.583.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Talat, Z., Névéol, A., Biderman, S., Clinciu, M., Dey, M., Longpre, S., Luccioni, S., Masoud, M., Mitchell, M., Radev, D., Sharma, S., Subramonian, A., Tae, J., Tan, S., Tunuguntla, D. &amp; Van Der Wal, O. (2022). You reap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings. In Proceedings of BigScience Episode #5 -- Workshop on Challenges &amp; Perspectives in Creating Large Language Models, pages 26–41, virtual+Dublin. Association for Computational Linguistics. [<a href="https://aclanthology.org/2022.bigscience-1.3.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Aka, O., Burke, K., Bäuerle, A., Greer, C., &amp; Mitchell, M. (2021). Measuring Model Biases in the Absence of Ground Truth. DOI:10.1145/3461702.3462557. AIES '21: AAAI/ACM Conference on AI, Ethics, and Society. [<a href="https://arxiv.org/abs/2103.03417">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Bender, E. M., Gebru, T., McMillan-Major, A., &amp; Shmitchell, S. (2021, March). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?🦜. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (pp. 610-623). doi:10.1145/3442188.3445922 [<a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922">paper</a>] <a href="../t-model-issues/"><img alt="Model Issues" src="https://img.shields.io/badge/t-model%20issues-yellow" /></a> <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Dev, S., Monajatipoor, M., Ovalle, A., Subramonian, A., Phillips, J., and Chang, K. (2021). Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1968–1994. [<a href="https://aclanthology.org/2021.emnlp-main.150.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Field, A., Blodgett, S. L., Talat, Z., &amp; Tsvetkov, Y. (2021, August). A Survey of Race, Racism, and Anti-Racism in NLP. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1905–1925, Online. Association for Computational Linguistics. doi:10.18653/v1/2021.acl-long.149 [<a href="https://aclanthology.org/2021.acl-long.149/">paper</a>] <a href="../t-model-issues/"><img alt="Model Issues" src="https://img.shields.io/badge/t-model%20issues-yellow" /></a> <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Fraser K. C., Nejadgholi, I. and Kiritchenko, S. (2021). Understanding and Countering Stereotypes: A Computational Approach to the Stereotype Content Model. In Proceedings of the 59<sup>th</sup> Annual Meeting of the Association for Computational Linguistics and the 11<sup>th</sup> International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 600–616, Online. Association for Computational Linguistics. [<a href="https://aclanthology.org/2021.acl-long.50/">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Hooker, S. (2021). Moving beyond “algorithmic bias is a data problem”. Patterns, 2(4).[<a href="https://www.cell.com/patterns/fulltext/S2666-3899(21)00061-1">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Blodgett, S. L., Barocas, S., Daumé III, H., &amp; Wallach, H. (2020). Language (technology) is power: A critical survey of "bias" in NLP.  In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 5454–5476, Online. Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.485. [<a href="https://www.aclweb.org/anthology/2020.acl-main.485">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Mohammad, S. M. (2020, July). Gender gap in natural language processing research: Disparities in authorship and citations. Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics. doi:10.18653/v1/2020.acl-main.702 [<a href="https://www.aclweb.org/anthology/2020.acl-main.702">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Nissim, M., van Noord, R., &amp; van der Goot, R. (2020). Fair is better than sensational: Man is to doctor as woman is to doctor. Computational Linguistics, 46(2), 487-497. doi:10.1162/coli_a_00379 [<a href="https://www.aclweb.org/anthology/2020.cl-2.7">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Garimella, A., Banea, C., Hovy, D., &amp; Mihalcea, R. (2019, July). Women's syntactic resilience and men's grammatical luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing. In Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (pp. 3493-3498). [<a href="https://aclanthology.org/P19-1339.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Sap, M., Gabriel, S., Qin, L., Jurafsky, D., Smith, N. A., &amp; Choi, Y. (2019). Social bias frames: Reasoning about social and power implications of language.  In Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, pages 5477–5490, Online. Association for Computational Linguistics. [<a href="https://aclanthology.org/2020.acl-main.486.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Curry, A. C., &amp; Rieser, V. (2018, June). # MeToo Alexa: How conversational systems respond to sexual harassment. In Proceedings of the second ACL workshop on ethics in natural language processing (pp. 7-14). [<a href="https://www.aclweb.org/anthology/W18-0802.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Fort, K., &amp; Névéol, A. (2018, January). Présence et représentation des femmes dans le traitement automatique des langues en France. In Penser la Recherche en Informatique comme pouvant être Située, Multidisciplinaire Et Genrée (PRISME-G). [<a href="https://hal.archives-ouvertes.fr/hal-01683774">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Kiritchenko S. and Mohammad S. (2018). Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems. In Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, pages 43–53, New Orleans, Louisiana. Association for Computational Linguistics. [<a href="https://aclanthology.org/S18-2005.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Schluter, N. (2018). The glass ceiling in NLP. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 2793-2798). doi:10.18653/v1/D18-1301 [<a href="https://www.aclweb.org/anthology/D18-1301">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Koolen, C. &amp; van Cranenburgh, A. These are not the Stereotypes You are Looking For: Bias and Fairness in Authorial Gender Attribution. In Proceedings of the first ACL workshop on ethics in natural language processing (pp. 12-22). [<a href="https://aclanthology.org/W17-1602.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
<li>
<p>Rudinger, R., May, C., &amp; Van Durme, B. (2017, April). Social bias in elicited natural language inferences. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 74-79). [<a href="https://aclanthology.org/W17-1609.pdf">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-published/"><img alt="published" src="https://img.shields.io/badge/type-published-lightgrey" /></a></p>
</li>
</ul>
<!--* Clark, J. (2016). Artificial intelligence has a ‘sea of dudes’ problem. Bloomberg Technology, 23. [[paper](https://www.bloomberg.com/news/articles/2016-06-23/artificial-intelligence-has-a-sea-of-dudes-problem)] ![Biases](https://img.shields.io/badge/t-biases-pink) ![post](https://img.shields.io/badge/type-post-lightgrey)-->

<ul>
<li>Larson, J., Angwin, J., &amp; Parris, T. (2016). Breaking the black box: How machines learn to be racist. <em>ProPublica</em>. [<a href="https://www.propublica.org/article/breaking-the-black-box-how-machines-learn-to-be-racist">paper</a>] <a href="./"><img alt="Biases" src="https://img.shields.io/badge/t-biases-pink" /></a> <a href="../type-post/"><img alt="post" src="https://img.shields.io/badge/type-post-lightgrey" /></a></li>
</ul>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2025–2023 <a href="https://github.com/acl-org/ethics-website"  target="_blank" rel="noopener">ACL Ethics Committee</a>

    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/acl-org/ethics-website" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.indexes", "navigation.top", "navigation.prune", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.07f07601.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.56dfad97.min.js"></script>
      
    
  </body>
</html>